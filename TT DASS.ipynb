{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast the difference between DAP and SSP\n",
    "Author: George Panagiotou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from comp_utils import *\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual=pd.read_csv('data/TradingTrackData/Actual_quantiles_cv_set.csv')\n",
    "Actual['time']=pd.to_datetime(Actual['time'])\n",
    "Actual.rename(columns={'time':'valid_time'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43906, 99)\n",
      "Original Train Table Shape: (43906, 99)\n"
     ]
    }
   ],
   "source": [
    "train_weather_feat = pd.read_hdf('data/DAP/train_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "train_weather_feat = train_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred=pd.read_csv('data/TradingTrackData/Demand_quantiles_train_set.csv')\n",
    "demand_pred.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "demand_pred['valid_time'] = pd.to_datetime(demand_pred['valid_time'], utc=True)\n",
    "demand_pred.drop(['ND'], axis=1, inplace=True)\n",
    "\n",
    "DAP_train_predictions=pd.read_csv('data/TradingTrackData/DAP_quantiles_train_set.csv')\n",
    "DAP_train_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "DAP_train_predictions.drop(['DA_Price'], axis=1, inplace=True)\n",
    "DAP_train_predictions['valid_time'] = pd.to_datetime(DAP_train_predictions['valid_time'], utc=True)\n",
    "\n",
    "SSP_train_predictions=pd.read_csv('data/TradingTrackData/SSP_quantiles_train_set.csv')\n",
    "SSP_train_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "SSP_train_predictions.drop(['SS_Price'], axis=1, inplace=True)\n",
    "SSP_train_predictions['valid_time'] = pd.to_datetime(SSP_train_predictions['valid_time'], utc=True)\n",
    "\n",
    "energy_data = pd.read_hdf(\"data/combined/train_energy_data_20200920_20240519.h5\",'df')\n",
    "train_table = pd.merge(demand_pred, train_weather_feat, on='valid_time', how='left')\n",
    "train_table = pd.merge(train_table, energy_data, left_on='valid_time', right_on='dtm', how='left')\n",
    "train_table = pd.merge(train_table, DAP_train_predictions, on='valid_time', how='left')\n",
    "train_table = pd.merge(train_table, SSP_train_predictions, on='valid_time', how='left')\n",
    "train_table.dropna(inplace=True)\n",
    "train_table.drop_duplicates(subset='valid_time', inplace=True)\n",
    "\n",
    "train_times = train_table['valid_time']\n",
    "train_target_variable = train_table['DA_Price']-train_table['SS_Price']\n",
    "train_table.drop(['DA_Price','dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', 'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', 'Availability1', 'Availability2', 'Availability3',], axis=1, inplace=True)\n",
    "print(train_table.shape)\n",
    "\n",
    "print(\"Original Train Table Shape:\", train_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5615, 99)\n",
      "CV Set Shape: (5615, 99)\n"
     ]
    }
   ],
   "source": [
    "train_weather_feat = pd.read_hdf('data/DAP/train_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "train_weather_feat = train_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred=pd.read_csv('data/TradingTrackData/Demand_quantiles_cv_set.csv')\n",
    "demand_pred.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "demand_pred['valid_time'] = pd.to_datetime(demand_pred['valid_time'], utc=True)\n",
    "demand_pred.drop(['ND'], axis=1, inplace=True)\n",
    "\n",
    "DAP_cv_predictions=pd.read_csv('data/TradingTrackData/DAP_quantiles_cv_set.csv')\n",
    "DAP_cv_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "DAP_cv_predictions['valid_time'] = pd.to_datetime(DAP_cv_predictions['valid_time'], utc=True)\n",
    "DAP_cv_predictions.drop(['DA_Price'], axis=1, inplace=True)\n",
    "\n",
    "SSP_cv_predictions=pd.read_csv('data/TradingTrackData/SSP_quantiles_cv_set.csv')\n",
    "SSP_cv_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "SSP_cv_predictions['valid_time'] = pd.to_datetime(SSP_cv_predictions['valid_time'], utc=True)\n",
    "SSP_cv_predictions.drop(['SS_Price'], axis=1, inplace=True)\n",
    "\n",
    "energy_data = pd.read_hdf(\"data/combined/train_energy_data_20200920_20240519.h5\",'df')\n",
    "cv_table = pd.merge(demand_pred, train_weather_feat, on='valid_time', how='left')\n",
    "cv_table = pd.merge(cv_table, energy_data, left_on='valid_time', right_on='dtm', how='left')\n",
    "cv_table = pd.merge(cv_table, DAP_cv_predictions, on='valid_time', how='left')\n",
    "cv_table = pd.merge(cv_table, SSP_cv_predictions, on='valid_time', how='left')\n",
    "cv_table.dropna(inplace=True)\n",
    "\n",
    "cv_times = cv_table['valid_time']\n",
    "cv_target_variable = cv_table['DA_Price']-cv_table['SS_Price']\n",
    "cv_table.drop(['DA_Price','dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', 'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', 'Availability1', 'Availability2', 'Availability3',], axis=1, inplace=True)\n",
    "print(cv_table.shape)\n",
    "print(\"CV Set Shape:\", cv_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4318, 10)\n",
      "Index(['q10_x', 'q20_x', 'q30_x', 'q40_x', 'q50_x', 'q60_x', 'q70_x', 'q80_x',\n",
      "       'q90_x', 'valid_time', 'DWD_WS_D_0', 'DWD_WS_D_1', 'DWD_WS_D_2',\n",
      "       'DWD_WS_D_3', 'DWD_WS_D_4', 'DWD_WS_D_5', 'DWD_WS_D_6', 'DWD_WD_D_0',\n",
      "       'DWD_WD_D_1', 'DWD_WD_D_2', 'DWD_WD_D_3', 'DWD_WD_D_4', 'DWD_WD_D_5',\n",
      "       'DWD_WD_D_6', 'DWD_RH_D_0', 'DWD_RH_D_1', 'DWD_RH_D_2', 'DWD_RH_D_3',\n",
      "       'DWD_RH_D_4', 'DWD_RH_D_5', 'DWD_RH_D_6', 'DWD_T_D_0', 'DWD_T_D_1',\n",
      "       'DWD_T_D_2', 'DWD_T_D_3', 'DWD_T_D_4', 'DWD_T_D_5', 'DWD_T_D_6',\n",
      "       'DWD_TP_D_0', 'DWD_TP_D_1', 'DWD_TP_D_2', 'DWD_TP_D_3', 'DWD_TP_D_4',\n",
      "       'DWD_TP_D_5', 'DWD_TP_D_6', 'NCEP_WS_D_0', 'NCEP_WS_D_1', 'NCEP_WS_D_2',\n",
      "       'NCEP_WS_D_3', 'NCEP_WS_D_4', 'NCEP_WS_D_5', 'NCEP_WS_D_6',\n",
      "       'NCEP_WD_D_0', 'NCEP_WD_D_1', 'NCEP_WD_D_2', 'NCEP_WD_D_3',\n",
      "       'NCEP_WD_D_4', 'NCEP_WD_D_5', 'NCEP_WD_D_6', 'NCEP_RH_D_0',\n",
      "       'NCEP_RH_D_1', 'NCEP_RH_D_2', 'NCEP_RH_D_3', 'NCEP_RH_D_4',\n",
      "       'NCEP_RH_D_5', 'NCEP_RH_D_6', 'NCEP_T_D_0', 'NCEP_T_D_1', 'NCEP_T_D_2',\n",
      "       'NCEP_T_D_3', 'NCEP_T_D_4', 'NCEP_T_D_5', 'NCEP_T_D_6', 'NCEP_TP_D_0',\n",
      "       'NCEP_TP_D_1', 'NCEP_TP_D_2', 'NCEP_TP_D_3', 'NCEP_TP_D_4',\n",
      "       'NCEP_TP_D_5', 'NCEP_TP_D_6', 'is_holiday', 'q10_y', 'q20_y', 'q30_y',\n",
      "       'q40_y', 'q50_y', 'q60_y', 'q70_y', 'q80_y', 'q90_y', 'q10', 'q20',\n",
      "       'q30', 'q40', 'q50', 'q60', 'q70', 'q80', 'q90'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_weather_feat = pd.read_hdf('data/DAP/test_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "test_weather_feat = test_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred_test = pd.read_csv('data/Demand/Demand_predictions_test_set.csv')\n",
    "demand_pred_test.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "demand_pred_test['valid_time'] = pd.to_datetime(demand_pred_test['valid_time'], utc=True)\n",
    "demand_pred_test.drop(['ND'], axis=1, inplace=True)\n",
    "print(demand_pred_test.shape)\n",
    "\n",
    "DAP_train_predictions=pd.read_csv('data/TradingTrackData/DAP_quantiles_test_set.csv')\n",
    "DAP_train_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "DAP_train_predictions.drop(['DA_Price'], axis=1, inplace=True)\n",
    "DAP_train_predictions['valid_time'] = pd.to_datetime(DAP_train_predictions['valid_time'], utc=True)\n",
    "\n",
    "SSP_train_predictions=pd.read_csv('data/TradingTrackData/SSP_quantiles_test_set.csv')\n",
    "SSP_train_predictions.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "SSP_train_predictions.drop(['SS_Price'], axis=1, inplace=True)\n",
    "SSP_train_predictions['valid_time'] = pd.to_datetime(SSP_train_predictions['valid_time'], utc=True)\n",
    "\n",
    "energy_data_test = pd.read_hdf(\"data/combined/test_energy_data_20200920_20240519.h5\",'df')\n",
    "\n",
    "test_table = pd.merge(demand_pred_test, test_weather_feat, on='valid_time', how='left')\n",
    "test_table = pd.merge(test_table, energy_data_test, left_on='valid_time', right_on='dtm', how='left')\n",
    "test_table = pd.merge(test_table, DAP_train_predictions, on='valid_time', how='left')\n",
    "test_table = pd.merge(test_table, SSP_train_predictions, on='valid_time', how='left')\n",
    "test_table.fillna(test_table.mean(), inplace=True)\n",
    "\n",
    "test_times = test_table['valid_time']\n",
    "test_target_variable = test_table['DA_Price']-test_table['SS_Price']\n",
    "test_table.drop(['DA_Price','dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', 'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', 'Availability1', 'Availability2', 'Availability3',], axis=1, inplace=True)\n",
    "print(test_table.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming time into cyclic features:\n",
    "We need to transform UTC datetime feature into numbers, thus we choose to convert datetime to cyclic features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features after adding cyclic times and removing valid_time: (43906, 107)\n",
      "CV features after adding cyclic times and removing valid_time: (5615, 107)\n",
      "Test features after adding cyclic times and removing valid_time: (4318, 107)\n"
     ]
    }
   ],
   "source": [
    "train_table = add_cyclic_features(train_table)\n",
    "train_table = train_table.drop(columns=[\"valid_time\"])\n",
    "print('Train features after adding cyclic times and removing valid_time:', train_table.shape)\n",
    "\n",
    "cv_table = add_cyclic_features(cv_table)\n",
    "cv_table = cv_table.drop(columns=[\"valid_time\"])\n",
    "print('CV features after adding cyclic times and removing valid_time:', cv_table.shape)\n",
    "\n",
    "test_table = add_cyclic_features(test_table)\n",
    "test_table = test_table.drop(columns=[\"valid_time\"])\n",
    "print('Test features after adding cyclic times and removing valid_time:', test_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:49:46,858] A new study created in memory with name: no-name-f9b9bdb9-df81-42f2-8c3c-ad254b7ea3e7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for quantile 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:49:47,909] Trial 0 finished with value: 8.613289121587432 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 8.613289121587432.\n",
      "[I 2024-08-20 22:49:49,601] Trial 1 finished with value: 7.759936579611473 and parameters: {'learning_rate': 0.030039546489421223, 'max_depth': -7, 'n_estimators': 189, 'num_leaves': 83, 'min_child_weight': 352.3487991282488}. Best is trial 1 with value: 7.759936579611473.\n",
      "[I 2024-08-20 22:49:50,532] Trial 2 finished with value: 8.039947645069622 and parameters: {'learning_rate': 0.04231050945002233, 'max_depth': -3, 'n_estimators': 159, 'num_leaves': 50, 'min_child_weight': 2.821547792117847}. Best is trial 1 with value: 7.759936579611473.\n",
      "[I 2024-08-20 22:49:51,265] Trial 3 finished with value: 8.508344699939057 and parameters: {'learning_rate': 0.07739518610306069, 'max_depth': -3, 'n_estimators': 201, 'num_leaves': 23, 'min_child_weight': 1.3265495324098902}. Best is trial 1 with value: 7.759936579611473.\n",
      "[I 2024-08-20 22:49:51,725] Trial 4 finished with value: 8.226498117239647 and parameters: {'learning_rate': 0.12584123509509754, 'max_depth': 3, 'n_estimators': 221, 'num_leaves': 76, 'min_child_weight': 23.210741723269468}. Best is trial 1 with value: 7.759936579611473.\n",
      "[I 2024-08-20 22:49:52,177] Trial 5 finished with value: 7.091315303619839 and parameters: {'learning_rate': 0.01883136322021595, 'max_depth': 2, 'n_estimators': 233, 'num_leaves': 82, 'min_child_weight': 33.17803245780064}. Best is trial 5 with value: 7.091315303619839.\n",
      "[I 2024-08-20 22:49:53,922] Trial 6 finished with value: 7.538158950580726 and parameters: {'learning_rate': 0.016850163841680154, 'max_depth': 0, 'n_estimators': 275, 'num_leaves': 51, 'min_child_weight': 517.3642478876053}. Best is trial 5 with value: 7.091315303619839.\n",
      "[I 2024-08-20 22:49:54,242] Trial 7 finished with value: 7.4077543743681264 and parameters: {'learning_rate': 0.0582518976220643, 'max_depth': 3, 'n_estimators': 126, 'num_leaves': 60, 'min_child_weight': 0.4006666925424543}. Best is trial 5 with value: 7.091315303619839.\n",
      "[I 2024-08-20 22:49:54,727] Trial 8 finished with value: 7.6263250320423115 and parameters: {'learning_rate': 0.06624689308547273, 'max_depth': 2, 'n_estimators': 249, 'num_leaves': 51, 'min_child_weight': 141.11717977406616}. Best is trial 5 with value: 7.091315303619839.\n",
      "[I 2024-08-20 22:49:55,181] Trial 9 finished with value: 7.236647141464715 and parameters: {'learning_rate': 0.028084027087897607, 'max_depth': 1, 'n_estimators': 259, 'num_leaves': 36, 'min_child_weight': 0.020532452917871792}. Best is trial 5 with value: 7.091315303619839.\n",
      "[I 2024-08-20 22:49:55,653] Trial 10 finished with value: 6.939796823787019 and parameters: {'learning_rate': 0.010077340465591519, 'max_depth': 7, 'n_estimators': 52, 'num_leaves': 96, 'min_child_weight': 18.134825703158327}. Best is trial 10 with value: 6.939796823787019.\n",
      "[I 2024-08-20 22:49:56,217] Trial 11 finished with value: 6.857339809179795 and parameters: {'learning_rate': 0.010046274771210006, 'max_depth': 7, 'n_estimators': 67, 'num_leaves': 97, 'min_child_weight': 16.502262140728156}. Best is trial 11 with value: 6.857339809179795.\n",
      "[I 2024-08-20 22:49:56,710] Trial 12 finished with value: 6.945552205577319 and parameters: {'learning_rate': 0.010169389687246589, 'max_depth': 7, 'n_estimators': 51, 'num_leaves': 100, 'min_child_weight': 8.786039734631922}. Best is trial 11 with value: 6.857339809179795.\n",
      "[I 2024-08-20 22:49:57,304] Trial 13 finished with value: 6.824524999967529 and parameters: {'learning_rate': 0.010773931177053634, 'max_depth': 7, 'n_estimators': 73, 'num_leaves': 97, 'min_child_weight': 0.18604415591785306}. Best is trial 13 with value: 6.824524999967529.\n",
      "[I 2024-08-20 22:49:57,706] Trial 14 finished with value: 6.818228999327996 and parameters: {'learning_rate': 0.01569113086713424, 'max_depth': 5, 'n_estimators': 92, 'num_leaves': 90, 'min_child_weight': 0.05623930458724062}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:49:58,104] Trial 15 finished with value: 6.835981961670307 and parameters: {'learning_rate': 0.016524638643585547, 'max_depth': 5, 'n_estimators': 96, 'num_leaves': 73, 'min_child_weight': 0.11097714542223913}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:49:58,538] Trial 16 finished with value: 6.824364509414814 and parameters: {'learning_rate': 0.014293705686893556, 'max_depth': 5, 'n_estimators': 105, 'num_leaves': 89, 'min_child_weight': 0.0017479323882641203}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:49:58,981] Trial 17 finished with value: 7.026437489260547 and parameters: {'learning_rate': 0.02316199890357379, 'max_depth': 5, 'n_estimators': 112, 'num_leaves': 87, 'min_child_weight': 0.0014463136523079373}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:49:59,514] Trial 18 finished with value: 6.880438933340633 and parameters: {'learning_rate': 0.013601960418622092, 'max_depth': 5, 'n_estimators': 136, 'num_leaves': 70, 'min_child_weight': 0.00126793359961497}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:50:00,392] Trial 19 finished with value: 7.779651166100811 and parameters: {'learning_rate': 0.04557888847486883, 'max_depth': -1, 'n_estimators': 95, 'num_leaves': 89, 'min_child_weight': 0.01050200834091173}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:50:00,700] Trial 20 finished with value: 6.886455574975409 and parameters: {'learning_rate': 0.02299256641897469, 'max_depth': 4, 'n_estimators': 94, 'num_leaves': 67, 'min_child_weight': 0.04065365073166759}. Best is trial 14 with value: 6.818228999327996.\n",
      "[I 2024-08-20 22:50:01,158] Trial 21 finished with value: 6.803516635202825 and parameters: {'learning_rate': 0.013535834371238675, 'max_depth': 6, 'n_estimators': 76, 'num_leaves': 91, 'min_child_weight': 0.26211299185272396}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:01,757] Trial 22 finished with value: 6.8208835051673935 and parameters: {'learning_rate': 0.013083701800311022, 'max_depth': 6, 'n_estimators': 112, 'num_leaves': 90, 'min_child_weight': 0.003742758703471141}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:02,405] Trial 23 finished with value: 6.83134001889066 and parameters: {'learning_rate': 0.012942808727760147, 'max_depth': 6, 'n_estimators': 124, 'num_leaves': 80, 'min_child_weight': 0.06021001614019257}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:02,726] Trial 24 finished with value: 6.8467267871838215 and parameters: {'learning_rate': 0.021174441512334278, 'max_depth': 4, 'n_estimators': 80, 'num_leaves': 91, 'min_child_weight': 0.005881506533644121}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:03,599] Trial 25 finished with value: 7.603117799369413 and parameters: {'learning_rate': 0.029638895536719615, 'max_depth': 6, 'n_estimators': 161, 'num_leaves': 91, 'min_child_weight': 0.4444321057559119}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:03,840] Trial 26 finished with value: 6.894026773159474 and parameters: {'learning_rate': 0.013221732472586699, 'max_depth': 3, 'n_estimators': 78, 'num_leaves': 78, 'min_child_weight': 0.004239310235229753}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:04,630] Trial 27 finished with value: 6.968083499373905 and parameters: {'learning_rate': 0.016514833504981168, 'max_depth': 6, 'n_estimators': 142, 'num_leaves': 64, 'min_child_weight': 0.027382844897810323}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:05,093] Trial 28 finished with value: 7.466458345814523 and parameters: {'learning_rate': 0.03622090779831205, 'max_depth': 4, 'n_estimators': 173, 'num_leaves': 84, 'min_child_weight': 0.1896389288383034}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:06,229] Trial 29 finished with value: 6.862625890910685 and parameters: {'learning_rate': 0.012362699430243632, 'max_depth': -1, 'n_estimators': 117, 'num_leaves': 93, 'min_child_weight': 0.012940513460753613}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:08,968] Trial 30 finished with value: 7.866410275485563 and parameters: {'learning_rate': 0.019652873175016412, 'max_depth': -7, 'n_estimators': 294, 'num_leaves': 100, 'min_child_weight': 2.4700776330029575}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:09,382] Trial 31 finished with value: 6.826875411961514 and parameters: {'learning_rate': 0.014743203195713076, 'max_depth': 5, 'n_estimators': 103, 'num_leaves': 87, 'min_child_weight': 0.0042086915916134315}. Best is trial 21 with value: 6.803516635202825.\n",
      "[I 2024-08-20 22:50:09,793] Trial 32 finished with value: 6.798836285631294 and parameters: {'learning_rate': 0.015353880225895525, 'max_depth': 6, 'n_estimators': 65, 'num_leaves': 84, 'min_child_weight': 0.001967460777660418}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:10,199] Trial 33 finished with value: 6.853789272343026 and parameters: {'learning_rate': 0.012003503353692446, 'max_depth': 6, 'n_estimators': 62, 'num_leaves': 74, 'min_child_weight': 0.06616782241436561}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:10,694] Trial 34 finished with value: 6.946986654303106 and parameters: {'learning_rate': 0.0265344097391032, 'max_depth': 6, 'n_estimators': 86, 'num_leaves': 84, 'min_child_weight': 0.004088730992362326}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:10,955] Trial 35 finished with value: 6.933635778217533 and parameters: {'learning_rate': 0.03538310168679642, 'max_depth': 4, 'n_estimators': 69, 'num_leaves': 93, 'min_child_weight': 0.8485543506601338}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:11,203] Trial 36 finished with value: 7.010520155179177 and parameters: {'learning_rate': 0.017013393280808916, 'max_depth': 2, 'n_estimators': 86, 'num_leaves': 83, 'min_child_weight': 0.009609418874030407}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:12,330] Trial 37 finished with value: 7.750140722360967 and parameters: {'learning_rate': 0.02447696725078368, 'max_depth': -6, 'n_estimators': 207, 'num_leaves': 42, 'min_child_weight': 0.0031005157863316373}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:12,892] Trial 38 finished with value: 8.45600740024693 and parameters: {'learning_rate': 0.14315407710938968, 'max_depth': -4, 'n_estimators': 138, 'num_leaves': 22, 'min_child_weight': 0.02645087877097725}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:13,865] Trial 39 finished with value: 7.15429198469431 and parameters: {'learning_rate': 0.019096105409775344, 'max_depth': 7, 'n_estimators': 152, 'num_leaves': 77, 'min_child_weight': 0.00100561632709473}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:14,274] Trial 40 finished with value: 7.029516813397231 and parameters: {'learning_rate': 0.014588340921831621, 'max_depth': 3, 'n_estimators': 186, 'num_leaves': 57, 'min_child_weight': 0.40169622506499214}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:14,705] Trial 41 finished with value: 6.845686018079091 and parameters: {'learning_rate': 0.01475381234877656, 'max_depth': 5, 'n_estimators': 111, 'num_leaves': 87, 'min_child_weight': 0.0021331173277724827}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:15,100] Trial 42 finished with value: 6.868252521471516 and parameters: {'learning_rate': 0.01165420152949775, 'max_depth': 6, 'n_estimators': 60, 'num_leaves': 94, 'min_child_weight': 0.002082379481807033}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:15,433] Trial 43 finished with value: 7.802720761093776 and parameters: {'learning_rate': 0.0935425588536694, 'max_depth': 4, 'n_estimators': 106, 'num_leaves': 29, 'min_child_weight': 0.010181541101329815}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:15,901] Trial 44 finished with value: 6.906262469173957 and parameters: {'learning_rate': 0.01725555862899662, 'max_depth': 5, 'n_estimators': 126, 'num_leaves': 82, 'min_child_weight': 0.017483558289383045}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:16,156] Trial 45 finished with value: 7.227364562558587 and parameters: {'learning_rate': 0.014979253753861095, 'max_depth': 1, 'n_estimators': 94, 'num_leaves': 89, 'min_child_weight': 0.006916539547815551}. Best is trial 32 with value: 6.798836285631294.\n",
      "[I 2024-08-20 22:50:16,630] Trial 46 finished with value: 6.793690568540095 and parameters: {'learning_rate': 0.01986885465117927, 'max_depth': 7, 'n_estimators': 55, 'num_leaves': 96, 'min_child_weight': 0.9462420975164575}. Best is trial 46 with value: 6.793690568540095.\n",
      "[I 2024-08-20 22:50:17,085] Trial 47 finished with value: 6.781438849126512 and parameters: {'learning_rate': 0.020733060828031863, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 100, 'min_child_weight': 3.902665397048191}. Best is trial 47 with value: 6.781438849126512.\n",
      "[I 2024-08-20 22:50:17,559] Trial 48 finished with value: 6.7805816748962835 and parameters: {'learning_rate': 0.020984745980128887, 'max_depth': 7, 'n_estimators': 51, 'num_leaves': 98, 'min_child_weight': 4.403183114236106}. Best is trial 48 with value: 6.7805816748962835.\n",
      "[I 2024-08-20 22:50:18,057] Trial 49 finished with value: 6.84632344985036 and parameters: {'learning_rate': 0.033407030213374454, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 97, 'min_child_weight': 6.2648772696359005}. Best is trial 48 with value: 6.7805816748962835.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -62.134998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:50:18,529] A new study created in memory with name: no-name-a76b2519-af0a-429c-afae-eb920b5be9c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.1\n",
      "Best parameters for quantile 0.1: {'learning_rate': 0.020984745980128887, 'max_depth': 7, 'n_estimators': 51, 'num_leaves': 98, 'min_child_weight': 4.403183114236106, 'objective': 'quantile', 'alpha': 0.1}\n",
      "Starting optimization for quantile 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:50:19,499] Trial 0 finished with value: 12.029669494729848 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 12.029669494729848.\n",
      "[I 2024-08-20 22:50:19,719] Trial 1 finished with value: 11.650202532985052 and parameters: {'learning_rate': 0.0132931409149161, 'max_depth': 4, 'n_estimators': 57, 'num_leaves': 87, 'min_child_weight': 0.0035740044378413513}. Best is trial 1 with value: 11.650202532985052.\n",
      "[I 2024-08-20 22:50:20,530] Trial 2 finished with value: 11.924541065289096 and parameters: {'learning_rate': 0.1359219086466172, 'max_depth': 7, 'n_estimators': 142, 'num_leaves': 77, 'min_child_weight': 4.083417277105759}. Best is trial 1 with value: 11.650202532985052.\n",
      "[I 2024-08-20 22:50:22,042] Trial 3 finished with value: 12.047243567175956 and parameters: {'learning_rate': 0.06542845308361667, 'max_depth': -4, 'n_estimators': 190, 'num_leaves': 70, 'min_child_weight': 1.3890470470378051}. Best is trial 1 with value: 11.650202532985052.\n",
      "[I 2024-08-20 22:50:22,529] Trial 4 finished with value: 11.289110874169827 and parameters: {'learning_rate': 0.012778237287456572, 'max_depth': 5, 'n_estimators': 139, 'num_leaves': 24, 'min_child_weight': 1.218955382991164}. Best is trial 4 with value: 11.289110874169827.\n",
      "[I 2024-08-20 22:50:23,650] Trial 5 finished with value: 11.283179141960655 and parameters: {'learning_rate': 0.014072948970520041, 'max_depth': -1, 'n_estimators': 113, 'num_leaves': 91, 'min_child_weight': 0.0011137585913478674}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:24,260] Trial 6 finished with value: 11.671820413899106 and parameters: {'learning_rate': 0.1320916047917074, 'max_depth': -6, 'n_estimators': 56, 'num_leaves': 83, 'min_child_weight': 275.4895177747005}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:25,773] Trial 7 finished with value: 12.010599594462878 and parameters: {'learning_rate': 0.04583459222483216, 'max_depth': -2, 'n_estimators': 221, 'num_leaves': 63, 'min_child_weight': 7.642728377865499}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:26,189] Trial 8 finished with value: 11.365768449146056 and parameters: {'learning_rate': 0.026591579398187182, 'max_depth': -6, 'n_estimators': 97, 'num_leaves': 22, 'min_child_weight': 62.89285042117869}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:26,605] Trial 9 finished with value: 11.375463049076355 and parameters: {'learning_rate': 0.01851700509199821, 'max_depth': -4, 'n_estimators': 79, 'num_leaves': 31, 'min_child_weight': 0.44644667844818914}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:27,139] Trial 10 finished with value: 11.6191575972199 and parameters: {'learning_rate': 0.0266246902522595, 'max_depth': 1, 'n_estimators': 269, 'num_leaves': 44, 'min_child_weight': 0.04227448310941012}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:27,421] Trial 11 finished with value: 12.007858574254485 and parameters: {'learning_rate': 0.01077183310552574, 'max_depth': 1, 'n_estimators': 117, 'num_leaves': 98, 'min_child_weight': 0.10766687273926386}. Best is trial 5 with value: 11.283179141960655.\n",
      "[I 2024-08-20 22:50:27,905] Trial 12 finished with value: 11.262896978155366 and parameters: {'learning_rate': 0.016925405226028034, 'max_depth': 4, 'n_estimators': 181, 'num_leaves': 46, 'min_child_weight': 0.0011713738018955106}. Best is trial 12 with value: 11.262896978155366.\n",
      "[I 2024-08-20 22:50:28,347] Trial 13 finished with value: 11.209866409468384 and parameters: {'learning_rate': 0.020125476283354687, 'max_depth': 3, 'n_estimators': 205, 'num_leaves': 49, 'min_child_weight': 0.0011624902074807272}. Best is trial 13 with value: 11.209866409468384.\n",
      "[I 2024-08-20 22:50:28,836] Trial 14 finished with value: 11.25536559725129 and parameters: {'learning_rate': 0.02293706041286118, 'max_depth': 3, 'n_estimators': 234, 'num_leaves': 45, 'min_child_weight': 0.015855610254936647}. Best is trial 13 with value: 11.209866409468384.\n",
      "[I 2024-08-20 22:50:29,334] Trial 15 finished with value: 11.547571505504273 and parameters: {'learning_rate': 0.028809994806920553, 'max_depth': 2, 'n_estimators': 249, 'num_leaves': 47, 'min_child_weight': 0.019191100711411203}. Best is trial 13 with value: 11.209866409468384.\n",
      "[I 2024-08-20 22:50:30,519] Trial 16 finished with value: 11.971336257779202 and parameters: {'learning_rate': 0.0424727107073704, 'max_depth': 7, 'n_estimators': 290, 'num_leaves': 36, 'min_child_weight': 0.09659836849332629}. Best is trial 13 with value: 11.209866409468384.\n",
      "[I 2024-08-20 22:50:31,000] Trial 17 finished with value: 11.199698326465871 and parameters: {'learning_rate': 0.019025163862454994, 'max_depth': 3, 'n_estimators': 218, 'num_leaves': 55, 'min_child_weight': 0.008045911767297869}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:31,696] Trial 18 finished with value: 11.67352249216911 and parameters: {'learning_rate': 0.0333304468281455, 'max_depth': 5, 'n_estimators': 203, 'num_leaves': 56, 'min_child_weight': 0.0035041902970121643}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:33,284] Trial 19 finished with value: 12.228379118700111 and parameters: {'learning_rate': 0.06230280038879719, 'max_depth': 0, 'n_estimators': 212, 'num_leaves': 69, 'min_child_weight': 0.2725296956998718}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:33,649] Trial 20 finished with value: 11.385882269688715 and parameters: {'learning_rate': 0.020249409437963835, 'max_depth': 2, 'n_estimators': 164, 'num_leaves': 54, 'min_child_weight': 0.004952700882811698}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:34,136] Trial 21 finished with value: 11.229179136413403 and parameters: {'learning_rate': 0.021539716553198765, 'max_depth': 3, 'n_estimators': 234, 'num_leaves': 38, 'min_child_weight': 0.02061027543342962}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:34,969] Trial 22 finished with value: 11.493861130836239 and parameters: {'learning_rate': 0.017968391354884653, 'max_depth': 5, 'n_estimators': 254, 'num_leaves': 38, 'min_child_weight': 0.045410233763679836}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:35,585] Trial 23 finished with value: 11.210290485245695 and parameters: {'learning_rate': 0.010227147672171552, 'max_depth': 3, 'n_estimators': 292, 'num_leaves': 52, 'min_child_weight': 0.0015732338569087595}. Best is trial 17 with value: 11.199698326465871.\n",
      "[I 2024-08-20 22:50:37,099] Trial 24 finished with value: 11.117153088860864 and parameters: {'learning_rate': 0.01004426483679321, 'max_depth': 6, 'n_estimators': 299, 'num_leaves': 53, 'min_child_weight': 0.0010581180045247812}. Best is trial 24 with value: 11.117153088860864.\n",
      "[I 2024-08-20 22:50:38,527] Trial 25 finished with value: 11.431574933344875 and parameters: {'learning_rate': 0.01664291510121309, 'max_depth': 6, 'n_estimators': 270, 'num_leaves': 63, 'min_child_weight': 0.006273770616141203}. Best is trial 24 with value: 11.117153088860864.\n",
      "[I 2024-08-20 22:50:39,494] Trial 26 finished with value: 11.097237001491292 and parameters: {'learning_rate': 0.013147495589295465, 'max_depth': 6, 'n_estimators': 197, 'num_leaves': 51, 'min_child_weight': 0.002472267995761714}. Best is trial 26 with value: 11.097237001491292.\n",
      "[I 2024-08-20 22:50:40,391] Trial 27 finished with value: 11.082825116077718 and parameters: {'learning_rate': 0.01245851698584666, 'max_depth': 6, 'n_estimators': 177, 'num_leaves': 70, 'min_child_weight': 0.0026521843432747282}. Best is trial 27 with value: 11.082825116077718.\n",
      "[I 2024-08-20 22:50:41,300] Trial 28 finished with value: 11.083394665561189 and parameters: {'learning_rate': 0.012137624744591246, 'max_depth': 6, 'n_estimators': 179, 'num_leaves': 71, 'min_child_weight': 0.002546452615252793}. Best is trial 27 with value: 11.082825116077718.\n",
      "[I 2024-08-20 22:50:42,344] Trial 29 finished with value: 11.146126255884484 and parameters: {'learning_rate': 0.014540126937725285, 'max_depth': 7, 'n_estimators': 164, 'num_leaves': 69, 'min_child_weight': 0.05503848193439824}. Best is trial 27 with value: 11.082825116077718.\n",
      "[I 2024-08-20 22:50:43,331] Trial 30 finished with value: 11.070721449295226 and parameters: {'learning_rate': 0.012268799222343352, 'max_depth': 6, 'n_estimators': 165, 'num_leaves': 78, 'min_child_weight': 0.00325489193608351}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:44,253] Trial 31 finished with value: 11.106938900585332 and parameters: {'learning_rate': 0.011947358392509193, 'max_depth': 6, 'n_estimators': 163, 'num_leaves': 79, 'min_child_weight': 0.0032495211142668165}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:44,939] Trial 32 finished with value: 11.189459742645099 and parameters: {'learning_rate': 0.015213282494638715, 'max_depth': 5, 'n_estimators': 190, 'num_leaves': 74, 'min_child_weight': 0.009830093720407303}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:45,885] Trial 33 finished with value: 11.22222471391721 and parameters: {'learning_rate': 0.011874177005171677, 'max_depth': 7, 'n_estimators': 147, 'num_leaves': 62, 'min_child_weight': 0.002902552235741983}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:46,264] Trial 34 finished with value: 11.235876819850763 and parameters: {'learning_rate': 0.013058241712835228, 'max_depth': 4, 'n_estimators': 131, 'num_leaves': 85, 'min_child_weight': 0.01415084567091086}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:47,206] Trial 35 finished with value: 11.089214995003708 and parameters: {'learning_rate': 0.015067437137300434, 'max_depth': 6, 'n_estimators': 179, 'num_leaves': 74, 'min_child_weight': 0.002905251677174936}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:48,475] Trial 36 finished with value: 11.136873131198614 and parameters: {'learning_rate': 0.015678730492275344, 'max_depth': 7, 'n_estimators': 174, 'num_leaves': 76, 'min_child_weight': 11.543827937998179}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:49,108] Trial 37 finished with value: 11.86416108690077 and parameters: {'learning_rate': 0.07769241404246968, 'max_depth': 5, 'n_estimators': 178, 'num_leaves': 89, 'min_child_weight': 0.006315537949390099}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:50,296] Trial 38 finished with value: 11.28445842911925 and parameters: {'learning_rate': 0.011597673850921067, 'max_depth': -2, 'n_estimators': 133, 'num_leaves': 81, 'min_child_weight': 0.03182644858543469}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:50,704] Trial 39 finished with value: 11.257787854890365 and parameters: {'learning_rate': 0.01378365175470098, 'max_depth': 4, 'n_estimators': 152, 'num_leaves': 73, 'min_child_weight': 627.7852234871687}. Best is trial 30 with value: 11.070721449295226.\n",
      "[I 2024-08-20 22:50:51,365] Trial 40 finished with value: 11.061610714759066 and parameters: {'learning_rate': 0.022973594981773045, 'max_depth': 6, 'n_estimators': 118, 'num_leaves': 66, 'min_child_weight': 0.2060953359902168}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:52,184] Trial 41 finished with value: 11.337983963243406 and parameters: {'learning_rate': 0.02433246297657239, 'max_depth': 6, 'n_estimators': 154, 'num_leaves': 66, 'min_child_weight': 3.845425092524432}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:52,516] Trial 42 finished with value: 11.128503246760348 and parameters: {'learning_rate': 0.03388777551513824, 'max_depth': 5, 'n_estimators': 70, 'num_leaves': 59, 'min_child_weight': 0.4055357761384623}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:53,375] Trial 43 finished with value: 11.189045560554677 and parameters: {'learning_rate': 0.014762837032944499, 'max_depth': 7, 'n_estimators': 121, 'num_leaves': 70, 'min_child_weight': 0.17767856967564483}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:53,703] Trial 44 finished with value: 11.429682553994349 and parameters: {'learning_rate': 0.011499783667826459, 'max_depth': 4, 'n_estimators': 98, 'num_leaves': 78, 'min_child_weight': 47.303139956047794}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:54,689] Trial 45 finished with value: 11.169241894921848 and parameters: {'learning_rate': 0.016686813580168058, 'max_depth': 6, 'n_estimators': 187, 'num_leaves': 94, 'min_child_weight': 0.001973819361791227}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:55,308] Trial 46 finished with value: 11.188420942820414 and parameters: {'learning_rate': 0.012641198166266788, 'max_depth': 5, 'n_estimators': 172, 'num_leaves': 66, 'min_child_weight': 2.175743944411549}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:55,657] Trial 47 finished with value: 11.418974421566741 and parameters: {'learning_rate': 0.010039190567936798, 'max_depth': 4, 'n_estimators': 111, 'num_leaves': 83, 'min_child_weight': 0.0111109781132637}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:56,452] Trial 48 finished with value: 12.30925877361031 and parameters: {'learning_rate': 0.1216888136366592, 'max_depth': -5, 'n_estimators': 100, 'num_leaves': 71, 'min_child_weight': 0.8648173195289773}. Best is trial 40 with value: 11.061610714759066.\n",
      "[I 2024-08-20 22:50:57,613] Trial 49 finished with value: 11.876437557505934 and parameters: {'learning_rate': 0.04994889088439597, 'max_depth': 7, 'n_estimators': 195, 'num_leaves': 66, 'min_child_weight': 0.004848976144865173}. Best is trial 40 with value: 11.061610714759066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -39.060001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:50:58,370] A new study created in memory with name: no-name-dd0e564d-324c-4d7d-a13d-fd2c4fa232c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.2\n",
      "Best parameters for quantile 0.2: {'learning_rate': 0.022973594981773045, 'max_depth': 6, 'n_estimators': 118, 'num_leaves': 66, 'min_child_weight': 0.2060953359902168, 'objective': 'quantile', 'alpha': 0.2}\n",
      "Starting optimization for quantile 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:50:59,368] Trial 0 finished with value: 14.004421624016393 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 14.004421624016393.\n",
      "[I 2024-08-20 22:51:00,090] Trial 1 finished with value: 14.201041067409738 and parameters: {'learning_rate': 0.10474591851992678, 'max_depth': 6, 'n_estimators': 222, 'num_leaves': 22, 'min_child_weight': 4.138485164765027}. Best is trial 0 with value: 14.004421624016393.\n",
      "[I 2024-08-20 22:51:00,709] Trial 2 finished with value: 13.818772889939376 and parameters: {'learning_rate': 0.09605314657904916, 'max_depth': -4, 'n_estimators': 52, 'num_leaves': 99, 'min_child_weight': 37.11392186736983}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:02,051] Trial 3 finished with value: 14.011682167870491 and parameters: {'learning_rate': 0.05948043621178618, 'max_depth': -2, 'n_estimators': 226, 'num_leaves': 50, 'min_child_weight': 0.04013029398773754}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:02,309] Trial 4 finished with value: 14.835871918355215 and parameters: {'learning_rate': 0.015601010906117027, 'max_depth': 2, 'n_estimators': 103, 'num_leaves': 25, 'min_child_weight': 0.031024534216950124}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:03,782] Trial 5 finished with value: 13.997436443164588 and parameters: {'learning_rate': 0.11615564453641862, 'max_depth': 7, 'n_estimators': 266, 'num_leaves': 92, 'min_child_weight': 0.004959629738070736}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:04,904] Trial 6 finished with value: 13.884008788916216 and parameters: {'learning_rate': 0.08745521774306655, 'max_depth': -6, 'n_estimators': 212, 'num_leaves': 44, 'min_child_weight': 3.749796079293457}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:06,189] Trial 7 finished with value: 14.072261353629331 and parameters: {'learning_rate': 0.06986135030217626, 'max_depth': -1, 'n_estimators': 229, 'num_leaves': 46, 'min_child_weight': 0.92775317327917}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:06,493] Trial 8 finished with value: 13.912224381848683 and parameters: {'learning_rate': 0.07874402233253437, 'max_depth': 4, 'n_estimators': 96, 'num_leaves': 47, 'min_child_weight': 6.807659562624584}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:06,998] Trial 9 finished with value: 13.942637425278436 and parameters: {'learning_rate': 0.012256872037298633, 'max_depth': 6, 'n_estimators': 95, 'num_leaves': 47, 'min_child_weight': 6.9267616099866975}. Best is trial 2 with value: 13.818772889939376.\n",
      "[I 2024-08-20 22:51:07,352] Trial 10 finished with value: 13.530087888391542 and parameters: {'learning_rate': 0.030235271680599703, 'max_depth': -7, 'n_estimators': 53, 'num_leaves': 98, 'min_child_weight': 976.0622506053029}. Best is trial 10 with value: 13.530087888391542.\n",
      "[I 2024-08-20 22:51:07,712] Trial 11 finished with value: 13.587846207401402 and parameters: {'learning_rate': 0.029399508469440908, 'max_depth': -7, 'n_estimators': 52, 'num_leaves': 99, 'min_child_weight': 899.2900057041352}. Best is trial 10 with value: 13.530087888391542.\n",
      "[I 2024-08-20 22:51:08,091] Trial 12 finished with value: 13.808346489012836 and parameters: {'learning_rate': 0.024513060473048465, 'max_depth': -7, 'n_estimators': 50, 'num_leaves': 82, 'min_child_weight': 848.120866303336}. Best is trial 10 with value: 13.530087888391542.\n",
      "[I 2024-08-20 22:51:08,830] Trial 13 finished with value: 13.727779387770465 and parameters: {'learning_rate': 0.036846621991786295, 'max_depth': -5, 'n_estimators': 148, 'num_leaves': 81, 'min_child_weight': 971.4048872828415}. Best is trial 10 with value: 13.530087888391542.\n",
      "[I 2024-08-20 22:51:09,581] Trial 14 finished with value: 13.41922895623078 and parameters: {'learning_rate': 0.027300774104029746, 'max_depth': -7, 'n_estimators': 81, 'num_leaves': 78, 'min_child_weight': 111.57750234322594}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:10,622] Trial 15 finished with value: 13.834339871152542 and parameters: {'learning_rate': 0.047915982954833805, 'max_depth': -2, 'n_estimators': 122, 'num_leaves': 76, 'min_child_weight': 86.67911411668635}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:10,874] Trial 16 finished with value: 15.326182500323085 and parameters: {'learning_rate': 0.021531643019876263, 'max_depth': 1, 'n_estimators': 78, 'num_leaves': 71, 'min_child_weight': 77.57118133662522}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:12,553] Trial 17 finished with value: 13.526942970056833 and parameters: {'learning_rate': 0.018098761107658207, 'max_depth': -4, 'n_estimators': 175, 'num_leaves': 89, 'min_child_weight': 169.5572511179498}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:14,002] Trial 18 finished with value: 13.638243713963192 and parameters: {'learning_rate': 0.01790160282115291, 'max_depth': -3, 'n_estimators': 185, 'num_leaves': 67, 'min_child_weight': 0.44752162227768344}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:16,654] Trial 19 finished with value: 13.51505881936768 and parameters: {'learning_rate': 0.010056644848320554, 'max_depth': -5, 'n_estimators': 286, 'num_leaves': 88, 'min_child_weight': 139.94588537046357}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:18,831] Trial 20 finished with value: 13.68816912419475 and parameters: {'learning_rate': 0.012715916279734838, 'max_depth': -5, 'n_estimators': 299, 'num_leaves': 62, 'min_child_weight': 0.16244330575320082}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:21,515] Trial 21 finished with value: 13.478346957842765 and parameters: {'learning_rate': 0.010246337254845023, 'max_depth': -5, 'n_estimators': 277, 'num_leaves': 89, 'min_child_weight': 149.3805277389751}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:24,312] Trial 22 finished with value: 13.598149882938943 and parameters: {'learning_rate': 0.011219200411051978, 'max_depth': -6, 'n_estimators': 300, 'num_leaves': 86, 'min_child_weight': 22.793449194235603}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:26,562] Trial 23 finished with value: 13.507465355185683 and parameters: {'learning_rate': 0.010665445336920395, 'max_depth': -5, 'n_estimators': 263, 'num_leaves': 76, 'min_child_weight': 145.02926622735285}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:28,629] Trial 24 finished with value: 14.276684936083688 and parameters: {'learning_rate': 0.14174025441996888, 'max_depth': 0, 'n_estimators': 257, 'num_leaves': 75, 'min_child_weight': 234.59128338949756}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:30,720] Trial 25 finished with value: 13.65188315503808 and parameters: {'learning_rate': 0.013921890840545648, 'max_depth': -3, 'n_estimators': 254, 'num_leaves': 78, 'min_child_weight': 20.930067451717413}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:32,762] Trial 26 finished with value: 13.481942255036136 and parameters: {'learning_rate': 0.010002783850902851, 'max_depth': -6, 'n_estimators': 273, 'num_leaves': 67, 'min_child_weight': 252.14472737426973}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:34,157] Trial 27 finished with value: 13.518003787340998 and parameters: {'learning_rate': 0.016341988665046894, 'max_depth': -6, 'n_estimators': 187, 'num_leaves': 59, 'min_child_weight': 341.5845214677594}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:35,997] Trial 28 finished with value: 13.799896116367805 and parameters: {'learning_rate': 0.020485087574330988, 'max_depth': -7, 'n_estimators': 242, 'num_leaves': 68, 'min_child_weight': 0.001426130993851297}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:36,941] Trial 29 finished with value: 13.974930918572975 and parameters: {'learning_rate': 0.04445599000576319, 'max_depth': -4, 'n_estimators': 145, 'num_leaves': 55, 'min_child_weight': 54.154512519222244}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:38,198] Trial 30 finished with value: 13.68105511606305 and parameters: {'learning_rate': 0.014177555087285998, 'max_depth': -3, 'n_estimators': 277, 'num_leaves': 32, 'min_child_weight': 12.452654378785668}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:40,468] Trial 31 finished with value: 13.463339566782535 and parameters: {'learning_rate': 0.010596843545289043, 'max_depth': -5, 'n_estimators': 278, 'num_leaves': 73, 'min_child_weight': 352.6594987154345}. Best is trial 14 with value: 13.41922895623078.\n",
      "[I 2024-08-20 22:51:42,012] Trial 32 finished with value: 13.399298047834252 and parameters: {'learning_rate': 0.010006021142719887, 'max_depth': -6, 'n_estimators': 205, 'num_leaves': 64, 'min_child_weight': 313.47497809080005}. Best is trial 32 with value: 13.399298047834252.\n",
      "[I 2024-08-20 22:51:43,739] Trial 33 finished with value: 13.338703792583955 and parameters: {'learning_rate': 0.012422009726324238, 'max_depth': -5, 'n_estimators': 204, 'num_leaves': 93, 'min_child_weight': 462.119911388544}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:45,206] Trial 34 finished with value: 13.438689154583416 and parameters: {'learning_rate': 0.013140611814951042, 'max_depth': -2, 'n_estimators': 199, 'num_leaves': 63, 'min_child_weight': 412.41665961861844}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:46,710] Trial 35 finished with value: 13.786767042480475 and parameters: {'learning_rate': 0.026805224808966733, 'max_depth': -1, 'n_estimators': 207, 'num_leaves': 61, 'min_child_weight': 423.4492432004554}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:47,637] Trial 36 finished with value: 13.513231525071294 and parameters: {'learning_rate': 0.014517197266832276, 'max_depth': -2, 'n_estimators': 171, 'num_leaves': 39, 'min_child_weight': 42.4076172704524}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:48,053] Trial 37 finished with value: 14.12748491173036 and parameters: {'learning_rate': 0.021237242007079934, 'max_depth': 2, 'n_estimators': 201, 'num_leaves': 57, 'min_child_weight': 2.0348672512783788}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:49,605] Trial 38 finished with value: 13.496468648019182 and parameters: {'learning_rate': 0.01215941436869992, 'max_depth': -4, 'n_estimators': 235, 'num_leaves': 52, 'min_child_weight': 489.5070390553711}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:51,080] Trial 39 finished with value: 13.428361571260309 and parameters: {'learning_rate': 0.016545860604936246, 'max_depth': -6, 'n_estimators': 133, 'num_leaves': 93, 'min_child_weight': 20.976807509120906}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:52,410] Trial 40 finished with value: 13.426290108711733 and parameters: {'learning_rate': 0.016897473295700727, 'max_depth': -6, 'n_estimators': 126, 'num_leaves': 92, 'min_child_weight': 22.026860473570807}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:53,750] Trial 41 finished with value: 13.441027237919469 and parameters: {'learning_rate': 0.016838921455526658, 'max_depth': -6, 'n_estimators': 126, 'num_leaves': 93, 'min_child_weight': 16.831730760286202}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:55,075] Trial 42 finished with value: 13.556882733407535 and parameters: {'learning_rate': 0.02469212267061425, 'max_depth': -7, 'n_estimators': 126, 'num_leaves': 95, 'min_child_weight': 38.55292248160061}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:55,827] Trial 43 finished with value: 13.504414145445189 and parameters: {'learning_rate': 0.034983089324178304, 'max_depth': -6, 'n_estimators': 72, 'num_leaves': 83, 'min_child_weight': 6.927600650831977}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:57,017] Trial 44 finished with value: 13.425079325431811 and parameters: {'learning_rate': 0.018989825554657863, 'max_depth': -7, 'n_estimators': 111, 'num_leaves': 95, 'min_child_weight': 2.6514363965649825}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:58,294] Trial 45 finished with value: 13.42426878528503 and parameters: {'learning_rate': 0.019088367731935934, 'max_depth': -7, 'n_estimators': 109, 'num_leaves': 100, 'min_child_weight': 2.587115357928209}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:51:59,452] Trial 46 finished with value: 13.426661813556176 and parameters: {'learning_rate': 0.018923799966408923, 'max_depth': -7, 'n_estimators': 108, 'num_leaves': 99, 'min_child_weight': 0.7326359338199706}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:52:00,298] Trial 47 finished with value: 13.419864320998643 and parameters: {'learning_rate': 0.031901801641638985, 'max_depth': -7, 'n_estimators': 78, 'num_leaves': 97, 'min_child_weight': 2.5582325772009016}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:52:00,574] Trial 48 finished with value: 13.747915275325964 and parameters: {'learning_rate': 0.032264619148572975, 'max_depth': 4, 'n_estimators': 74, 'num_leaves': 86, 'min_child_weight': 0.046896895975210066}. Best is trial 33 with value: 13.338703792583955.\n",
      "[I 2024-08-20 22:52:01,572] Trial 49 finished with value: 13.816761947573958 and parameters: {'learning_rate': 0.05751154967859116, 'max_depth': -4, 'n_estimators': 94, 'num_leaves': 100, 'min_child_weight': 0.35886963723836496}. Best is trial 33 with value: 13.338703792583955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -25.070000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:52:03,403] A new study created in memory with name: no-name-752a4ce8-ebeb-407f-85f6-f1aacca00def\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.3\n",
      "Best parameters for quantile 0.3: {'learning_rate': 0.012422009726324238, 'max_depth': -5, 'n_estimators': 204, 'num_leaves': 93, 'min_child_weight': 462.119911388544, 'objective': 'quantile', 'alpha': 0.3}\n",
      "Starting optimization for quantile 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:52:04,428] Trial 0 finished with value: 14.962516316813058 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 14.962516316813058.\n",
      "[I 2024-08-20 22:52:05,843] Trial 1 finished with value: 14.918215167179138 and parameters: {'learning_rate': 0.016828036015074644, 'max_depth': -4, 'n_estimators': 276, 'num_leaves': 40, 'min_child_weight': 692.5481988650308}. Best is trial 1 with value: 14.918215167179138.\n",
      "[I 2024-08-20 22:52:06,258] Trial 2 finished with value: 15.431603492828755 and parameters: {'learning_rate': 0.016772392008403903, 'max_depth': -6, 'n_estimators': 72, 'num_leaves': 35, 'min_child_weight': 0.17905949337494032}. Best is trial 1 with value: 14.918215167179138.\n",
      "[I 2024-08-20 22:52:07,536] Trial 3 finished with value: 14.821232866449147 and parameters: {'learning_rate': 0.0298940296762154, 'max_depth': -2, 'n_estimators': 153, 'num_leaves': 73, 'min_child_weight': 0.054184359564715026}. Best is trial 3 with value: 14.821232866449147.\n",
      "[I 2024-08-20 22:52:09,421] Trial 4 finished with value: 14.780524967821835 and parameters: {'learning_rate': 0.0121145491664588, 'max_depth': -5, 'n_estimators': 297, 'num_leaves': 51, 'min_child_weight': 0.5310001526272361}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:10,239] Trial 5 finished with value: 14.799485759825686 and parameters: {'learning_rate': 0.029255980457825657, 'max_depth': 6, 'n_estimators': 175, 'num_leaves': 82, 'min_child_weight': 0.8632128851909294}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:10,850] Trial 6 finished with value: 14.90524967274873 and parameters: {'learning_rate': 0.14821756932723593, 'max_depth': 6, 'n_estimators': 131, 'num_leaves': 70, 'min_child_weight': 26.9117913825707}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:12,001] Trial 7 finished with value: 15.01260887909102 and parameters: {'learning_rate': 0.08560687563644967, 'max_depth': -4, 'n_estimators': 195, 'num_leaves': 48, 'min_child_weight': 63.52346233381756}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:13,038] Trial 8 finished with value: 14.870358224610413 and parameters: {'learning_rate': 0.043035332512927814, 'max_depth': -5, 'n_estimators': 124, 'num_leaves': 77, 'min_child_weight': 1.2680140966585867}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:14,173] Trial 9 finished with value: 14.846816796127856 and parameters: {'learning_rate': 0.016565004401718174, 'max_depth': -1, 'n_estimators': 205, 'num_leaves': 41, 'min_child_weight': 55.58117632019733}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:14,724] Trial 10 finished with value: 15.517436744256056 and parameters: {'learning_rate': 0.011115543057846965, 'max_depth': 2, 'n_estimators': 296, 'num_leaves': 20, 'min_child_weight': 0.001037595178130183}. Best is trial 4 with value: 14.780524967821835.\n",
      "[I 2024-08-20 22:52:16,283] Trial 11 finished with value: 14.671152450945861 and parameters: {'learning_rate': 0.03743153369003486, 'max_depth': 7, 'n_estimators': 241, 'num_leaves': 99, 'min_child_weight': 0.7474931200009012}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:16,811] Trial 12 finished with value: 15.130440878438765 and parameters: {'learning_rate': 0.05009026158229486, 'max_depth': 2, 'n_estimators': 250, 'num_leaves': 94, 'min_child_weight': 3.1410604514412963}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:17,296] Trial 13 finished with value: 15.10876368469668 and parameters: {'learning_rate': 0.011045253799165964, 'max_depth': 3, 'n_estimators': 236, 'num_leaves': 56, 'min_child_weight': 0.07548444057434829}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:18,788] Trial 14 finished with value: 14.749376372681988 and parameters: {'learning_rate': 0.061715026151504815, 'max_depth': 7, 'n_estimators': 247, 'num_leaves': 90, 'min_child_weight': 2.6449902174488957}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:20,262] Trial 15 finished with value: 14.802773370222729 and parameters: {'learning_rate': 0.06418238958313004, 'max_depth': 7, 'n_estimators': 242, 'num_leaves': 99, 'min_child_weight': 7.051170990476191}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:20,854] Trial 16 finished with value: 14.998924489871406 and parameters: {'learning_rate': 0.029440314419947496, 'max_depth': 4, 'n_estimators': 225, 'num_leaves': 88, 'min_child_weight': 10.170483239091569}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:21,603] Trial 17 finished with value: 14.92684669171456 and parameters: {'learning_rate': 0.06122885077048129, 'max_depth': 5, 'n_estimators': 258, 'num_leaves': 100, 'min_child_weight': 352.5238870525328}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:23,124] Trial 18 finished with value: 14.710806375224683 and parameters: {'learning_rate': 0.03358023074223666, 'max_depth': 7, 'n_estimators': 213, 'num_leaves': 88, 'min_child_weight': 0.013838959739789878}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:23,547] Trial 19 finished with value: 16.99062593131292 and parameters: {'learning_rate': 0.02351989279066494, 'max_depth': 1, 'n_estimators': 206, 'num_leaves': 83, 'min_child_weight': 0.0072211069690390215}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:23,828] Trial 20 finished with value: 15.128550812164205 and parameters: {'learning_rate': 0.02300743025350421, 'max_depth': 4, 'n_estimators': 79, 'num_leaves': 69, 'min_child_weight': 0.011624082148292275}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:25,451] Trial 21 finished with value: 14.75318954413722 and parameters: {'learning_rate': 0.039654408112776825, 'max_depth': 7, 'n_estimators': 268, 'num_leaves': 91, 'min_child_weight': 0.001000643271872204}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:26,841] Trial 22 finished with value: 14.773839210082059 and parameters: {'learning_rate': 0.055199802700148605, 'max_depth': 7, 'n_estimators': 226, 'num_leaves': 87, 'min_child_weight': 0.24542398860213124}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:27,470] Trial 23 finished with value: 14.867223664953883 and parameters: {'learning_rate': 0.076099010339484, 'max_depth': 5, 'n_estimators': 186, 'num_leaves': 94, 'min_child_weight': 0.029157170860818687}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:28,183] Trial 24 finished with value: 14.772395483451824 and parameters: {'learning_rate': 0.03731832694061966, 'max_depth': 5, 'n_estimators': 220, 'num_leaves': 79, 'min_child_weight': 2.511686457703688}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:29,385] Trial 25 finished with value: 14.862518829131698 and parameters: {'learning_rate': 0.04652691269804775, 'max_depth': 6, 'n_estimators': 274, 'num_leaves': 65, 'min_child_weight': 0.2808145568500773}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:29,951] Trial 26 finished with value: 14.977562649692453 and parameters: {'learning_rate': 0.10913472807168124, 'max_depth': 4, 'n_estimators': 207, 'num_leaves': 100, 'min_child_weight': 15.329644137954682}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:31,373] Trial 27 finished with value: 14.806412444260976 and parameters: {'learning_rate': 0.0696126686269782, 'max_depth': 7, 'n_estimators': 251, 'num_leaves': 86, 'min_child_weight': 3.1196063647329124}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:31,988] Trial 28 finished with value: 15.100548272184778 and parameters: {'learning_rate': 0.0348689610171301, 'max_depth': 3, 'n_estimators': 280, 'num_leaves': 92, 'min_child_weight': 137.5178869875978}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:32,732] Trial 29 finished with value: 14.901113323412114 and parameters: {'learning_rate': 0.10667557925514777, 'max_depth': 6, 'n_estimators': 163, 'num_leaves': 63, 'min_child_weight': 0.007490820313974082}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:34,730] Trial 30 finished with value: 14.834818880067454 and parameters: {'learning_rate': 0.022624418447050394, 'max_depth': 0, 'n_estimators': 233, 'num_leaves': 77, 'min_child_weight': 0.00315242416082611}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:36,399] Trial 31 finished with value: 14.758795329921023 and parameters: {'learning_rate': 0.04065195228553109, 'max_depth': 7, 'n_estimators': 264, 'num_leaves': 92, 'min_child_weight': 0.0016791951050159936}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:38,147] Trial 32 finished with value: 14.852423513300895 and parameters: {'learning_rate': 0.03393362448506341, 'max_depth': 7, 'n_estimators': 276, 'num_leaves': 90, 'min_child_weight': 0.025326916359795372}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:38,995] Trial 33 finished with value: 14.880639431896812 and parameters: {'learning_rate': 0.05231723554041275, 'max_depth': 5, 'n_estimators': 260, 'num_leaves': 95, 'min_child_weight': 0.003234164895464824}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:39,995] Trial 34 finished with value: 14.852262583798037 and parameters: {'learning_rate': 0.026422160645909777, 'max_depth': 6, 'n_estimators': 217, 'num_leaves': 82, 'min_child_weight': 0.14529891120703392}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:42,280] Trial 35 finished with value: 14.829214195846143 and parameters: {'learning_rate': 0.01828494728275972, 'max_depth': -7, 'n_estimators': 284, 'num_leaves': 74, 'min_child_weight': 0.0030906118622855373}. Best is trial 11 with value: 14.671152450945861.\n",
      "[I 2024-08-20 22:52:43,815] Trial 36 finished with value: 14.659187099616371 and parameters: {'learning_rate': 0.042140156115624945, 'max_depth': 7, 'n_estimators': 242, 'num_leaves': 97, 'min_child_weight': 0.5666469955622686}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:45,563] Trial 37 finished with value: 14.939250201467233 and parameters: {'learning_rate': 0.08692937164580575, 'max_depth': -2, 'n_estimators': 179, 'num_leaves': 97, 'min_child_weight': 0.6764481219287215}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:46,613] Trial 38 finished with value: 14.797102471786896 and parameters: {'learning_rate': 0.033279503890597265, 'max_depth': 6, 'n_estimators': 241, 'num_leaves': 86, 'min_child_weight': 1.4451976139833362}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:46,916] Trial 39 finished with value: 14.853093707074114 and parameters: {'learning_rate': 0.056565367468059534, 'max_depth': 5, 'n_estimators': 57, 'num_leaves': 97, 'min_child_weight': 0.4146029092808091}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:47,372] Trial 40 finished with value: 15.030957240823055 and parameters: {'learning_rate': 0.01940363035985725, 'max_depth': 3, 'n_estimators': 196, 'num_leaves': 82, 'min_child_weight': 0.10973470781087208}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:49,075] Trial 41 finished with value: 14.781152373882588 and parameters: {'learning_rate': 0.042181011230611784, 'max_depth': 7, 'n_estimators': 262, 'num_leaves': 90, 'min_child_weight': 0.03859219321339309}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:50,466] Trial 42 finished with value: 14.802072918018936 and parameters: {'learning_rate': 0.04434623721032171, 'max_depth': 6, 'n_estimators': 300, 'num_leaves': 94, 'min_child_weight': 4.76376602028876}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:51,964] Trial 43 finished with value: 14.719651578607555 and parameters: {'learning_rate': 0.03736983077216459, 'max_depth': 7, 'n_estimators': 243, 'num_leaves': 85, 'min_child_weight': 1.1847993888909287}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:52,772] Trial 44 finished with value: 15.01316477948726 and parameters: {'learning_rate': 0.026324347639490174, 'max_depth': 6, 'n_estimators': 247, 'num_leaves': 24, 'min_child_weight': 1.3692319597321068}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:53,414] Trial 45 finished with value: 15.002433260552744 and parameters: {'learning_rate': 0.04910414412770833, 'max_depth': 4, 'n_estimators': 232, 'num_leaves': 84, 'min_child_weight': 0.5836563853134876}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:54,663] Trial 46 finished with value: 14.71600643812482 and parameters: {'learning_rate': 0.031072065290465932, 'max_depth': 7, 'n_estimators': 215, 'num_leaves': 78, 'min_child_weight': 33.60216080992468}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:55,384] Trial 47 finished with value: 14.754039292670479 and parameters: {'learning_rate': 0.014023003714942247, 'max_depth': 5, 'n_estimators': 211, 'num_leaves': 72, 'min_child_weight': 32.13763494241605}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:56,459] Trial 48 finished with value: 14.972200934736243 and parameters: {'learning_rate': 0.031357899105053794, 'max_depth': -3, 'n_estimators': 197, 'num_leaves': 58, 'min_child_weight': 785.4370618846831}. Best is trial 36 with value: 14.659187099616371.\n",
      "[I 2024-08-20 22:52:57,428] Trial 49 finished with value: 14.761007305376744 and parameters: {'learning_rate': 0.028073312568862793, 'max_depth': 7, 'n_estimators': 162, 'num_leaves': 79, 'min_child_weight': 174.33842987656496}. Best is trial 36 with value: 14.659187099616371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -15.210000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:52:59,063] A new study created in memory with name: no-name-53e359aa-b8cb-4756-bc33-84e5f6ba58be\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.4\n",
      "Best parameters for quantile 0.4: {'learning_rate': 0.042140156115624945, 'max_depth': 7, 'n_estimators': 242, 'num_leaves': 97, 'min_child_weight': 0.5666469955622686, 'objective': 'quantile', 'alpha': 0.4}\n",
      "Starting optimization for quantile 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:53:00,064] Trial 0 finished with value: 15.082289585319067 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 15.082289585319067.\n",
      "[I 2024-08-20 22:53:00,285] Trial 1 finished with value: 15.157503515848875 and parameters: {'learning_rate': 0.04355989491509264, 'max_depth': 4, 'n_estimators': 55, 'num_leaves': 47, 'min_child_weight': 0.23469424828834948}. Best is trial 0 with value: 15.082289585319067.\n",
      "[I 2024-08-20 22:53:01,113] Trial 2 finished with value: 14.877584073255365 and parameters: {'learning_rate': 0.02313141349550808, 'max_depth': -4, 'n_estimators': 134, 'num_leaves': 50, 'min_child_weight': 114.79667287157966}. Best is trial 2 with value: 14.877584073255365.\n",
      "[I 2024-08-20 22:53:01,576] Trial 3 finished with value: 15.093490324969725 and parameters: {'learning_rate': 0.038889212409656426, 'max_depth': 3, 'n_estimators': 208, 'num_leaves': 60, 'min_child_weight': 0.3317498057575534}. Best is trial 2 with value: 14.877584073255365.\n",
      "[I 2024-08-20 22:53:03,487] Trial 4 finished with value: 14.842495725774116 and parameters: {'learning_rate': 0.021135234317400366, 'max_depth': 0, 'n_estimators': 218, 'num_leaves': 77, 'min_child_weight': 0.04858772939250694}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:03,981] Trial 5 finished with value: 15.217088325217032 and parameters: {'learning_rate': 0.025986101861877435, 'max_depth': 2, 'n_estimators': 267, 'num_leaves': 61, 'min_child_weight': 0.0016872947820104705}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:04,407] Trial 6 finished with value: 14.96902875420931 and parameters: {'learning_rate': 0.038657304799109386, 'max_depth': -2, 'n_estimators': 53, 'num_leaves': 56, 'min_child_weight': 39.639607473036996}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:04,729] Trial 7 finished with value: 15.114443589419677 and parameters: {'learning_rate': 0.04520552796639755, 'max_depth': 4, 'n_estimators': 106, 'num_leaves': 65, 'min_child_weight': 0.8063973215234479}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:04,989] Trial 8 finished with value: 15.224229499386329 and parameters: {'learning_rate': 0.056420784631636155, 'max_depth': 2, 'n_estimators': 105, 'num_leaves': 32, 'min_child_weight': 1.711712757526979}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:05,349] Trial 9 finished with value: 15.35189866925569 and parameters: {'learning_rate': 0.019179972023271343, 'max_depth': 5, 'n_estimators': 81, 'num_leaves': 44, 'min_child_weight': 0.0011877272522692972}. Best is trial 4 with value: 14.842495725774116.\n",
      "[I 2024-08-20 22:53:07,497] Trial 10 finished with value: 14.839557223885075 and parameters: {'learning_rate': 0.010340366136466737, 'max_depth': -7, 'n_estimators': 217, 'num_leaves': 92, 'min_child_weight': 0.028900750361016067}. Best is trial 10 with value: 14.839557223885075.\n",
      "[I 2024-08-20 22:53:09,748] Trial 11 finished with value: 14.830178747311052 and parameters: {'learning_rate': 0.010606999284302556, 'max_depth': -7, 'n_estimators': 223, 'num_leaves': 91, 'min_child_weight': 0.032527307192842365}. Best is trial 11 with value: 14.830178747311052.\n",
      "[I 2024-08-20 22:53:12,650] Trial 12 finished with value: 14.79540375487279 and parameters: {'learning_rate': 0.010514066450975927, 'max_depth': -7, 'n_estimators': 283, 'num_leaves': 97, 'min_child_weight': 0.018724168881641065}. Best is trial 12 with value: 14.79540375487279.\n",
      "[I 2024-08-20 22:53:15,522] Trial 13 finished with value: 14.763790154643766 and parameters: {'learning_rate': 0.010342118227016297, 'max_depth': -7, 'n_estimators': 285, 'num_leaves': 97, 'min_child_weight': 0.008151597961739239}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:18,521] Trial 14 finished with value: 14.768530573138463 and parameters: {'learning_rate': 0.01433485475262461, 'max_depth': -5, 'n_estimators': 299, 'num_leaves': 100, 'min_child_weight': 0.005217094167885958}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:20,360] Trial 15 finished with value: 14.887137385298551 and parameters: {'learning_rate': 0.015577825679784971, 'max_depth': 7, 'n_estimators': 294, 'num_leaves': 84, 'min_child_weight': 7.029594791370704}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:21,706] Trial 16 finished with value: 15.041754508000514 and parameters: {'learning_rate': 0.014716707253378147, 'max_depth': -4, 'n_estimators': 260, 'num_leaves': 76, 'min_child_weight': 812.8672096370666}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:24,400] Trial 17 finished with value: 14.781856549563589 and parameters: {'learning_rate': 0.015064960409846962, 'max_depth': -5, 'n_estimators': 248, 'num_leaves': 100, 'min_child_weight': 0.0025967199099878177}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:25,864] Trial 18 finished with value: 14.8773935361193 and parameters: {'learning_rate': 0.14872803079908367, 'max_depth': -1, 'n_estimators': 179, 'num_leaves': 75, 'min_child_weight': 0.006969152543695845}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:28,153] Trial 19 finished with value: 14.785803850357546 and parameters: {'learning_rate': 0.01371047700923745, 'max_depth': -5, 'n_estimators': 245, 'num_leaves': 86, 'min_child_weight': 0.12985223134602036}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:29,212] Trial 20 finished with value: 15.091941936632766 and parameters: {'learning_rate': 0.027674063786868344, 'max_depth': -2, 'n_estimators': 299, 'num_leaves': 21, 'min_child_weight': 0.005296729827285742}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:31,857] Trial 21 finished with value: 14.783192873968602 and parameters: {'learning_rate': 0.016054294366591136, 'max_depth': -5, 'n_estimators': 255, 'num_leaves': 100, 'min_child_weight': 0.0026649785996245927}. Best is trial 13 with value: 14.763790154643766.\n",
      "[I 2024-08-20 22:53:34,743] Trial 22 finished with value: 14.76353919014549 and parameters: {'learning_rate': 0.012898684892003466, 'max_depth': -6, 'n_estimators': 275, 'num_leaves': 100, 'min_child_weight': 0.0010049340302110202}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:37,373] Trial 23 finished with value: 14.76404988957227 and parameters: {'learning_rate': 0.012918675624813546, 'max_depth': -6, 'n_estimators': 277, 'num_leaves': 91, 'min_child_weight': 0.001047320545721658}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:39,220] Trial 24 finished with value: 14.817632906850196 and parameters: {'learning_rate': 0.012542440285977249, 'max_depth': -6, 'n_estimators': 192, 'num_leaves': 85, 'min_child_weight': 0.0014817522110384272}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:41,867] Trial 25 finished with value: 14.826105061865192 and parameters: {'learning_rate': 0.01815434378746226, 'max_depth': -3, 'n_estimators': 276, 'num_leaves': 92, 'min_child_weight': 0.0010894824956710699}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:43,810] Trial 26 finished with value: 14.841562281828878 and parameters: {'learning_rate': 0.030557491283292864, 'max_depth': -6, 'n_estimators': 238, 'num_leaves': 73, 'min_child_weight': 0.06313413819006079}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:46,410] Trial 27 finished with value: 14.793424256348299 and parameters: {'learning_rate': 0.012033424737878752, 'max_depth': -6, 'n_estimators': 272, 'num_leaves': 92, 'min_child_weight': 0.01264945987200371}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:48,353] Trial 28 finished with value: 14.893228017508166 and parameters: {'learning_rate': 0.07893939993751613, 'max_depth': -3, 'n_estimators': 236, 'num_leaves': 81, 'min_child_weight': 0.004236192472265442}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:50,500] Trial 29 finished with value: 14.845373417961484 and parameters: {'learning_rate': 0.018986483818297387, 'max_depth': -7, 'n_estimators': 281, 'num_leaves': 67, 'min_child_weight': 0.01042274118348272}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:52,130] Trial 30 finished with value: 14.961487161454043 and parameters: {'learning_rate': 0.011712555011071553, 'max_depth': -4, 'n_estimators': 152, 'num_leaves': 95, 'min_child_weight': 3.78304435319044}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:53:58,838] Trial 31 finished with value: 14.791624223640719 and parameters: {'learning_rate': 0.013158649230137629, 'max_depth': -6, 'n_estimators': 297, 'num_leaves': 88, 'min_child_weight': 0.004598033159295241}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:01,741] Trial 32 finished with value: 14.765003074806673 and parameters: {'learning_rate': 0.017068843567198143, 'max_depth': -5, 'n_estimators': 285, 'num_leaves': 100, 'min_child_weight': 0.011087378359726535}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:04,098] Trial 33 finished with value: 14.830975242279752 and parameters: {'learning_rate': 0.016855190102934743, 'max_depth': -3, 'n_estimators': 266, 'num_leaves': 81, 'min_child_weight': 0.001034579878805704}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:06,912] Trial 34 finished with value: 14.789763511728166 and parameters: {'learning_rate': 0.010436413061299742, 'max_depth': -6, 'n_estimators': 283, 'num_leaves': 95, 'min_child_weight': 0.08338279763595918}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:09,101] Trial 35 finished with value: 14.8777335659432 and parameters: {'learning_rate': 0.02267837621261171, 'max_depth': -5, 'n_estimators': 231, 'num_leaves': 89, 'min_child_weight': 0.01808124667886463}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:11,079] Trial 36 finished with value: 14.831013536677629 and parameters: {'learning_rate': 0.021361125749169922, 'max_depth': 0, 'n_estimators': 198, 'num_leaves': 96, 'min_child_weight': 0.0025600673637531696}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:13,329] Trial 37 finished with value: 14.79721245749365 and parameters: {'learning_rate': 0.012421601332199262, 'max_depth': -4, 'n_estimators': 256, 'num_leaves': 81, 'min_child_weight': 0.18940573446853431}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:15,582] Trial 38 finished with value: 14.880897717693532 and parameters: {'learning_rate': 0.02689994954936365, 'max_depth': -7, 'n_estimators': 286, 'num_leaves': 70, 'min_child_weight': 0.44590318533403756}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:16,417] Trial 39 finished with value: 14.97845700648432 and parameters: {'learning_rate': 0.03242993311845308, 'max_depth': -1, 'n_estimators': 148, 'num_leaves': 42, 'min_child_weight': 0.009608936213418916}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:18,138] Trial 40 finished with value: 14.911515547083111 and parameters: {'learning_rate': 0.06500406375051537, 'max_depth': -6, 'n_estimators': 267, 'num_leaves': 55, 'min_child_weight': 0.002574698997943116}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:21,222] Trial 41 finished with value: 14.789609706624777 and parameters: {'learning_rate': 0.01338367418323397, 'max_depth': -5, 'n_estimators': 300, 'num_leaves': 100, 'min_child_weight': 0.005921164365213158}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:24,043] Trial 42 finished with value: 14.801099243568451 and parameters: {'learning_rate': 0.01770619257715767, 'max_depth': -5, 'n_estimators': 288, 'num_leaves': 96, 'min_child_weight': 0.03465947339518648}. Best is trial 22 with value: 14.76353919014549.\n",
      "[I 2024-08-20 22:54:26,855] Trial 43 finished with value: 14.76134082842429 and parameters: {'learning_rate': 0.011344349142377447, 'max_depth': -7, 'n_estimators': 273, 'num_leaves': 100, 'min_child_weight': 0.002160989068218634}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:29,651] Trial 44 finished with value: 14.78992463791691 and parameters: {'learning_rate': 0.011581545378218363, 'max_depth': -7, 'n_estimators': 271, 'num_leaves': 94, 'min_child_weight': 0.0018701666700414645}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:32,140] Trial 45 finished with value: 14.785843235553426 and parameters: {'learning_rate': 0.011339398495665601, 'max_depth': -7, 'n_estimators': 249, 'num_leaves': 90, 'min_child_weight': 0.018118847125143004}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:32,634] Trial 46 finished with value: 18.284841755023724 and parameters: {'learning_rate': 0.01039651939223973, 'max_depth': 1, 'n_estimators': 262, 'num_leaves': 88, 'min_child_weight': 0.0033830954889107465}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:34,995] Trial 47 finished with value: 14.779511913013934 and parameters: {'learning_rate': 0.01954460200723856, 'max_depth': -6, 'n_estimators': 225, 'num_leaves': 98, 'min_child_weight': 0.001124483368551974}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:37,148] Trial 48 finished with value: 14.77837638773878 and parameters: {'learning_rate': 0.014444153056044583, 'max_depth': -4, 'n_estimators': 215, 'num_leaves': 92, 'min_child_weight': 21.250682199400103}. Best is trial 43 with value: 14.76134082842429.\n",
      "[I 2024-08-20 22:54:39,716] Trial 49 finished with value: 14.818698052564754 and parameters: {'learning_rate': 0.010106876634193114, 'max_depth': -7, 'n_estimators': 275, 'num_leaves': 84, 'min_child_weight': 0.008859717544233732}. Best is trial 43 with value: 14.76134082842429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -1.045065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:54:42,594] A new study created in memory with name: no-name-cbdc4065-6ee8-4a97-bcb5-0687fc5a29c3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.5\n",
      "Best parameters for quantile 0.5: {'learning_rate': 0.011344349142377447, 'max_depth': -7, 'n_estimators': 273, 'num_leaves': 100, 'min_child_weight': 0.002160989068218634, 'objective': 'quantile', 'alpha': 0.5}\n",
      "Starting optimization for quantile 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:54:43,623] Trial 0 finished with value: 14.266255308673873 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 14.266255308673873.\n",
      "[I 2024-08-20 22:54:45,049] Trial 1 finished with value: 14.205159499122246 and parameters: {'learning_rate': 0.08207180648200955, 'max_depth': -1, 'n_estimators': 155, 'num_leaves': 84, 'min_child_weight': 49.99523875444}. Best is trial 1 with value: 14.205159499122246.\n",
      "[I 2024-08-20 22:54:46,531] Trial 2 finished with value: 14.265273587710968 and parameters: {'learning_rate': 0.019587116600088456, 'max_depth': -4, 'n_estimators': 165, 'num_leaves': 79, 'min_child_weight': 0.006841890849599187}. Best is trial 1 with value: 14.205159499122246.\n",
      "[I 2024-08-20 22:54:47,119] Trial 3 finished with value: 14.544994001100484 and parameters: {'learning_rate': 0.014797519943230726, 'max_depth': -3, 'n_estimators': 94, 'num_leaves': 44, 'min_child_weight': 0.1568133358477376}. Best is trial 1 with value: 14.205159499122246.\n",
      "[I 2024-08-20 22:54:48,132] Trial 4 finished with value: 14.126759580426862 and parameters: {'learning_rate': 0.07372475088656313, 'max_depth': 7, 'n_estimators': 265, 'num_leaves': 32, 'min_child_weight': 0.0023732671035589467}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:48,847] Trial 5 finished with value: 14.635852585836847 and parameters: {'learning_rate': 0.01461328062604696, 'max_depth': -7, 'n_estimators': 84, 'num_leaves': 55, 'min_child_weight': 181.63011014548974}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:49,886] Trial 6 finished with value: 14.299626312214144 and parameters: {'learning_rate': 0.018379551820962046, 'max_depth': -2, 'n_estimators': 127, 'num_leaves': 74, 'min_child_weight': 1.1500068221351614}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:51,426] Trial 7 finished with value: 14.290648750497068 and parameters: {'learning_rate': 0.013933500366978508, 'max_depth': 0, 'n_estimators': 297, 'num_leaves': 42, 'min_child_weight': 0.003191052915899275}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:51,702] Trial 8 finished with value: 14.498596680613213 and parameters: {'learning_rate': 0.13026280955774958, 'max_depth': 2, 'n_estimators': 90, 'num_leaves': 28, 'min_child_weight': 0.019886391897800847}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:52,111] Trial 9 finished with value: 14.19869428103228 and parameters: {'learning_rate': 0.09722637330726656, 'max_depth': -3, 'n_estimators': 67, 'num_leaves': 39, 'min_child_weight': 1.8269250778727768}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:52,927] Trial 10 finished with value: 14.233405386113386 and parameters: {'learning_rate': 0.04508023251231643, 'max_depth': 7, 'n_estimators': 244, 'num_leaves': 23, 'min_child_weight': 10.789252556348552}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:53,912] Trial 11 finished with value: 14.135827981675208 and parameters: {'learning_rate': 0.05834569359854689, 'max_depth': 7, 'n_estimators': 231, 'num_leaves': 37, 'min_child_weight': 1.0067233065876005}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:54,797] Trial 12 finished with value: 14.219778124182119 and parameters: {'learning_rate': 0.05057524336444465, 'max_depth': 7, 'n_estimators': 222, 'num_leaves': 32, 'min_child_weight': 0.12035644554706981}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:55,369] Trial 13 finished with value: 14.41601422810263 and parameters: {'learning_rate': 0.030621997628530014, 'max_depth': 4, 'n_estimators': 228, 'num_leaves': 49, 'min_child_weight': 0.21767035080543057}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:56,062] Trial 14 finished with value: 14.219206853442563 and parameters: {'learning_rate': 0.07317265839760198, 'max_depth': 4, 'n_estimators': 281, 'num_leaves': 98, 'min_child_weight': 0.0010970707708185994}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:56,714] Trial 15 finished with value: 14.415962438224403 and parameters: {'learning_rate': 0.05620110870169615, 'max_depth': 5, 'n_estimators': 259, 'num_leaves': 20, 'min_child_weight': 854.747228747881}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:57,458] Trial 16 finished with value: 14.320388657133984 and parameters: {'learning_rate': 0.03153550741824399, 'max_depth': 6, 'n_estimators': 196, 'num_leaves': 34, 'min_child_weight': 6.290607886745012}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:57,913] Trial 17 finished with value: 14.427903757723268 and parameters: {'learning_rate': 0.0652406921063976, 'max_depth': 2, 'n_estimators': 203, 'num_leaves': 65, 'min_child_weight': 0.06766655963673958}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:58,484] Trial 18 finished with value: 14.566050784413452 and parameters: {'learning_rate': 0.14797944686979664, 'max_depth': 2, 'n_estimators': 281, 'num_leaves': 50, 'min_child_weight': 0.5494177818347998}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:59,149] Trial 19 finished with value: 14.375786240584864 and parameters: {'learning_rate': 0.03651211487369807, 'max_depth': 4, 'n_estimators': 265, 'num_leaves': 35, 'min_child_weight': 0.032203937970446135}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:54:59,866] Trial 20 finished with value: 14.335231791595595 and parameters: {'learning_rate': 0.023317825310186398, 'max_depth': 6, 'n_estimators': 205, 'num_leaves': 28, 'min_child_weight': 7.182929957440545}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:00,567] Trial 21 finished with value: 14.205155772574361 and parameters: {'learning_rate': 0.1006215276386554, 'max_depth': -5, 'n_estimators': 133, 'num_leaves': 40, 'min_child_weight': 1.501314963793833}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:01,479] Trial 22 finished with value: 14.249725245130868 and parameters: {'learning_rate': 0.09430197886749161, 'max_depth': 0, 'n_estimators': 185, 'num_leaves': 37, 'min_child_weight': 2.975371106643836}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:02,851] Trial 23 finished with value: 14.307178684821766 and parameters: {'learning_rate': 0.06209310221620841, 'max_depth': -7, 'n_estimators': 237, 'num_leaves': 48, 'min_child_weight': 18.9982892486816}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:03,138] Trial 24 finished with value: 15.681688987061134 and parameters: {'learning_rate': 0.010045178267572473, 'max_depth': 7, 'n_estimators': 51, 'num_leaves': 25, 'min_child_weight': 0.34561021762041233}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:03,339] Trial 25 finished with value: 16.17237201166592 and parameters: {'learning_rate': 0.12348705262649234, 'max_depth': 1, 'n_estimators': 52, 'num_leaves': 57, 'min_child_weight': 2.203802244553509}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:04,482] Trial 26 finished with value: 14.280105545666192 and parameters: {'learning_rate': 0.044140451183760816, 'max_depth': -5, 'n_estimators': 255, 'num_leaves': 31, 'min_child_weight': 57.77146875297684}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:05,199] Trial 27 finished with value: 14.223214489294792 and parameters: {'learning_rate': 0.07774399252331142, 'max_depth': 5, 'n_estimators': 220, 'num_leaves': 42, 'min_child_weight': 0.4874283916245086}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:05,523] Trial 28 finished with value: 14.45414586718029 and parameters: {'learning_rate': 0.11635530420683295, 'max_depth': 3, 'n_estimators': 121, 'num_leaves': 71, 'min_child_weight': 0.05005892619666586}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:06,616] Trial 29 finished with value: 14.158317310500443 and parameters: {'learning_rate': 0.09611654612060107, 'max_depth': -2, 'n_estimators': 178, 'num_leaves': 51, 'min_child_weight': 0.014120781464864274}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:07,942] Trial 30 finished with value: 14.259541146185247 and parameters: {'learning_rate': 0.06590890219430978, 'max_depth': -1, 'n_estimators': 178, 'num_leaves': 61, 'min_child_weight': 0.0012787751541400822}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:08,814] Trial 31 finished with value: 14.213117519220985 and parameters: {'learning_rate': 0.09742321765040232, 'max_depth': -3, 'n_estimators': 144, 'num_leaves': 51, 'min_child_weight': 0.010797762875690673}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:09,732] Trial 32 finished with value: 14.162548162693883 and parameters: {'learning_rate': 0.09001837228727361, 'max_depth': -2, 'n_estimators': 167, 'num_leaves': 45, 'min_child_weight': 0.003843359497210847}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:10,613] Trial 33 finished with value: 14.25638727930155 and parameters: {'learning_rate': 0.08320128910250066, 'max_depth': -1, 'n_estimators': 159, 'num_leaves': 45, 'min_child_weight': 0.003933815603054489}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:11,673] Trial 34 finished with value: 14.23963406255501 and parameters: {'learning_rate': 0.05466620946209719, 'max_depth': -2, 'n_estimators': 171, 'num_leaves': 54, 'min_child_weight': 0.002656485032393664}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:12,546] Trial 35 finished with value: 14.240410107568406 and parameters: {'learning_rate': 0.07871060400479622, 'max_depth': -4, 'n_estimators': 109, 'num_leaves': 65, 'min_child_weight': 0.010958562476684332}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:13,419] Trial 36 finished with value: 14.253057227132386 and parameters: {'learning_rate': 0.114882704704722, 'max_depth': -2, 'n_estimators': 150, 'num_leaves': 45, 'min_child_weight': 0.006202978404229689}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:14,768] Trial 37 finished with value: 14.138508480525452 and parameters: {'learning_rate': 0.08857277340657378, 'max_depth': 0, 'n_estimators': 193, 'num_leaves': 59, 'min_child_weight': 0.02384697529011729}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:16,453] Trial 38 finished with value: 14.166038422826665 and parameters: {'learning_rate': 0.07070050817621606, 'max_depth': 0, 'n_estimators': 190, 'num_leaves': 83, 'min_child_weight': 0.01909205404634105}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:16,883] Trial 39 finished with value: 14.323227097474517 and parameters: {'learning_rate': 0.1403317554353149, 'max_depth': 1, 'n_estimators': 212, 'num_leaves': 71, 'min_child_weight': 0.08998773661736605}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:17,941] Trial 40 finished with value: 14.21961412560826 and parameters: {'learning_rate': 0.11111708190378707, 'max_depth': 6, 'n_estimators': 241, 'num_leaves': 60, 'min_child_weight': 0.02740831762909974}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:19,139] Trial 41 finished with value: 14.165006913999402 and parameters: {'learning_rate': 0.08803105770581077, 'max_depth': -1, 'n_estimators': 169, 'num_leaves': 57, 'min_child_weight': 0.0023262890164787568}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:19,539] Trial 42 finished with value: 15.271334463893073 and parameters: {'learning_rate': 0.06081519638370133, 'max_depth': 1, 'n_estimators': 181, 'num_leaves': 53, 'min_child_weight': 0.009515179365226617}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:20,892] Trial 43 finished with value: 14.212371003998145 and parameters: {'learning_rate': 0.04863214595394798, 'max_depth': -4, 'n_estimators': 275, 'num_leaves': 38, 'min_child_weight': 0.005276553213917909}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:22,146] Trial 44 finished with value: 14.240300223583278 and parameters: {'learning_rate': 0.08814712525254023, 'max_depth': -2, 'n_estimators': 229, 'num_leaves': 45, 'min_child_weight': 0.0016575538785822002}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:23,446] Trial 45 finished with value: 14.32750680222976 and parameters: {'learning_rate': 0.10647846120718535, 'max_depth': -3, 'n_estimators': 293, 'num_leaves': 31, 'min_child_weight': 0.1892514269230766}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:24,937] Trial 46 finished with value: 14.177106344952897 and parameters: {'learning_rate': 0.07576444381757086, 'max_depth': -1, 'n_estimators': 250, 'num_leaves': 48, 'min_child_weight': 0.012836984981487975}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:25,790] Trial 47 finished with value: 14.359163604919548 and parameters: {'learning_rate': 0.06960365998713358, 'max_depth': -5, 'n_estimators': 212, 'num_leaves': 27, 'min_child_weight': 0.04103467955252906}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:26,358] Trial 48 finished with value: 14.284810901982004 and parameters: {'learning_rate': 0.055507843618177864, 'max_depth': 5, 'n_estimators': 161, 'num_leaves': 63, 'min_child_weight': 0.004824709859940119}. Best is trial 4 with value: 14.126759580426862.\n",
      "[I 2024-08-20 22:55:27,346] Trial 49 finished with value: 14.24850900087299 and parameters: {'learning_rate': 0.04252636663613323, 'max_depth': 0, 'n_estimators': 195, 'num_leaves': 40, 'min_child_weight': 0.0024835680926723644}. Best is trial 4 with value: 14.126759580426862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 15.300011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:55:28,434] A new study created in memory with name: no-name-de5e69e5-6dac-44f9-b789-f67569513350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.6\n",
      "Best parameters for quantile 0.6: {'learning_rate': 0.07372475088656313, 'max_depth': 7, 'n_estimators': 265, 'num_leaves': 32, 'min_child_weight': 0.0023732671035589467, 'objective': 'quantile', 'alpha': 0.6}\n",
      "Starting optimization for quantile 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:55:29,479] Trial 0 finished with value: 12.861239099329934 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 12.861239099329934.\n",
      "[I 2024-08-20 22:55:29,844] Trial 1 finished with value: 12.86904076985223 and parameters: {'learning_rate': 0.11401157332381615, 'max_depth': 1, 'n_estimators': 196, 'num_leaves': 69, 'min_child_weight': 154.2992768563449}. Best is trial 0 with value: 12.861239099329934.\n",
      "[I 2024-08-20 22:55:30,301] Trial 2 finished with value: 12.860363460333263 and parameters: {'learning_rate': 0.0745442512124204, 'max_depth': -6, 'n_estimators': 55, 'num_leaves': 61, 'min_child_weight': 34.23423726083658}. Best is trial 2 with value: 12.860363460333263.\n",
      "[I 2024-08-20 22:55:30,476] Trial 3 finished with value: 15.188611784010327 and parameters: {'learning_rate': 0.011104570918459615, 'max_depth': 1, 'n_estimators': 53, 'num_leaves': 54, 'min_child_weight': 135.96011338284714}. Best is trial 2 with value: 12.860363460333263.\n",
      "[I 2024-08-20 22:55:30,907] Trial 4 finished with value: 12.949476660280144 and parameters: {'learning_rate': 0.05488835470487607, 'max_depth': 7, 'n_estimators': 99, 'num_leaves': 25, 'min_child_weight': 2.3122988861863054}. Best is trial 2 with value: 12.860363460333263.\n",
      "[I 2024-08-20 22:55:31,679] Trial 5 finished with value: 12.791828587891137 and parameters: {'learning_rate': 0.1311143252104359, 'max_depth': -4, 'n_estimators': 93, 'num_leaves': 72, 'min_child_weight': 36.15264628931357}. Best is trial 5 with value: 12.791828587891137.\n",
      "[I 2024-08-20 22:55:32,257] Trial 6 finished with value: 13.156551244084888 and parameters: {'learning_rate': 0.012811609669753511, 'max_depth': 6, 'n_estimators': 156, 'num_leaves': 26, 'min_child_weight': 980.2758983994283}. Best is trial 5 with value: 12.791828587891137.\n",
      "[I 2024-08-20 22:55:33,071] Trial 7 finished with value: 12.837356482085566 and parameters: {'learning_rate': 0.03169725120520237, 'max_depth': -3, 'n_estimators': 92, 'num_leaves': 80, 'min_child_weight': 228.65081152811905}. Best is trial 5 with value: 12.791828587891137.\n",
      "[I 2024-08-20 22:55:33,918] Trial 8 finished with value: 12.86167180277544 and parameters: {'learning_rate': 0.09363774371384864, 'max_depth': 5, 'n_estimators': 286, 'num_leaves': 79, 'min_child_weight': 0.0021691574256863795}. Best is trial 5 with value: 12.791828587891137.\n",
      "[I 2024-08-20 22:55:34,583] Trial 9 finished with value: 12.90295482263228 and parameters: {'learning_rate': 0.0628580985102474, 'max_depth': 4, 'n_estimators': 265, 'num_leaves': 68, 'min_child_weight': 0.017706204827262727}. Best is trial 5 with value: 12.791828587891137.\n",
      "[I 2024-08-20 22:55:36,804] Trial 10 finished with value: 12.730527133650968 and parameters: {'learning_rate': 0.028654003221508545, 'max_depth': -7, 'n_estimators': 205, 'num_leaves': 100, 'min_child_weight': 1.4329943346340968}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:39,112] Trial 11 finished with value: 12.748606465883729 and parameters: {'learning_rate': 0.023342381793831704, 'max_depth': -7, 'n_estimators': 225, 'num_leaves': 100, 'min_child_weight': 0.5096408746875432}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:41,353] Trial 12 finished with value: 12.745376109457927 and parameters: {'learning_rate': 0.022550461121117044, 'max_depth': -7, 'n_estimators': 224, 'num_leaves': 98, 'min_child_weight': 0.3795863239131994}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:43,643] Trial 13 finished with value: 12.77233082944382 and parameters: {'learning_rate': 0.019932343522449335, 'max_depth': -2, 'n_estimators': 231, 'num_leaves': 96, 'min_child_weight': 0.5085003149876587}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:45,417] Trial 14 finished with value: 12.790588560145988 and parameters: {'learning_rate': 0.038337095755131036, 'max_depth': -7, 'n_estimators': 194, 'num_leaves': 89, 'min_child_weight': 2.3079221964323353}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:46,846] Trial 15 finished with value: 12.846533255071257 and parameters: {'learning_rate': 0.018407934882604157, 'max_depth': -1, 'n_estimators': 240, 'num_leaves': 45, 'min_child_weight': 0.12362786550125876}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:49,580] Trial 16 finished with value: 12.76832443885003 and parameters: {'learning_rate': 0.028117619661287414, 'max_depth': -5, 'n_estimators': 300, 'num_leaves': 89, 'min_child_weight': 0.07726604315866714}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:51,405] Trial 17 finished with value: 12.831126854352108 and parameters: {'learning_rate': 0.014915655942361706, 'max_depth': -5, 'n_estimators': 184, 'num_leaves': 89, 'min_child_weight': 3.7642884962207295}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:51,767] Trial 18 finished with value: 12.927826882545395 and parameters: {'learning_rate': 0.04967263100266689, 'max_depth': 3, 'n_estimators': 148, 'num_leaves': 38, 'min_child_weight': 10.317473104705192}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:54,308] Trial 19 finished with value: 12.733226976636859 and parameters: {'learning_rate': 0.03344437179879464, 'max_depth': -7, 'n_estimators': 256, 'num_leaves': 99, 'min_child_weight': 0.12626613247870408}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:56,384] Trial 20 finished with value: 12.810530098575247 and parameters: {'learning_rate': 0.04253885044177863, 'max_depth': -1, 'n_estimators': 244, 'num_leaves': 82, 'min_child_weight': 0.05292403057124947}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:55:58,484] Trial 21 finished with value: 12.827032722316547 and parameters: {'learning_rate': 0.029296287014451146, 'max_depth': -7, 'n_estimators': 209, 'num_leaves': 100, 'min_child_weight': 0.2495466716976027}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:01,001] Trial 22 finished with value: 12.794141945473388 and parameters: {'learning_rate': 0.023020928989507628, 'max_depth': -5, 'n_estimators': 266, 'num_leaves': 91, 'min_child_weight': 1.0522145264661174}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:03,581] Trial 23 finished with value: 12.782736431892529 and parameters: {'learning_rate': 0.016317692980135728, 'max_depth': -6, 'n_estimators': 259, 'num_leaves': 94, 'min_child_weight': 0.021983693253341877}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:05,624] Trial 24 finished with value: 12.757232475148424 and parameters: {'learning_rate': 0.0363113524631781, 'max_depth': -3, 'n_estimators': 223, 'num_leaves': 84, 'min_child_weight': 7.334592183735294}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:07,422] Trial 25 finished with value: 12.78952616299458 and parameters: {'learning_rate': 0.024633802758721957, 'max_depth': -6, 'n_estimators': 172, 'num_leaves': 99, 'min_child_weight': 0.0024707282191432918}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:09,195] Trial 26 finished with value: 12.780839599866487 and parameters: {'learning_rate': 0.04429796820547601, 'max_depth': -7, 'n_estimators': 212, 'num_leaves': 75, 'min_child_weight': 0.17721388967965282}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:11,503] Trial 27 finished with value: 12.744940047192744 and parameters: {'learning_rate': 0.030825903855206102, 'max_depth': -4, 'n_estimators': 254, 'num_leaves': 86, 'min_child_weight': 0.8492030459763913}. Best is trial 10 with value: 12.730527133650968.\n",
      "[I 2024-08-20 22:56:13,878] Trial 28 finished with value: 12.685631646452048 and parameters: {'learning_rate': 0.06726909381637428, 'max_depth': -4, 'n_estimators': 276, 'num_leaves': 85, 'min_child_weight': 0.8375469702784957}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:15,748] Trial 29 finished with value: 12.779492644416154 and parameters: {'learning_rate': 0.07619430879803768, 'max_depth': -4, 'n_estimators': 274, 'num_leaves': 62, 'min_child_weight': 0.005319340559418632}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:18,344] Trial 30 finished with value: 12.782365142955403 and parameters: {'learning_rate': 0.05571702626292683, 'max_depth': -3, 'n_estimators': 286, 'num_leaves': 93, 'min_child_weight': 0.045819106177723244}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:20,570] Trial 31 finished with value: 12.73132035427569 and parameters: {'learning_rate': 0.032557497557695304, 'max_depth': -4, 'n_estimators': 247, 'num_leaves': 84, 'min_child_weight': 0.8544212086696824}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:22,554] Trial 32 finished with value: 12.762437288108739 and parameters: {'learning_rate': 0.035436324630390655, 'max_depth': -5, 'n_estimators': 247, 'num_leaves': 76, 'min_child_weight': 1.23172416013122}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:24,687] Trial 33 finished with value: 12.765529306194741 and parameters: {'learning_rate': 0.07102234350407345, 'max_depth': -2, 'n_estimators': 299, 'num_leaves': 66, 'min_child_weight': 9.646178929033823}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:25,229] Trial 34 finished with value: 12.993612187238154 and parameters: {'learning_rate': 0.04843778953494478, 'max_depth': 2, 'n_estimators': 281, 'num_leaves': 85, 'min_child_weight': 4.538577962061683}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:27,176] Trial 35 finished with value: 12.720446168106353 and parameters: {'learning_rate': 0.08781923120830752, 'max_depth': -6, 'n_estimators': 207, 'num_leaves': 92, 'min_child_weight': 19.794514520508308}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:29,062] Trial 36 finished with value: 12.71995714570227 and parameters: {'learning_rate': 0.09626201358689901, 'max_depth': -6, 'n_estimators': 197, 'num_leaves': 93, 'min_child_weight': 35.22529295104371}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:30,393] Trial 37 finished with value: 12.693291923017322 and parameters: {'learning_rate': 0.1496249782467922, 'max_depth': -6, 'n_estimators': 135, 'num_leaves': 94, 'min_child_weight': 30.32063931460086}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:31,257] Trial 38 finished with value: 12.780706162369805 and parameters: {'learning_rate': 0.13031691957290983, 'max_depth': -6, 'n_estimators': 129, 'num_leaves': 53, 'min_child_weight': 37.687609179640766}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:32,312] Trial 39 finished with value: 12.804285310605668 and parameters: {'learning_rate': 0.09938639277172884, 'max_depth': -5, 'n_estimators': 124, 'num_leaves': 73, 'min_child_weight': 90.01717840278111}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:33,605] Trial 40 finished with value: 12.808262259271006 and parameters: {'learning_rate': 0.14355118392670688, 'max_depth': -6, 'n_estimators': 164, 'num_leaves': 93, 'min_child_weight': 483.71432828482716}. Best is trial 28 with value: 12.685631646452048.\n",
      "[I 2024-08-20 22:56:35,566] Trial 41 finished with value: 12.670274528105077 and parameters: {'learning_rate': 0.08269958816586145, 'max_depth': -6, 'n_estimators': 199, 'num_leaves': 95, 'min_child_weight': 20.121004472302893}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:37,144] Trial 42 finished with value: 12.775777079766744 and parameters: {'learning_rate': 0.08508317044569723, 'max_depth': -6, 'n_estimators': 187, 'num_leaves': 79, 'min_child_weight': 22.8343980531317}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:38,664] Trial 43 finished with value: 12.714331542312983 and parameters: {'learning_rate': 0.11854745601262089, 'max_depth': -5, 'n_estimators': 148, 'num_leaves': 94, 'min_child_weight': 67.10469487669823}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:40,102] Trial 44 finished with value: 12.708661347987382 and parameters: {'learning_rate': 0.11267158660469355, 'max_depth': -4, 'n_estimators': 140, 'num_leaves': 88, 'min_child_weight': 93.04034341153685}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:40,619] Trial 45 finished with value: 12.971995638556956 and parameters: {'learning_rate': 0.11526467808823292, 'max_depth': -3, 'n_estimators': 136, 'num_leaves': 20, 'min_child_weight': 88.75380480616307}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:41,712] Trial 46 finished with value: 12.788344655831738 and parameters: {'learning_rate': 0.11420858139171668, 'max_depth': 0, 'n_estimators': 115, 'num_leaves': 87, 'min_child_weight': 270.5645793901865}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:42,629] Trial 47 finished with value: 12.847893467427513 and parameters: {'learning_rate': 0.1276853245693553, 'max_depth': -2, 'n_estimators': 104, 'num_leaves': 80, 'min_child_weight': 67.09304839423451}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:43,443] Trial 48 finished with value: 12.920749299194972 and parameters: {'learning_rate': 0.14954779446478164, 'max_depth': -4, 'n_estimators': 78, 'num_leaves': 97, 'min_child_weight': 172.18027128583518}. Best is trial 41 with value: 12.670274528105077.\n",
      "[I 2024-08-20 22:56:44,570] Trial 49 finished with value: 12.818517330429462 and parameters: {'learning_rate': 0.10649779573471524, 'max_depth': -4, 'n_estimators': 147, 'num_leaves': 96, 'min_child_weight': 515.0643561576567}. Best is trial 41 with value: 12.670274528105077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 29.510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:56:46,531] A new study created in memory with name: no-name-c6541272-2607-4faf-95c7-0e1ce8881e84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.7\n",
      "Best parameters for quantile 0.7: {'learning_rate': 0.08269958816586145, 'max_depth': -6, 'n_estimators': 199, 'num_leaves': 95, 'min_child_weight': 20.121004472302893, 'objective': 'quantile', 'alpha': 0.7}\n",
      "Starting optimization for quantile 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:56:47,548] Trial 0 finished with value: 10.515008506095658 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 10.515008506095658.\n",
      "[I 2024-08-20 22:56:48,024] Trial 1 finished with value: 10.539041468377071 and parameters: {'learning_rate': 0.12602401980692945, 'max_depth': 6, 'n_estimators': 97, 'num_leaves': 75, 'min_child_weight': 0.001034054586409475}. Best is trial 0 with value: 10.515008506095658.\n",
      "[I 2024-08-20 22:56:50,202] Trial 2 finished with value: 10.33282939977197 and parameters: {'learning_rate': 0.07105200322510033, 'max_depth': -2, 'n_estimators': 229, 'num_leaves': 97, 'min_child_weight': 0.7240698533113}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:51,518] Trial 3 finished with value: 10.403414403312096 and parameters: {'learning_rate': 0.01032852924019552, 'max_depth': -1, 'n_estimators': 218, 'num_leaves': 47, 'min_child_weight': 0.06873445390617434}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:52,068] Trial 4 finished with value: 10.583272196610222 and parameters: {'learning_rate': 0.05061931457818433, 'max_depth': 4, 'n_estimators': 222, 'num_leaves': 44, 'min_child_weight': 0.04630313575885933}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:53,479] Trial 5 finished with value: 10.462898712033002 and parameters: {'learning_rate': 0.02889151309275559, 'max_depth': -2, 'n_estimators': 230, 'num_leaves': 48, 'min_child_weight': 133.77819673322682}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:54,232] Trial 6 finished with value: 10.490921597015769 and parameters: {'learning_rate': 0.12750762464593274, 'max_depth': -3, 'n_estimators': 171, 'num_leaves': 34, 'min_child_weight': 0.021059426450773956}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:55,534] Trial 7 finished with value: 10.504387803561961 and parameters: {'learning_rate': 0.12160505484667009, 'max_depth': -6, 'n_estimators': 260, 'num_leaves': 43, 'min_child_weight': 14.252336013251831}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:57,079] Trial 8 finished with value: 10.516201371074043 and parameters: {'learning_rate': 0.03994646061828695, 'max_depth': -5, 'n_estimators': 238, 'num_leaves': 56, 'min_child_weight': 610.7867663071387}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:57,466] Trial 9 finished with value: 10.495340900000253 and parameters: {'learning_rate': 0.03707110665940532, 'max_depth': 3, 'n_estimators': 186, 'num_leaves': 30, 'min_child_weight': 0.024524002975401638}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:57,969] Trial 10 finished with value: 10.359984810207877 and parameters: {'learning_rate': 0.07523905662915523, 'max_depth': 1, 'n_estimators': 296, 'num_leaves': 94, 'min_child_weight': 1.6559150204391635}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:56:58,491] Trial 11 finished with value: 10.351533828324968 and parameters: {'learning_rate': 0.07568262563587279, 'max_depth': 1, 'n_estimators': 300, 'num_leaves': 100, 'min_child_weight': 1.9515065956303894}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:01,276] Trial 12 finished with value: 10.445081143922673 and parameters: {'learning_rate': 0.06543518004524994, 'max_depth': 0, 'n_estimators': 300, 'num_leaves': 100, 'min_child_weight': 1.3655761765635837}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:01,476] Trial 13 finished with value: 11.331371363879118 and parameters: {'learning_rate': 0.02270981353744159, 'max_depth': 2, 'n_estimators': 56, 'num_leaves': 84, 'min_child_weight': 16.69452030055143}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:03,023] Trial 14 finished with value: 10.504536019657156 and parameters: {'learning_rate': 0.07457222466654757, 'max_depth': 7, 'n_estimators': 271, 'num_leaves': 81, 'min_child_weight': 0.3601339567998202}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:05,001] Trial 15 finished with value: 10.432620400917777 and parameters: {'learning_rate': 0.05636241171526885, 'max_depth': -1, 'n_estimators': 266, 'num_leaves': 71, 'min_child_weight': 7.4570600702993115}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:05,375] Trial 16 finished with value: 10.594090833369453 and parameters: {'learning_rate': 0.0928245388001798, 'max_depth': 4, 'n_estimators': 125, 'num_leaves': 90, 'min_child_weight': 0.3150616040869651}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:07,287] Trial 17 finished with value: 10.364295416535391 and parameters: {'learning_rate': 0.017090695217673337, 'max_depth': -7, 'n_estimators': 193, 'num_leaves': 97, 'min_child_weight': 4.363513780278398}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:07,747] Trial 18 finished with value: 10.720049734974987 and parameters: {'learning_rate': 0.043093198847084874, 'max_depth': 1, 'n_estimators': 253, 'num_leaves': 69, 'min_child_weight': 47.453847802525914}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:09,562] Trial 19 finished with value: 10.441132194019387 and parameters: {'learning_rate': 0.08973843938465371, 'max_depth': -2, 'n_estimators': 204, 'num_leaves': 87, 'min_child_weight': 0.22965208570735876}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:12,229] Trial 20 finished with value: 10.407367157224495 and parameters: {'learning_rate': 0.03082881170971002, 'max_depth': -4, 'n_estimators': 281, 'num_leaves': 100, 'min_child_weight': 0.0036870773487052053}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:12,704] Trial 21 finished with value: 10.385952591070408 and parameters: {'learning_rate': 0.06888103007143179, 'max_depth': 1, 'n_estimators': 278, 'num_leaves': 92, 'min_child_weight': 1.1107778799238481}. Best is trial 2 with value: 10.33282939977197.\n",
      "[I 2024-08-20 22:57:13,220] Trial 22 finished with value: 10.331961339961843 and parameters: {'learning_rate': 0.07804262763291973, 'max_depth': 1, 'n_estimators': 299, 'num_leaves': 79, 'min_child_weight': 2.7701887189519883}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:13,729] Trial 23 finished with value: 10.514256712772212 and parameters: {'learning_rate': 0.05518692016124537, 'max_depth': 3, 'n_estimators': 247, 'num_leaves': 79, 'min_child_weight': 4.86531622996151}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:15,784] Trial 24 finished with value: 10.602410465548182 and parameters: {'learning_rate': 0.14946484840009025, 'max_depth': 0, 'n_estimators': 297, 'num_leaves': 67, 'min_child_weight': 0.19023567127346658}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:17,379] Trial 25 finished with value: 10.398663408360774 and parameters: {'learning_rate': 0.09270818492985704, 'max_depth': -2, 'n_estimators': 158, 'num_leaves': 88, 'min_child_weight': 83.68647838400021}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:18,255] Trial 26 finished with value: 10.4982940167675 and parameters: {'learning_rate': 0.0501383315022179, 'max_depth': 5, 'n_estimators': 280, 'num_leaves': 79, 'min_child_weight': 2.5505540726255362}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:18,732] Trial 27 finished with value: 10.611788527624359 and parameters: {'learning_rate': 0.079925171691439, 'max_depth': 2, 'n_estimators': 243, 'num_leaves': 94, 'min_child_weight': 0.49459131183022204}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:19,501] Trial 28 finished with value: 10.532506450796857 and parameters: {'learning_rate': 0.11010922227867856, 'max_depth': 0, 'n_estimators': 208, 'num_leaves': 21, 'min_child_weight': 27.32057721489881}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:20,807] Trial 29 finished with value: 10.37929962437262 and parameters: {'learning_rate': 0.06266323161927648, 'max_depth': -4, 'n_estimators': 145, 'num_leaves': 86, 'min_child_weight': 0.13234260552040786}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:22,857] Trial 30 finished with value: 10.349907971734513 and parameters: {'learning_rate': 0.10469648607193749, 'max_depth': -1, 'n_estimators': 282, 'num_leaves': 73, 'min_child_weight': 3.430079634617128}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:24,721] Trial 31 finished with value: 10.422642601863613 and parameters: {'learning_rate': 0.10223688380822606, 'max_depth': -1, 'n_estimators': 282, 'num_leaves': 58, 'min_child_weight': 0.6451838746653226}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:25,206] Trial 32 finished with value: 10.60987494950686 and parameters: {'learning_rate': 0.08584668198176042, 'max_depth': 2, 'n_estimators': 256, 'num_leaves': 64, 'min_child_weight': 2.669563856222672}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:27,408] Trial 33 finished with value: 10.36436593435909 and parameters: {'learning_rate': 0.13682547159754796, 'max_depth': -3, 'n_estimators': 300, 'num_leaves': 74, 'min_child_weight': 7.242489887145922}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:29,391] Trial 34 finished with value: 10.415456631102918 and parameters: {'learning_rate': 0.10586971060810808, 'max_depth': -1, 'n_estimators': 268, 'num_leaves': 76, 'min_child_weight': 0.8031420420672908}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:31,008] Trial 35 finished with value: 10.452956251582393 and parameters: {'learning_rate': 0.046749416768753646, 'max_depth': -3, 'n_estimators': 231, 'num_leaves': 63, 'min_child_weight': 0.08901412747045911}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:33,422] Trial 36 finished with value: 10.414577793422785 and parameters: {'learning_rate': 0.059364390589896704, 'max_depth': 0, 'n_estimators': 287, 'num_leaves': 83, 'min_child_weight': 15.492778130574484}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:35,511] Trial 37 finished with value: 10.414034386721294 and parameters: {'learning_rate': 0.11170331948555398, 'max_depth': -2, 'n_estimators': 223, 'num_leaves': 96, 'min_child_weight': 2.293139130641674}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:35,996] Trial 38 finished with value: 11.539548651092154 and parameters: {'learning_rate': 0.012392866189033958, 'max_depth': 1, 'n_estimators': 264, 'num_leaves': 55, 'min_child_weight': 456.1007811946057}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:36,538] Trial 39 finished with value: 10.47549682405468 and parameters: {'learning_rate': 0.03409805711455878, 'max_depth': 3, 'n_estimators': 240, 'num_leaves': 90, 'min_child_weight': 0.05433399187310531}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:38,215] Trial 40 finished with value: 10.458490331358789 and parameters: {'learning_rate': 0.0705230303572154, 'max_depth': -3, 'n_estimators': 285, 'num_leaves': 52, 'min_child_weight': 7.802050049211305}. Best is trial 22 with value: 10.331961339961843.\n",
      "[I 2024-08-20 22:57:38,731] Trial 41 finished with value: 10.310840608720353 and parameters: {'learning_rate': 0.08106290157696565, 'max_depth': 1, 'n_estimators': 294, 'num_leaves': 94, 'min_child_weight': 1.5987670769004885}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:41,391] Trial 42 finished with value: 10.50699499817087 and parameters: {'learning_rate': 0.11974428904721564, 'max_depth': 0, 'n_estimators': 291, 'num_leaves': 100, 'min_child_weight': 0.9841987993462361}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:43,824] Trial 43 finished with value: 10.448115322794395 and parameters: {'learning_rate': 0.07937564697332011, 'max_depth': -1, 'n_estimators': 274, 'num_leaves': 96, 'min_child_weight': 3.541085269529517}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:44,314] Trial 44 finished with value: 10.609967991664856 and parameters: {'learning_rate': 0.08289597699348901, 'max_depth': 2, 'n_estimators': 256, 'num_leaves': 75, 'min_child_weight': 1.3158628699158135}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:45,060] Trial 45 finished with value: 10.541127585038806 and parameters: {'learning_rate': 0.09763064203630403, 'max_depth': 4, 'n_estimators': 300, 'num_leaves': 92, 'min_child_weight': 0.5076619995019628}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:45,334] Trial 46 finished with value: 10.623591816731869 and parameters: {'learning_rate': 0.12395216348784063, 'max_depth': 1, 'n_estimators': 97, 'num_leaves': 86, 'min_child_weight': 9.683930146343114}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:47,698] Trial 47 finished with value: 10.405464894676683 and parameters: {'learning_rate': 0.06496849684488744, 'max_depth': -5, 'n_estimators': 270, 'num_leaves': 83, 'min_child_weight': 39.02402876242042}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:50,353] Trial 48 finished with value: 10.445876293559929 and parameters: {'learning_rate': 0.07460050466756776, 'max_depth': -1, 'n_estimators': 291, 'num_leaves': 96, 'min_child_weight': 0.028970687941460935}. Best is trial 41 with value: 10.310840608720353.\n",
      "[I 2024-08-20 22:57:50,724] Trial 49 finished with value: 10.57040398731162 and parameters: {'learning_rate': 0.05375948051663094, 'max_depth': 2, 'n_estimators': 176, 'num_leaves': 72, 'min_child_weight': 1.7553214892739009}. Best is trial 41 with value: 10.310840608720353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 47.090004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:57:51,285] A new study created in memory with name: no-name-eb899c23-f4ea-4c9e-a832-d786c302cc15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.8\n",
      "Best parameters for quantile 0.8: {'learning_rate': 0.08106290157696565, 'max_depth': 1, 'n_estimators': 294, 'num_leaves': 94, 'min_child_weight': 1.5987670769004885, 'objective': 'quantile', 'alpha': 0.8}\n",
      "Starting optimization for quantile 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 22:57:52,252] Trial 0 finished with value: 6.790076667062589 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 6.790076667062589.\n",
      "[I 2024-08-20 22:57:52,578] Trial 1 finished with value: 6.873680006648543 and parameters: {'learning_rate': 0.010178607954250936, 'max_depth': 3, 'n_estimators': 156, 'num_leaves': 94, 'min_child_weight': 149.4401417724866}. Best is trial 0 with value: 6.790076667062589.\n",
      "[I 2024-08-20 22:57:52,781] Trial 2 finished with value: 8.127920441847385 and parameters: {'learning_rate': 0.012011926413271142, 'max_depth': 1, 'n_estimators': 70, 'num_leaves': 30, 'min_child_weight': 704.8093115447183}. Best is trial 0 with value: 6.790076667062589.\n",
      "[I 2024-08-20 22:57:53,119] Trial 3 finished with value: 6.559260599767328 and parameters: {'learning_rate': 0.01593961001086031, 'max_depth': 3, 'n_estimators': 168, 'num_leaves': 39, 'min_child_weight': 6.776252253253197}. Best is trial 3 with value: 6.559260599767328.\n",
      "[I 2024-08-20 22:57:53,739] Trial 4 finished with value: 6.785993624787323 and parameters: {'learning_rate': 0.08108068248816139, 'max_depth': 5, 'n_estimators': 201, 'num_leaves': 58, 'min_child_weight': 0.23311549864457803}. Best is trial 3 with value: 6.559260599767328.\n",
      "[I 2024-08-20 22:57:54,474] Trial 5 finished with value: 6.43412866000197 and parameters: {'learning_rate': 0.01134738378690518, 'max_depth': 5, 'n_estimators': 222, 'num_leaves': 68, 'min_child_weight': 0.0583312531603817}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:54,711] Trial 6 finished with value: 6.7959924149849815 and parameters: {'learning_rate': 0.03444484065573664, 'max_depth': 2, 'n_estimators': 91, 'num_leaves': 25, 'min_child_weight': 523.3869821687375}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:55,099] Trial 7 finished with value: 6.677088933765322 and parameters: {'learning_rate': 0.04543393530075535, 'max_depth': 5, 'n_estimators': 104, 'num_leaves': 96, 'min_child_weight': 0.685526021661074}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:55,309] Trial 8 finished with value: 6.528610542329568 and parameters: {'learning_rate': 0.06812710554938872, 'max_depth': 4, 'n_estimators': 53, 'num_leaves': 77, 'min_child_weight': 140.32699227043975}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:56,862] Trial 9 finished with value: 6.745554358717257 and parameters: {'learning_rate': 0.03092567347725986, 'max_depth': -5, 'n_estimators': 263, 'num_leaves': 50, 'min_child_weight': 276.6712730556433}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:58,977] Trial 10 finished with value: 6.6724902732808316 and parameters: {'learning_rate': 0.020221838642523988, 'max_depth': -2, 'n_estimators': 279, 'num_leaves': 77, 'min_child_weight': 0.001155927435271265}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:57:59,930] Trial 11 finished with value: 6.738929720361683 and parameters: {'learning_rate': 0.062418361352437994, 'max_depth': 6, 'n_estimators': 228, 'num_leaves': 72, 'min_child_weight': 9.284291321022}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:01,131] Trial 12 finished with value: 6.858313205628459 and parameters: {'learning_rate': 0.1372480904873512, 'max_depth': 7, 'n_estimators': 225, 'num_leaves': 78, 'min_child_weight': 0.03949842566362332}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:01,651] Trial 13 finished with value: 6.726830885972416 and parameters: {'learning_rate': 0.02418637571181249, 'max_depth': 0, 'n_estimators': 52, 'num_leaves': 84, 'min_child_weight': 14.399906869461718}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:02,423] Trial 14 finished with value: 6.7073373368874645 and parameters: {'learning_rate': 0.052672475571756215, 'max_depth': -7, 'n_estimators': 107, 'num_leaves': 65, 'min_child_weight': 0.0833496233064814}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:02,798] Trial 15 finished with value: 6.773152853071391 and parameters: {'learning_rate': 0.0751279632990821, 'max_depth': 4, 'n_estimators': 131, 'num_leaves': 48, 'min_child_weight': 2.0190362052578625}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:04,513] Trial 16 finished with value: 6.856202575180212 and parameters: {'learning_rate': 0.13193206094258567, 'max_depth': -1, 'n_estimators': 191, 'num_leaves': 87, 'min_child_weight': 59.467824847008266}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:06,234] Trial 17 finished with value: 6.640928917132585 and parameters: {'learning_rate': 0.015536806559749554, 'max_depth': 7, 'n_estimators': 299, 'num_leaves': 69, 'min_child_weight': 0.005345704618444454}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:06,839] Trial 18 finished with value: 6.6766369006031265 and parameters: {'learning_rate': 0.02519175548503077, 'max_depth': 4, 'n_estimators': 243, 'num_leaves': 54, 'min_child_weight': 1.1533554032371813}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:07,211] Trial 19 finished with value: 6.753482918163061 and parameters: {'learning_rate': 0.048822563239258016, 'max_depth': 1, 'n_estimators': 200, 'num_leaves': 42, 'min_child_weight': 61.93406878972126}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:07,678] Trial 20 finished with value: 6.861081075712221 and parameters: {'learning_rate': 0.10306076021574338, 'max_depth': 5, 'n_estimators': 133, 'num_leaves': 86, 'min_child_weight': 0.185643849493953}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:08,051] Trial 21 finished with value: 6.526700106758633 and parameters: {'learning_rate': 0.015389082251741517, 'max_depth': 3, 'n_estimators': 181, 'num_leaves': 34, 'min_child_weight': 7.485103890899499}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:08,432] Trial 22 finished with value: 6.56051824592259 and parameters: {'learning_rate': 0.013891977988128065, 'max_depth': 3, 'n_estimators': 187, 'num_leaves': 20, 'min_child_weight': 52.983705325945735}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:08,838] Trial 23 finished with value: 7.085254878710454 and parameters: {'learning_rate': 0.010086790664838618, 'max_depth': 2, 'n_estimators': 218, 'num_leaves': 67, 'min_child_weight': 3.0082550768628344}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:09,832] Trial 24 finished with value: 6.651690740885078 and parameters: {'learning_rate': 0.019991842044531617, 'max_depth': 6, 'n_estimators': 244, 'num_leaves': 37, 'min_child_weight': 16.756557095200353}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:10,266] Trial 25 finished with value: 6.46330420180769 and parameters: {'learning_rate': 0.01923474370395139, 'max_depth': 4, 'n_estimators': 167, 'num_leaves': 75, 'min_child_weight': 0.02201213933377576}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:10,629] Trial 26 finished with value: 6.76999497587678 and parameters: {'learning_rate': 0.018323880397021697, 'max_depth': 2, 'n_estimators': 182, 'num_leaves': 61, 'min_child_weight': 0.02203503665829632}. Best is trial 5 with value: 6.43412866000197.\n",
      "[I 2024-08-20 22:58:11,351] Trial 27 finished with value: 6.411604519157104 and parameters: {'learning_rate': 0.013278437753410713, 'max_depth': 6, 'n_estimators': 160, 'num_leaves': 47, 'min_child_weight': 0.0031480771680520293}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:11,970] Trial 28 finished with value: 6.507592482566482 and parameters: {'learning_rate': 0.01256684656735379, 'max_depth': 6, 'n_estimators': 135, 'num_leaves': 43, 'min_child_weight': 0.0048466771856610705}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:12,865] Trial 29 finished with value: 6.597623657522222 and parameters: {'learning_rate': 0.026602103660857784, 'max_depth': 7, 'n_estimators': 156, 'num_leaves': 59, 'min_child_weight': 0.0016863972022037525}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:13,858] Trial 30 finished with value: 6.42327994801295 and parameters: {'learning_rate': 0.011734667987162573, 'max_depth': -3, 'n_estimators': 167, 'num_leaves': 52, 'min_child_weight': 0.008114610378293863}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:14,857] Trial 31 finished with value: 6.419338308759803 and parameters: {'learning_rate': 0.011953959266173418, 'max_depth': -3, 'n_estimators': 168, 'num_leaves': 50, 'min_child_weight': 0.01499003088291226}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:15,771] Trial 32 finished with value: 6.490662445087575 and parameters: {'learning_rate': 0.011665475117083601, 'max_depth': -3, 'n_estimators': 153, 'num_leaves': 47, 'min_child_weight': 0.008403194178408612}. Best is trial 27 with value: 6.411604519157104.\n",
      "[I 2024-08-20 22:58:17,123] Trial 33 finished with value: 6.353609454121512 and parameters: {'learning_rate': 0.011272377905062159, 'max_depth': -5, 'n_estimators': 209, 'num_leaves': 53, 'min_child_weight': 0.0029496004735900866}. Best is trial 33 with value: 6.353609454121512.\n",
      "[I 2024-08-20 22:58:18,389] Trial 34 finished with value: 6.337894225136524 and parameters: {'learning_rate': 0.013454360340447682, 'max_depth': -5, 'n_estimators': 205, 'num_leaves': 54, 'min_child_weight': 0.002593402641552295}. Best is trial 34 with value: 6.337894225136524.\n",
      "[I 2024-08-20 22:58:19,666] Trial 35 finished with value: 6.337587019182319 and parameters: {'learning_rate': 0.013758464267594389, 'max_depth': -5, 'n_estimators': 204, 'num_leaves': 54, 'min_child_weight': 0.0016650869738934794}. Best is trial 35 with value: 6.337587019182319.\n",
      "[I 2024-08-20 22:58:21,018] Trial 36 finished with value: 6.34457849254017 and parameters: {'learning_rate': 0.01466976355583151, 'max_depth': -6, 'n_estimators': 208, 'num_leaves': 57, 'min_child_weight': 0.00263773098569597}. Best is trial 35 with value: 6.337587019182319.\n",
      "[I 2024-08-20 22:58:22,349] Trial 37 finished with value: 6.453107499083899 and parameters: {'learning_rate': 0.017172163872820334, 'max_depth': -6, 'n_estimators': 209, 'num_leaves': 56, 'min_child_weight': 0.0024262247135629646}. Best is trial 35 with value: 6.337587019182319.\n",
      "[I 2024-08-20 22:58:23,958] Trial 38 finished with value: 6.458143364227431 and parameters: {'learning_rate': 0.014340605429187596, 'max_depth': -5, 'n_estimators': 242, 'num_leaves': 63, 'min_child_weight': 0.0014111386847147666}. Best is trial 35 with value: 6.337587019182319.\n",
      "[I 2024-08-20 22:58:25,370] Trial 39 finished with value: 6.410217458087469 and parameters: {'learning_rate': 0.016718221341483284, 'max_depth': -7, 'n_estimators': 206, 'num_leaves': 57, 'min_child_weight': 0.0028409587426747123}. Best is trial 35 with value: 6.337587019182319.\n",
      "[I 2024-08-20 22:58:26,803] Trial 40 finished with value: 6.336900996947795 and parameters: {'learning_rate': 0.010342248217853635, 'max_depth': -5, 'n_estimators': 266, 'num_leaves': 42, 'min_child_weight': 0.0952473066882487}. Best is trial 40 with value: 6.336900996947795.\n",
      "[I 2024-08-20 22:58:28,228] Trial 41 finished with value: 6.335304850156551 and parameters: {'learning_rate': 0.01061321502490367, 'max_depth': -5, 'n_estimators': 264, 'num_leaves': 43, 'min_child_weight': 0.004124348240572179}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:29,522] Trial 42 finished with value: 6.350684976203014 and parameters: {'learning_rate': 0.010603476543755829, 'max_depth': -4, 'n_estimators': 268, 'num_leaves': 31, 'min_child_weight': 0.0011162404638432597}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:30,904] Trial 43 finished with value: 6.478020530225796 and parameters: {'learning_rate': 0.013860187845018855, 'max_depth': -6, 'n_estimators': 260, 'num_leaves': 42, 'min_child_weight': 0.25789696005405666}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:32,358] Trial 44 finished with value: 6.353759841668061 and parameters: {'learning_rate': 0.010251319396078765, 'max_depth': -4, 'n_estimators': 292, 'num_leaves': 38, 'min_child_weight': 0.013245166160738658}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:34,190] Trial 45 finished with value: 6.706334913720489 and parameters: {'learning_rate': 0.022889507566743093, 'max_depth': -6, 'n_estimators': 281, 'num_leaves': 44, 'min_child_weight': 0.04283053858879131}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:35,164] Trial 46 finished with value: 6.762466322972177 and parameters: {'learning_rate': 0.04031608549231869, 'max_depth': -5, 'n_estimators': 235, 'num_leaves': 29, 'min_child_weight': 0.1050757312004478}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:37,483] Trial 47 finished with value: 6.392104225197293 and parameters: {'learning_rate': 0.0127220220531634, 'max_depth': -7, 'n_estimators': 257, 'num_leaves': 60, 'min_child_weight': 0.005121635177625649}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:38,832] Trial 48 finished with value: 6.758394073051393 and parameters: {'learning_rate': 0.029406468107895253, 'max_depth': -2, 'n_estimators': 275, 'num_leaves': 35, 'min_child_weight': 0.020749788503787274}. Best is trial 41 with value: 6.335304850156551.\n",
      "[I 2024-08-20 22:58:40,584] Trial 49 finished with value: 6.4936324789227235 and parameters: {'learning_rate': 0.015266764052545474, 'max_depth': -6, 'n_estimators': 251, 'num_leaves': 45, 'min_child_weight': 0.005912163471312008}. Best is trial 41 with value: 6.335304850156551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24863\n",
      "[LightGBM] [Info] Number of data points in the train set: 43906, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 74.910004\n",
      "Finished optimization for quantile 0.9\n",
      "Best parameters for quantile 0.9: {'learning_rate': 0.01061321502490367, 'max_depth': -5, 'n_estimators': 264, 'num_leaves': 43, 'min_child_weight': 0.004124348240572179, 'objective': 'quantile', 'alpha': 0.9}\n",
      "Last CV loss for quantile 0.1: 6.780581668037305\n",
      "Last CV loss for quantile 0.2: 11.061610703172434\n",
      "Last CV loss for quantile 0.3: 13.33870378623958\n",
      "Last CV loss for quantile 0.4: 14.65918709643453\n",
      "Last CV loss for quantile 0.5: 14.761340830757305\n",
      "Last CV loss for quantile 0.6: 14.126759588916896\n",
      "Last CV loss for quantile 0.7: 12.67027454288016\n",
      "Last CV loss for quantile 0.8: 10.31084062314175\n",
      "Last CV loss for quantile 0.9: 6.335304859515308\n"
     ]
    }
   ],
   "source": [
    "# Directory for saving models\n",
    "saved_models_dir = 'models/DAP'\n",
    "os.makedirs(saved_models_dir, exist_ok=True)\n",
    "\n",
    "# Quantiles for the models\n",
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "best_params_dict = {}\n",
    "best_models = {}\n",
    "\n",
    "# Function to compute pinball loss\n",
    "def pinball_loss(y_true, y_pred, alpha):\n",
    "    residuals = y_true - y_pred\n",
    "    return np.mean(np.maximum(alpha * residuals, (alpha - 1) * residuals))\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial, quantile, initial_params=None):\n",
    "    if initial_params:\n",
    "        params = initial_params\n",
    "    else:\n",
    "        params = {\n",
    "            'objective': 'quantile',\n",
    "            'alpha': quantile,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', -7, 7),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 1e3, log=True),\n",
    "            'verbose': -1\n",
    "        }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # Train on train_table and evaluate on cv_table\n",
    "    model.fit(train_table, train_target_variable)\n",
    "    preds = model.predict(cv_table)\n",
    "    \n",
    "    # Calculate pinball loss on the CV set\n",
    "    loss = pinball_loss(cv_target_variable, preds, alpha=quantile)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Train a model for each quantile with Optuna\n",
    "for quantile in quantiles:\n",
    "    print(f\"Starting optimization for quantile {quantile}\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # Initial parameters (from the ones you provided)\n",
    "    initial_params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': quantile,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': -4,\n",
    "        'n_estimators': 150,\n",
    "        'num_leaves': 60,\n",
    "        'min_child_weight': 1e-2,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Run the first trial with your initial parameters\n",
    "    study.enqueue_trial(initial_params)\n",
    "    \n",
    "    # Run further trials\n",
    "    study.optimize(lambda trial: objective(trial, quantile), n_trials=50)  # You can adjust the number of trials\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_params['objective'] = 'quantile'\n",
    "    best_params['alpha'] = quantile\n",
    "    \n",
    "    # Train the model with the best parameters\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        train_table, train_target_variable,\n",
    "        eval_set=[(cv_table, cv_target_variable)],\n",
    "        eval_metric='quantile'\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = f'{saved_models_dir}/DASS_Tuned_q{int(quantile * 100)}.txt'\n",
    "    model.booster_.save_model(model_path)\n",
    "    \n",
    "    # Store the best params and model\n",
    "    best_params_dict[quantile] = best_params\n",
    "    best_models[quantile] = model\n",
    "    \n",
    "    print(f\"Finished optimization for quantile {quantile}\")\n",
    "    print(f\"Best parameters for quantile {quantile}: {best_params}\")\n",
    "\n",
    "# Print the last training loss for each quantile after all models have been trained\n",
    "for quantile, model in best_models.items():\n",
    "    last_loss = model.evals_result_['valid_0']['quantile'][-1]\n",
    "    print(f\"Last CV loss for quantile {quantile}: {last_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.946356082387325\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DASS'] = train_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DASS_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(train_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DASS'))\n",
    "\n",
    "# Save the predictions (They might be used for ensemble learning)\n",
    "quantile_predictions_df['time'] = train_times  \n",
    "quantile_predictions_df.to_csv('data/TradingTrackData/DASS_train_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.526005750545346\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DASS'] = cv_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DASS_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(cv_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DASS'))\n",
    "\n",
    "quantile_predictions_df['time'] = cv_times  \n",
    "quantile_predictions_df.to_csv('data/TradingTrackData/DASS_cv_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.237183999525646\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DASS'] = test_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DASS_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(test_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DASS'))\n",
    "\n",
    "quantile_predictions_df['time'] = test_times  \n",
    "quantile_predictions_df.to_csv('data/TradingTrackData/DASS_test_set.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"plots/DAP/DASS_Plot.html\"\n",
    "graph_title = \"DAP-SSP Quantile Predictions\"\n",
    "quantile_predictions_df['time'] = test_times  \n",
    "plot_quantiles_target_and_average_loss_interactive(quantile_predictions_df, 'DASS', test_times, save_path, title=graph_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile_stats(quantile_predictions_df,'DASS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
