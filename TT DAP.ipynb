{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Ahead Price Forecasting\n",
    "Author: George Panagiotou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from comp_utils import *\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual=pd.read_csv('data/TradingTrackData/Actual_quantiles_cv_set.csv')\n",
    "Actual['time']=pd.to_datetime(Actual['time'])\n",
    "Actual.rename(columns={'time':'valid_time'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Train Table Shape: (50891, 81)\n"
     ]
    }
   ],
   "source": [
    "train_weather_feat = pd.read_hdf('data/DAP/train_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "train_weather_feat = train_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred = pd.read_csv('data/TradingTrackData/Demand_quantiles_train_set.csv')\n",
    "demand_pred.rename(columns={'time': 'valid_time'}, inplace=True)\n",
    "demand_pred['valid_time'] = pd.to_datetime(demand_pred['valid_time'], utc=True)\n",
    "demand_pred.drop(['ND'], axis=1, inplace=True)\n",
    "\n",
    "energy_data = pd.read_hdf(\"data/combined/train_energy_data_20200920_20240519.h5\", 'df')\n",
    "train_table = pd.merge(demand_pred, train_weather_feat, on='valid_time', how='left')\n",
    "train_table = pd.merge(train_table, energy_data, left_on='valid_time', right_on='dtm', how='left')\n",
    "train_table.dropna(inplace=True)\n",
    "\n",
    "# Define train_target_variable\n",
    "train_target_variable = train_table['DA_Price']\n",
    "# Apply IQR method to remove outliers from train_target_variable (DA_Price)\n",
    "Q1 = train_target_variable.quantile(0.25)\n",
    "Q3 = train_target_variable.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the dataset to remove rows with outliers in 'DA_Price'\n",
    "train_table = train_table[(train_target_variable >= lower_bound) & (train_target_variable <= upper_bound)]\n",
    "\n",
    "# Drop unnecessary columns after filtering\n",
    "train_times = train_table['valid_time']\n",
    "# Define train_target_variable\n",
    "train_target_variable = train_table['DA_Price']\n",
    "train_table.drop(['DA_Price', 'dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', \n",
    "                  'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', \n",
    "                  'Availability1', 'Availability2', 'Availability3'], axis=1, inplace=True)\n",
    "\n",
    "# Print the shape of the filtered dataset\n",
    "print(\"Filtered Train Table Shape:\", train_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5951, 81)\n",
      "CV Set Shape: (5951, 81)\n"
     ]
    }
   ],
   "source": [
    "train_weather_feat = pd.read_hdf('data/DAP/train_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "train_weather_feat = train_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred=pd.read_csv('data/TradingTrackData/Demand_quantiles_cv_set.csv')\n",
    "demand_pred.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "demand_pred['valid_time'] = pd.to_datetime(demand_pred['valid_time'], utc=True)\n",
    "demand_pred.drop(['ND'], axis=1, inplace=True)\n",
    "\n",
    "energy_data = pd.read_hdf(\"data/combined/train_energy_data_20200920_20240519.h5\",'df')\n",
    "cv_table = pd.merge(demand_pred, train_weather_feat, on='valid_time', how='left')\n",
    "cv_table = pd.merge(cv_table, energy_data, left_on='valid_time', right_on='dtm', how='left')\n",
    "cv_table.dropna(inplace=True)\n",
    "\n",
    "cv_times = cv_table['valid_time']\n",
    "cv_target_variable = cv_table['DA_Price']\n",
    "cv_table.drop(['DA_Price','dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', 'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', 'Availability1', 'Availability2', 'Availability3',], axis=1, inplace=True)\n",
    "print(cv_table.shape)\n",
    "print(\"CV Set Shape:\", cv_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4318, 10)\n",
      "(4318, 81)\n"
     ]
    }
   ],
   "source": [
    "test_weather_feat = pd.read_hdf('data/DAP/test_features.h5', 'df')\n",
    "columns_to_drop = [\n",
    "    'SS_Price', 'DA_Price', 'total_generation_MWh', 'ND', 'TSD', \n",
    "    'EMBEDDED_WIND_GENERATION', 'EMBEDDED_SOLAR_GENERATION', \n",
    "    'EMBEDDED_SOLAR_CAPACITY', 'EMBEDDED_WIND_CAPACITY', \n",
    "    'PUMP_STORAGE_PUMPING', 'q10', 'q20', 'q30', \n",
    "    'q40', 'q50', 'q60', 'q70', 'q80', 'q90'\n",
    "]\n",
    "test_weather_feat = test_weather_feat.drop(columns=columns_to_drop)\n",
    "\n",
    "demand_pred_test = pd.read_csv('data/Demand/Demand_predictions_test_set.csv')\n",
    "demand_pred_test.rename(columns={'time':'valid_time'}, inplace=True)\n",
    "demand_pred_test['valid_time'] = pd.to_datetime(demand_pred_test['valid_time'], utc=True)\n",
    "demand_pred_test.drop(['ND'], axis=1, inplace=True)\n",
    "print(demand_pred_test.shape)\n",
    "\n",
    "energy_data_test = pd.read_hdf(\"data/combined/test_energy_data_20200920_20240519.h5\",'df')\n",
    "\n",
    "test_table = pd.merge(demand_pred_test, test_weather_feat, on='valid_time', how='left')\n",
    "test_table = pd.merge(test_table, energy_data_test, left_on='valid_time', right_on='dtm', how='left')\n",
    "test_table.fillna(test_table.mean(), inplace=True)\n",
    "\n",
    "test_times = test_table['valid_time']\n",
    "test_target_variable = test_table['DA_Price']\n",
    "test_table.drop(['DA_Price','dtm', 'MIP', 'Solar_installedcapacity_mwp', 'Solar_MW', 'Solar_capacity_mwp', 'Wind_MW', 'SS_Price', 'boa_MWh', 'Availability1', 'Availability2', 'Availability3',], axis=1, inplace=True)\n",
    "print(test_table.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming time into cyclic features:\n",
    "We need to transform UTC datetime feature into numbers, thus we choose to convert datetime to cyclic features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features after adding cyclic times and removing valid_time: (50891, 89)\n",
      "CV features after adding cyclic times and removing valid_time: (5951, 89)\n",
      "Test features after adding cyclic times and removing valid_time: (4318, 89)\n"
     ]
    }
   ],
   "source": [
    "train_table = add_cyclic_features(train_table)\n",
    "train_table = train_table.drop(columns=[\"valid_time\"])\n",
    "print('Train features after adding cyclic times and removing valid_time:', train_table.shape)\n",
    "\n",
    "cv_table = add_cyclic_features(cv_table)\n",
    "cv_table = cv_table.drop(columns=[\"valid_time\"])\n",
    "print('CV features after adding cyclic times and removing valid_time:', cv_table.shape)\n",
    "\n",
    "test_table = add_cyclic_features(test_table)\n",
    "test_table = test_table.drop(columns=[\"valid_time\"])\n",
    "print('Test features after adding cyclic times and removing valid_time:', test_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:15:36,846] A new study created in memory with name: no-name-df3e5e19-2c3a-4551-b520-bc1d9767cad7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for quantile 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:15:37,890] Trial 0 finished with value: 7.010847222332562 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 7.010847222332562.\n",
      "[I 2024-08-20 20:15:38,746] Trial 1 finished with value: 5.617318412788926 and parameters: {'learning_rate': 0.08143456298013049, 'max_depth': -3, 'n_estimators': 188, 'num_leaves': 34, 'min_child_weight': 0.0017832921125738523}. Best is trial 1 with value: 5.617318412788926.\n",
      "[I 2024-08-20 20:15:39,231] Trial 2 finished with value: 4.723298530627986 and parameters: {'learning_rate': 0.02051386490954429, 'max_depth': 5, 'n_estimators': 142, 'num_leaves': 84, 'min_child_weight': 105.41848251940519}. Best is trial 2 with value: 4.723298530627986.\n",
      "[I 2024-08-20 20:15:39,482] Trial 3 finished with value: 3.929877899163394 and parameters: {'learning_rate': 0.08068449175415093, 'max_depth': 2, 'n_estimators': 112, 'num_leaves': 41, 'min_child_weight': 2.0913545703150236}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:39,854] Trial 4 finished with value: 3.9584499287729225 and parameters: {'learning_rate': 0.022258844130658234, 'max_depth': 4, 'n_estimators': 129, 'num_leaves': 62, 'min_child_weight': 0.07702769495196539}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:40,288] Trial 5 finished with value: 4.408651702609901 and parameters: {'learning_rate': 0.013877658846179815, 'max_depth': 5, 'n_estimators': 124, 'num_leaves': 25, 'min_child_weight': 205.2809213763823}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:42,612] Trial 6 finished with value: 5.756905410812633 and parameters: {'learning_rate': 0.019686937678129224, 'max_depth': -7, 'n_estimators': 263, 'num_leaves': 91, 'min_child_weight': 2.214897976405833}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:43,042] Trial 7 finished with value: 4.032953512164244 and parameters: {'learning_rate': 0.02080576148485519, 'max_depth': -4, 'n_estimators': 55, 'num_leaves': 61, 'min_child_weight': 0.09236869663469945}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:43,917] Trial 8 finished with value: 6.546806164264875 and parameters: {'learning_rate': 0.03284491682868277, 'max_depth': 5, 'n_estimators': 276, 'num_leaves': 51, 'min_child_weight': 23.42401289563936}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:44,961] Trial 9 finished with value: 5.072364067490934 and parameters: {'learning_rate': 0.01644704252469757, 'max_depth': 6, 'n_estimators': 273, 'num_leaves': 36, 'min_child_weight': 0.14307343590021884}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:45,154] Trial 10 finished with value: 4.413008633598707 and parameters: {'learning_rate': 0.147385528232677, 'max_depth': 1, 'n_estimators': 53, 'num_leaves': 44, 'min_child_weight': 4.175409165219831}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:45,399] Trial 11 finished with value: 4.001902217594962 and parameters: {'learning_rate': 0.0481875655491561, 'max_depth': 2, 'n_estimators': 99, 'num_leaves': 72, 'min_child_weight': 0.1981080916271879}. Best is trial 3 with value: 3.929877899163394.\n",
      "[I 2024-08-20 20:15:45,790] Trial 12 finished with value: 3.9272919856648576 and parameters: {'learning_rate': 0.04134193314122527, 'max_depth': 2, 'n_estimators': 197, 'num_leaves': 72, 'min_child_weight': 0.022768574684439172}. Best is trial 12 with value: 3.9272919856648576.\n",
      "[I 2024-08-20 20:15:47,405] Trial 13 finished with value: 6.335365909472366 and parameters: {'learning_rate': 0.045782324525020346, 'max_depth': -1, 'n_estimators': 201, 'num_leaves': 77, 'min_child_weight': 0.007027331666059435}. Best is trial 12 with value: 3.9272919856648576.\n",
      "[I 2024-08-20 20:15:47,817] Trial 14 finished with value: 3.7444159545085975 and parameters: {'learning_rate': 0.06715139566560084, 'max_depth': 2, 'n_estimators': 222, 'num_leaves': 97, 'min_child_weight': 0.8212893083870109}. Best is trial 14 with value: 3.7444159545085975.\n",
      "[I 2024-08-20 20:15:49,973] Trial 15 finished with value: 6.810068320607052 and parameters: {'learning_rate': 0.05610072268995851, 'max_depth': -1, 'n_estimators': 228, 'num_leaves': 100, 'min_child_weight': 0.014132143781707136}. Best is trial 14 with value: 3.7444159545085975.\n",
      "[I 2024-08-20 20:15:50,402] Trial 16 finished with value: 3.9179670726808826 and parameters: {'learning_rate': 0.03213876802812567, 'max_depth': 3, 'n_estimators': 227, 'num_leaves': 100, 'min_child_weight': 915.7079825927786}. Best is trial 14 with value: 3.7444159545085975.\n",
      "[I 2024-08-20 20:15:51,373] Trial 17 finished with value: 4.46614029258128 and parameters: {'learning_rate': 0.01101266946891515, 'max_depth': 7, 'n_estimators': 233, 'num_leaves': 95, 'min_child_weight': 789.2420053406842}. Best is trial 14 with value: 3.7444159545085975.\n",
      "[I 2024-08-20 20:15:53,809] Trial 18 finished with value: 6.4451455013409635 and parameters: {'learning_rate': 0.03059625127479533, 'max_depth': 0, 'n_estimators': 300, 'num_leaves': 86, 'min_child_weight': 17.47375656504571}. Best is trial 14 with value: 3.7444159545085975.\n",
      "[I 2024-08-20 20:15:54,254] Trial 19 finished with value: 3.595890550467074 and parameters: {'learning_rate': 0.06235204448573756, 'max_depth': 3, 'n_estimators': 228, 'num_leaves': 97, 'min_child_weight': 0.7307725242991207}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:55,758] Trial 20 finished with value: 7.023149820861857 and parameters: {'learning_rate': 0.06553113958980393, 'max_depth': -2, 'n_estimators': 172, 'num_leaves': 84, 'min_child_weight': 0.5518664098166025}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:56,195] Trial 21 finished with value: 4.017416624942843 and parameters: {'learning_rate': 0.028925397511281748, 'max_depth': 3, 'n_estimators': 227, 'num_leaves': 100, 'min_child_weight': 0.5575344551920616}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:56,746] Trial 22 finished with value: 4.715793356946473 and parameters: {'learning_rate': 0.11228817823101434, 'max_depth': 3, 'n_estimators': 248, 'num_leaves': 92, 'min_child_weight': 16.27995364464181}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:57,165] Trial 23 finished with value: 4.358551470083567 and parameters: {'learning_rate': 0.06077765593411066, 'max_depth': 1, 'n_estimators': 217, 'num_leaves': 100, 'min_child_weight': 5.889517768833016}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:57,622] Trial 24 finished with value: 4.008128315414765 and parameters: {'learning_rate': 0.07512029385009819, 'max_depth': 4, 'n_estimators': 168, 'num_leaves': 78, 'min_child_weight': 0.5816024673556615}. Best is trial 19 with value: 3.595890550467074.\n",
      "[I 2024-08-20 20:15:58,106] Trial 25 finished with value: 3.4731677285862697 and parameters: {'learning_rate': 0.03581018357843234, 'max_depth': 3, 'n_estimators': 248, 'num_leaves': 90, 'min_child_weight': 83.47811049867354}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:00,391] Trial 26 finished with value: 6.02729623302514 and parameters: {'learning_rate': 0.05125278186987154, 'max_depth': 0, 'n_estimators': 246, 'num_leaves': 89, 'min_child_weight': 139.06691494770038}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:02,124] Trial 27 finished with value: 6.016162494654803 and parameters: {'learning_rate': 0.0407580940288864, 'max_depth': 7, 'n_estimators': 297, 'num_leaves': 78, 'min_child_weight': 56.97453622856093}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:02,559] Trial 28 finished with value: 4.390842705043227 and parameters: {'learning_rate': 0.09907034271434773, 'max_depth': 1, 'n_estimators': 254, 'num_leaves': 94, 'min_child_weight': 1.6120493944791536}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:03,101] Trial 29 finished with value: 3.7887828026576162 and parameters: {'learning_rate': 0.11698851857096508, 'max_depth': 4, 'n_estimators': 209, 'num_leaves': 55, 'min_child_weight': 6.85863761823716}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:04,369] Trial 30 finished with value: 5.261530279127535 and parameters: {'learning_rate': 0.0643174660286205, 'max_depth': -6, 'n_estimators': 179, 'num_leaves': 67, 'min_child_weight': 0.0430918813458347}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:04,924] Trial 31 finished with value: 4.15171550499014 and parameters: {'learning_rate': 0.1489355427878356, 'max_depth': 4, 'n_estimators': 207, 'num_leaves': 55, 'min_child_weight': 6.886918487246853}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:05,355] Trial 32 finished with value: 3.8231607217722146 and parameters: {'learning_rate': 0.09652514109876104, 'max_depth': 3, 'n_estimators': 214, 'num_leaves': 51, 'min_child_weight': 36.923451167948635}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:06,057] Trial 33 finished with value: 6.049619872312375 and parameters: {'learning_rate': 0.11308328442055247, 'max_depth': 6, 'n_estimators': 185, 'num_leaves': 87, 'min_child_weight': 291.78106382694006}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:06,364] Trial 34 finished with value: 3.85007230147644 and parameters: {'learning_rate': 0.07832061569503697, 'max_depth': 2, 'n_estimators': 156, 'num_leaves': 81, 'min_child_weight': 9.619430065607306}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:06,961] Trial 35 finished with value: 3.8810057431857166 and parameters: {'learning_rate': 0.1203408785157803, 'max_depth': 4, 'n_estimators': 237, 'num_leaves': 94, 'min_child_weight': 0.339201943439399}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:08,367] Trial 36 finished with value: 5.974193413863798 and parameters: {'learning_rate': 0.025704043853717617, 'max_depth': 6, 'n_estimators': 282, 'num_leaves': 65, 'min_child_weight': 2.0620034875940396}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:09,238] Trial 37 finished with value: 5.105800149366104 and parameters: {'learning_rate': 0.09135217651962818, 'max_depth': 5, 'n_estimators': 259, 'num_leaves': 72, 'min_child_weight': 63.32686017638184}. Best is trial 25 with value: 3.4731677285862697.\n",
      "[I 2024-08-20 20:16:09,758] Trial 38 finished with value: 3.321702556172912 and parameters: {'learning_rate': 0.03820278709071215, 'max_depth': 4, 'n_estimators': 202, 'num_leaves': 56, 'min_child_weight': 0.0015288426571796125}. Best is trial 38 with value: 3.321702556172912.\n",
      "[I 2024-08-20 20:16:10,134] Trial 39 finished with value: 3.9641738350576734 and parameters: {'learning_rate': 0.035924862415263326, 'max_depth': 2, 'n_estimators': 193, 'num_leaves': 23, 'min_child_weight': 0.0021494746223759634}. Best is trial 38 with value: 3.321702556172912.\n",
      "[I 2024-08-20 20:16:10,460] Trial 40 finished with value: 4.624723440194418 and parameters: {'learning_rate': 0.024386897775012142, 'max_depth': 1, 'n_estimators': 159, 'num_leaves': 43, 'min_child_weight': 0.0036578215732470886}. Best is trial 38 with value: 3.321702556172912.\n",
      "[I 2024-08-20 20:16:11,024] Trial 41 finished with value: 3.212506164982489 and parameters: {'learning_rate': 0.036608481083625785, 'max_depth': 4, 'n_estimators': 218, 'num_leaves': 54, 'min_child_weight': 3.329314483655658}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:11,510] Trial 42 finished with value: 3.533956307870007 and parameters: {'learning_rate': 0.037320524396083576, 'max_depth': 3, 'n_estimators': 241, 'num_leaves': 47, 'min_child_weight': 1.0510710931262222}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:12,334] Trial 43 finished with value: 5.6252419038285595 and parameters: {'learning_rate': 0.03644342670320258, 'max_depth': 5, 'n_estimators': 239, 'num_leaves': 49, 'min_child_weight': 0.0010590920864346448}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:12,883] Trial 44 finished with value: 3.7863176961725302 and parameters: {'learning_rate': 0.04462638324577291, 'max_depth': 3, 'n_estimators': 262, 'num_leaves': 29, 'min_child_weight': 0.05871084269477332}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:13,551] Trial 45 finished with value: 3.2555725548073284 and parameters: {'learning_rate': 0.02782704314116579, 'max_depth': 4, 'n_estimators': 277, 'num_leaves': 57, 'min_child_weight': 0.15543313975267833}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:14,445] Trial 46 finished with value: 4.75604315159725 and parameters: {'learning_rate': 0.017707293905340555, 'max_depth': 5, 'n_estimators': 272, 'num_leaves': 57, 'min_child_weight': 0.2054581058175954}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:14,718] Trial 47 finished with value: 4.211454946429785 and parameters: {'learning_rate': 0.02707250562831137, 'max_depth': 4, 'n_estimators': 78, 'num_leaves': 37, 'min_child_weight': 1.3053664332637618}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:15,991] Trial 48 finished with value: 5.359585469668755 and parameters: {'learning_rate': 0.03647127164594723, 'max_depth': 6, 'n_estimators': 288, 'num_leaves': 48, 'min_child_weight': 3.1695415197742864}. Best is trial 41 with value: 3.212506164982489.\n",
      "[I 2024-08-20 20:16:16,983] Trial 49 finished with value: 4.8773869262275085 and parameters: {'learning_rate': 0.022854004089188508, 'max_depth': 5, 'n_estimators': 268, 'num_leaves': 59, 'min_child_weight': 0.01897567426391198}. Best is trial 41 with value: 3.212506164982489.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 46.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:16:17,596] A new study created in memory with name: no-name-9c0346bc-c2ad-4ac6-b28a-858d4a898c57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.1\n",
      "Best parameters for quantile 0.1: {'learning_rate': 0.036608481083625785, 'max_depth': 4, 'n_estimators': 218, 'num_leaves': 54, 'min_child_weight': 3.329314483655658, 'objective': 'quantile', 'alpha': 0.1}\n",
      "Starting optimization for quantile 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:16:18,634] Trial 0 finished with value: 9.051694623867775 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 9.051694623867775.\n",
      "[I 2024-08-20 20:16:19,175] Trial 1 finished with value: 7.200600414835646 and parameters: {'learning_rate': 0.09763353563457515, 'max_depth': 6, 'n_estimators': 112, 'num_leaves': 50, 'min_child_weight': 0.005370904479022393}. Best is trial 1 with value: 7.200600414835646.\n",
      "[I 2024-08-20 20:16:20,094] Trial 2 finished with value: 7.465015047378945 and parameters: {'learning_rate': 0.046508064392693726, 'max_depth': 6, 'n_estimators': 213, 'num_leaves': 50, 'min_child_weight': 0.4067195004710134}. Best is trial 1 with value: 7.200600414835646.\n",
      "[I 2024-08-20 20:16:20,831] Trial 3 finished with value: 7.738380545797435 and parameters: {'learning_rate': 0.13260766864023993, 'max_depth': -3, 'n_estimators': 97, 'num_leaves': 72, 'min_child_weight': 0.005638855113911698}. Best is trial 1 with value: 7.200600414835646.\n",
      "[I 2024-08-20 20:16:23,347] Trial 4 finished with value: 8.074283718309067 and parameters: {'learning_rate': 0.03293202342028517, 'max_depth': -2, 'n_estimators': 289, 'num_leaves': 78, 'min_child_weight': 460.53123879120824}. Best is trial 1 with value: 7.200600414835646.\n",
      "[I 2024-08-20 20:16:25,651] Trial 5 finished with value: 7.590112207260949 and parameters: {'learning_rate': 0.12487716132633375, 'max_depth': -2, 'n_estimators': 290, 'num_leaves': 77, 'min_child_weight': 8.976244999653924}. Best is trial 1 with value: 7.200600414835646.\n",
      "[I 2024-08-20 20:16:26,420] Trial 6 finished with value: 6.219739552810863 and parameters: {'learning_rate': 0.011458211175972132, 'max_depth': 5, 'n_estimators': 227, 'num_leaves': 46, 'min_child_weight': 0.4254061407284913}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:26,979] Trial 7 finished with value: 7.49246427828849 and parameters: {'learning_rate': 0.06561856314571049, 'max_depth': 4, 'n_estimators': 235, 'num_leaves': 93, 'min_child_weight': 0.05810625818989622}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:27,373] Trial 8 finished with value: 6.8010002039923725 and parameters: {'learning_rate': 0.06866804525172954, 'max_depth': 1, 'n_estimators': 212, 'num_leaves': 84, 'min_child_weight': 163.04389689169918}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:29,078] Trial 9 finished with value: 8.897615578679178 and parameters: {'learning_rate': 0.13999666561451946, 'max_depth': -2, 'n_estimators': 242, 'num_leaves': 60, 'min_child_weight': 393.9688314950596}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:29,273] Trial 10 finished with value: 8.084186922608545 and parameters: {'learning_rate': 0.010679614622892209, 'max_depth': 2, 'n_estimators': 56, 'num_leaves': 20, 'min_child_weight': 5.408900349632599}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:30,268] Trial 11 finished with value: 7.8882738253486435 and parameters: {'learning_rate': 0.01059316664767399, 'max_depth': -7, 'n_estimators': 185, 'num_leaves': 42, 'min_child_weight': 18.567831333125888}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:30,647] Trial 12 finished with value: 6.812540424027052 and parameters: {'learning_rate': 0.022955230326209258, 'max_depth': 2, 'n_estimators': 184, 'num_leaves': 98, 'min_child_weight': 0.3352942843846548}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:31,094] Trial 13 finished with value: 7.064944108112688 and parameters: {'learning_rate': 0.0185050513614466, 'max_depth': 1, 'n_estimators': 244, 'num_leaves': 30, 'min_child_weight': 53.23198519753434}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:32,103] Trial 14 finished with value: 7.490509491485575 and parameters: {'learning_rate': 0.05933906399112229, 'max_depth': 7, 'n_estimators': 141, 'num_leaves': 90, 'min_child_weight': 1.9980285875709975}. Best is trial 6 with value: 6.219739552810863.\n",
      "[I 2024-08-20 20:16:32,716] Trial 15 finished with value: 6.0065294366888295 and parameters: {'learning_rate': 0.03007972391457465, 'max_depth': 4, 'n_estimators': 211, 'num_leaves': 35, 'min_child_weight': 0.06348731421317239}. Best is trial 15 with value: 6.0065294366888295.\n",
      "[I 2024-08-20 20:16:33,363] Trial 16 finished with value: 6.008480384686633 and parameters: {'learning_rate': 0.01671801254794832, 'max_depth': 4, 'n_estimators': 269, 'num_leaves': 34, 'min_child_weight': 0.0746897778456546}. Best is trial 15 with value: 6.0065294366888295.\n",
      "[I 2024-08-20 20:16:34,866] Trial 17 finished with value: 6.601310047004391 and parameters: {'learning_rate': 0.022170081146637596, 'max_depth': 4, 'n_estimators': 274, 'num_leaves': 33, 'min_child_weight': 0.001156229210594657}. Best is trial 15 with value: 6.0065294366888295.\n",
      "[I 2024-08-20 20:16:35,392] Trial 18 finished with value: 5.419349528634506 and parameters: {'learning_rate': 0.031685369447438994, 'max_depth': 3, 'n_estimators': 258, 'num_leaves': 21, 'min_child_weight': 0.0555416301126125}. Best is trial 18 with value: 5.419349528634506.\n",
      "[I 2024-08-20 20:16:35,751] Trial 19 finished with value: 5.329484601405161 and parameters: {'learning_rate': 0.03368180849126191, 'max_depth': 3, 'n_estimators': 163, 'num_leaves': 23, 'min_child_weight': 0.049452989127047126}. Best is trial 19 with value: 5.329484601405161.\n",
      "[I 2024-08-20 20:16:36,369] Trial 20 finished with value: 8.79495047845455 and parameters: {'learning_rate': 0.039233309411679865, 'max_depth': 0, 'n_estimators': 161, 'num_leaves': 23, 'min_child_weight': 0.019719401886155303}. Best is trial 19 with value: 5.329484601405161.\n",
      "[I 2024-08-20 20:16:36,811] Trial 21 finished with value: 5.375117011182134 and parameters: {'learning_rate': 0.03126716350574981, 'max_depth': 3, 'n_estimators': 199, 'num_leaves': 28, 'min_child_weight': 0.06950090726432948}. Best is trial 19 with value: 5.329484601405161.\n",
      "[I 2024-08-20 20:16:37,160] Trial 22 finished with value: 6.718809017125596 and parameters: {'learning_rate': 0.029693718946808546, 'max_depth': 2, 'n_estimators': 183, 'num_leaves': 25, 'min_child_weight': 0.09878535663468731}. Best is trial 19 with value: 5.329484601405161.\n",
      "[I 2024-08-20 20:16:37,475] Trial 23 finished with value: 5.306578496752088 and parameters: {'learning_rate': 0.048161643942864533, 'max_depth': 3, 'n_estimators': 133, 'num_leaves': 27, 'min_child_weight': 0.019923438169941108}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:38,180] Trial 24 finished with value: 7.620353114753611 and parameters: {'learning_rate': 0.04627813515843536, 'max_depth': 0, 'n_estimators': 126, 'num_leaves': 40, 'min_child_weight': 0.0012758740032223046}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:38,427] Trial 25 finished with value: 5.55648436921261 and parameters: {'learning_rate': 0.05259878074689975, 'max_depth': 3, 'n_estimators': 89, 'num_leaves': 28, 'min_child_weight': 0.01881539461580038}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:39,146] Trial 26 finished with value: 7.355190602581732 and parameters: {'learning_rate': 0.038996772899570945, 'max_depth': 6, 'n_estimators': 169, 'num_leaves': 39, 'min_child_weight': 1.2153392683258533}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:39,440] Trial 27 finished with value: 6.8468865273045125 and parameters: {'learning_rate': 0.0779956039630775, 'max_depth': 1, 'n_estimators': 132, 'num_leaves': 60, 'min_child_weight': 0.21418913579779958}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:39,878] Trial 28 finished with value: 5.658810782530287 and parameters: {'learning_rate': 0.024255815613706728, 'max_depth': 3, 'n_estimators': 198, 'num_leaves': 30, 'min_child_weight': 0.0027651007647844232}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:40,921] Trial 29 finished with value: 7.886291284261534 and parameters: {'learning_rate': 0.0144215039366508, 'max_depth': -7, 'n_estimators': 150, 'num_leaves': 54, 'min_child_weight': 0.014668328042576154}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:41,693] Trial 30 finished with value: 7.768006666124453 and parameters: {'learning_rate': 0.08933807245815786, 'max_depth': -1, 'n_estimators': 158, 'num_leaves': 26, 'min_child_weight': 0.027164505474739437}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:42,265] Trial 31 finished with value: 5.709336076731455 and parameters: {'learning_rate': 0.03374854571698067, 'max_depth': 3, 'n_estimators': 260, 'num_leaves': 23, 'min_child_weight': 0.17101913001259467}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:42,723] Trial 32 finished with value: 7.088258492724139 and parameters: {'learning_rate': 0.02797144743101596, 'max_depth': 5, 'n_estimators': 113, 'num_leaves': 21, 'min_child_weight': 0.005775614692161383}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:43,420] Trial 33 finished with value: 7.504745285972897 and parameters: {'learning_rate': 0.04815462825732039, 'max_depth': 5, 'n_estimators': 200, 'num_leaves': 36, 'min_child_weight': 0.04130844822895538}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:43,880] Trial 34 finished with value: 7.794313617635913 and parameters: {'learning_rate': 0.037528059297036134, 'max_depth': 7, 'n_estimators': 95, 'num_leaves': 29, 'min_child_weight': 0.007962983499512067}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:44,127] Trial 35 finished with value: 5.87204033551411 and parameters: {'learning_rate': 0.0422703652114467, 'max_depth': 3, 'n_estimators': 73, 'num_leaves': 46, 'min_child_weight': 0.0025686497855733153}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:44,405] Trial 36 finished with value: 6.973249747111923 and parameters: {'learning_rate': 0.02639255070178009, 'max_depth': 2, 'n_estimators': 120, 'num_leaves': 68, 'min_child_weight': 0.8365180220886207}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:45,293] Trial 37 finished with value: 8.364947466337743 and parameters: {'learning_rate': 0.03394894084264314, 'max_depth': 6, 'n_estimators': 300, 'num_leaves': 21, 'min_child_weight': 0.14910145533550365}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:45,610] Trial 38 finished with value: 6.929843119358127 and parameters: {'learning_rate': 0.052768657299059475, 'max_depth': 1, 'n_estimators': 141, 'num_leaves': 51, 'min_child_weight': 0.03600357581333629}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:46,208] Trial 39 finished with value: 7.212238252838991 and parameters: {'learning_rate': 0.020759622544895853, 'max_depth': 5, 'n_estimators': 172, 'num_leaves': 32, 'min_child_weight': 0.011857159461374694}. Best is trial 23 with value: 5.306578496752088.\n",
      "[I 2024-08-20 20:16:46,722] Trial 40 finished with value: 5.014813927005119 and parameters: {'learning_rate': 0.03547318526315517, 'max_depth': 3, 'n_estimators': 226, 'num_leaves': 44, 'min_child_weight': 0.5034412361664726}. Best is trial 40 with value: 5.014813927005119.\n",
      "[I 2024-08-20 20:16:47,197] Trial 41 finished with value: 4.885855558056748 and parameters: {'learning_rate': 0.033479781468629656, 'max_depth': 3, 'n_estimators': 228, 'num_leaves': 44, 'min_child_weight': 0.445243986449614}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:47,781] Trial 42 finished with value: 6.391795091049837 and parameters: {'learning_rate': 0.043171580335745335, 'max_depth': 4, 'n_estimators': 229, 'num_leaves': 46, 'min_child_weight': 0.42073250936634915}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:48,183] Trial 43 finished with value: 6.5008105932832265 and parameters: {'learning_rate': 0.035653595970305096, 'max_depth': 2, 'n_estimators': 219, 'num_leaves': 66, 'min_child_weight': 1.0115453326697457}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:49,381] Trial 44 finished with value: 8.231462052246975 and parameters: {'learning_rate': 0.025938338324690235, 'max_depth': -4, 'n_estimators': 201, 'num_leaves': 43, 'min_child_weight': 4.918500356438687}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:51,010] Trial 45 finished with value: 7.610418686173315 and parameters: {'learning_rate': 0.058224393761672044, 'max_depth': -1, 'n_estimators': 245, 'num_leaves': 54, 'min_child_weight': 0.26298772487055444}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:51,464] Trial 46 finished with value: 5.241026633768247 and parameters: {'learning_rate': 0.06936590989501258, 'max_depth': 3, 'n_estimators': 218, 'num_leaves': 37, 'min_child_weight': 0.6479641034407552}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:51,892] Trial 47 finished with value: 5.895874103604238 and parameters: {'learning_rate': 0.07859465970027482, 'max_depth': 2, 'n_estimators': 213, 'num_leaves': 37, 'min_child_weight': 1.7310039595339621}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:52,528] Trial 48 finished with value: 6.3749773869644155 and parameters: {'learning_rate': 0.0697327646770351, 'max_depth': 4, 'n_estimators': 251, 'num_leaves': 45, 'min_child_weight': 3.16710356314405}. Best is trial 41 with value: 4.885855558056748.\n",
      "[I 2024-08-20 20:16:52,980] Trial 49 finished with value: 6.829816176875985 and parameters: {'learning_rate': 0.06055738515044221, 'max_depth': 1, 'n_estimators': 226, 'num_leaves': 56, 'min_child_weight': 0.66256070028785}. Best is trial 41 with value: 4.885855558056748.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 59.259998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:16:53,490] A new study created in memory with name: no-name-561b7fdd-7024-42a4-8e1e-cea087106b5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.2\n",
      "Best parameters for quantile 0.2: {'learning_rate': 0.033479781468629656, 'max_depth': 3, 'n_estimators': 228, 'num_leaves': 44, 'min_child_weight': 0.445243986449614, 'objective': 'quantile', 'alpha': 0.2}\n",
      "Starting optimization for quantile 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:16:54,500] Trial 0 finished with value: 7.870273413399211 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 7.870273413399211.\n",
      "[I 2024-08-20 20:16:55,911] Trial 1 finished with value: 9.615565857017213 and parameters: {'learning_rate': 0.04039363335057253, 'max_depth': -3, 'n_estimators': 184, 'num_leaves': 61, 'min_child_weight': 0.0021628240347034574}. Best is trial 0 with value: 7.870273413399211.\n",
      "[I 2024-08-20 20:16:56,937] Trial 2 finished with value: 8.91265948130552 and parameters: {'learning_rate': 0.01588540153708914, 'max_depth': 6, 'n_estimators': 225, 'num_leaves': 42, 'min_child_weight': 159.97403621355483}. Best is trial 0 with value: 7.870273413399211.\n",
      "[I 2024-08-20 20:16:57,236] Trial 3 finished with value: 7.104332577003056 and parameters: {'learning_rate': 0.04263483656795103, 'max_depth': 4, 'n_estimators': 92, 'num_leaves': 48, 'min_child_weight': 0.006428232559924056}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:16:58,660] Trial 4 finished with value: 10.249165389613143 and parameters: {'learning_rate': 0.09825548518424773, 'max_depth': -1, 'n_estimators': 231, 'num_leaves': 48, 'min_child_weight': 0.0013492868516072828}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:16:59,293] Trial 5 finished with value: 8.081461117198595 and parameters: {'learning_rate': 0.02340610098128443, 'max_depth': 7, 'n_estimators': 92, 'num_leaves': 65, 'min_child_weight': 0.12119515156143341}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:01,562] Trial 6 finished with value: 9.355061102609614 and parameters: {'learning_rate': 0.08126710431421548, 'max_depth': 0, 'n_estimators': 243, 'num_leaves': 92, 'min_child_weight': 0.03333404548090636}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:03,617] Trial 7 finished with value: 9.127707223839009 and parameters: {'learning_rate': 0.09157180091676087, 'max_depth': -6, 'n_estimators': 233, 'num_leaves': 86, 'min_child_weight': 0.004094090841664917}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:04,252] Trial 8 finished with value: 9.520487460093705 and parameters: {'learning_rate': 0.03672933598761976, 'max_depth': -6, 'n_estimators': 74, 'num_leaves': 60, 'min_child_weight': 0.018777486806933072}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:05,258] Trial 9 finished with value: 10.147731426714653 and parameters: {'learning_rate': 0.013017653359864786, 'max_depth': -5, 'n_estimators': 177, 'num_leaves': 44, 'min_child_weight': 35.04529657055501}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:05,663] Trial 10 finished with value: 7.636084429785469 and parameters: {'learning_rate': 0.04764323554413028, 'max_depth': 4, 'n_estimators': 114, 'num_leaves': 20, 'min_child_weight': 1.1637151873029303}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:06,019] Trial 11 finished with value: 8.171922357424842 and parameters: {'learning_rate': 0.04985896033341202, 'max_depth': 4, 'n_estimators': 118, 'num_leaves': 22, 'min_child_weight': 2.2596879623416335}. Best is trial 3 with value: 7.104332577003056.\n",
      "[I 2024-08-20 20:17:06,232] Trial 12 finished with value: 7.0494042736381255 and parameters: {'learning_rate': 0.05370940074341324, 'max_depth': 3, 'n_estimators': 61, 'num_leaves': 21, 'min_child_weight': 0.934023070951241}. Best is trial 12 with value: 7.0494042736381255.\n",
      "[I 2024-08-20 20:17:06,430] Trial 13 finished with value: 9.705596837588129 and parameters: {'learning_rate': 0.02524137449813237, 'max_depth': 2, 'n_estimators': 53, 'num_leaves': 32, 'min_child_weight': 0.1642888075955144}. Best is trial 12 with value: 7.0494042736381255.\n",
      "[I 2024-08-20 20:17:06,989] Trial 14 finished with value: 6.919629439663532 and parameters: {'learning_rate': 0.06144059846441634, 'max_depth': 2, 'n_estimators': 299, 'num_leaves': 79, 'min_child_weight': 12.597650793263869}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:07,560] Trial 15 finished with value: 7.7046622876876745 and parameters: {'learning_rate': 0.14542327793262888, 'max_depth': 2, 'n_estimators': 300, 'num_leaves': 79, 'min_child_weight': 16.58224507787361}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:08,125] Trial 16 finished with value: 7.009274578590334 and parameters: {'learning_rate': 0.06549397443395066, 'max_depth': 2, 'n_estimators': 298, 'num_leaves': 74, 'min_child_weight': 713.3691986604013}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:09,793] Trial 17 finished with value: 9.563657627826592 and parameters: {'learning_rate': 0.06748108399008572, 'max_depth': -2, 'n_estimators': 298, 'num_leaves': 76, 'min_child_weight': 923.8091169680263}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:10,314] Trial 18 finished with value: 8.539370322545041 and parameters: {'learning_rate': 0.13258660094020633, 'max_depth': 1, 'n_estimators': 268, 'num_leaves': 100, 'min_child_weight': 537.652573397672}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:12,368] Trial 19 finished with value: 8.798908389495539 and parameters: {'learning_rate': 0.06629536029147962, 'max_depth': 0, 'n_estimators': 263, 'num_leaves': 71, 'min_child_weight': 17.926923895845842}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:13,310] Trial 20 finished with value: 9.292456278094175 and parameters: {'learning_rate': 0.03016171517798299, 'max_depth': 6, 'n_estimators': 201, 'num_leaves': 87, 'min_child_weight': 111.23501685190794}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:13,864] Trial 21 finished with value: 9.652612841416236 and parameters: {'learning_rate': 0.06021660863813126, 'max_depth': 3, 'n_estimators': 275, 'num_leaves': 70, 'min_child_weight': 4.479161229882101}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:14,400] Trial 22 finished with value: 7.0097408260204785 and parameters: {'learning_rate': 0.05589262276122199, 'max_depth': 2, 'n_estimators': 278, 'num_leaves': 81, 'min_child_weight': 0.20601289695110886}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:14,940] Trial 23 finished with value: 8.230839326271576 and parameters: {'learning_rate': 0.07598366132466203, 'max_depth': 1, 'n_estimators': 283, 'num_leaves': 81, 'min_child_weight': 0.26386971167865714}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:17,490] Trial 24 finished with value: 10.477677644527427 and parameters: {'learning_rate': 0.11454537955398189, 'max_depth': -1, 'n_estimators': 254, 'num_leaves': 95, 'min_child_weight': 176.81542113147742}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:18,204] Trial 25 finished with value: 8.246463119719659 and parameters: {'learning_rate': 0.03200029815555868, 'max_depth': 5, 'n_estimators': 208, 'num_leaves': 72, 'min_child_weight': 6.816012473913593}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:18,722] Trial 26 finished with value: 6.934861999124302 and parameters: {'learning_rate': 0.058835243076668604, 'max_depth': 2, 'n_estimators': 286, 'num_leaves': 86, 'min_child_weight': 0.49407830526921787}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:19,308] Trial 27 finished with value: 8.271903515978417 and parameters: {'learning_rate': 0.06523257169806101, 'max_depth': 1, 'n_estimators': 299, 'num_leaves': 89, 'min_child_weight': 59.88701381694127}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:19,828] Trial 28 finished with value: 9.549034399893621 and parameters: {'learning_rate': 0.07727318202794972, 'max_depth': 3, 'n_estimators': 254, 'num_leaves': 99, 'min_child_weight': 364.83616350169075}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:20,771] Trial 29 finished with value: 9.010765284730589 and parameters: {'learning_rate': 0.11482209798313074, 'max_depth': 0, 'n_estimators': 145, 'num_leaves': 54, 'min_child_weight': 0.6550957553653597}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:22,040] Trial 30 finished with value: 9.32715263623669 and parameters: {'learning_rate': 0.01867047172587083, 'max_depth': -3, 'n_estimators': 157, 'num_leaves': 68, 'min_child_weight': 0.07465602472118728}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:22,627] Trial 31 finished with value: 6.981007705721703 and parameters: {'learning_rate': 0.05624792364913543, 'max_depth': 2, 'n_estimators': 286, 'num_leaves': 83, 'min_child_weight': 0.4091154770918397}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:23,142] Trial 32 finished with value: 7.192468965683292 and parameters: {'learning_rate': 0.041686287022844284, 'max_depth': 2, 'n_estimators': 281, 'num_leaves': 85, 'min_child_weight': 0.476569769619635}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:24,105] Trial 33 finished with value: 8.197412914205112 and parameters: {'learning_rate': 0.08716685399238709, 'max_depth': 5, 'n_estimators': 286, 'num_leaves': 76, 'min_child_weight': 2.562992529492021}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:24,597] Trial 34 finished with value: 8.329143973367865 and parameters: {'learning_rate': 0.04590971437064201, 'max_depth': 1, 'n_estimators': 250, 'num_leaves': 93, 'min_child_weight': 0.06196199529856531}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:26,205] Trial 35 finished with value: 9.311696346538108 and parameters: {'learning_rate': 0.03555570791330501, 'max_depth': -1, 'n_estimators': 211, 'num_leaves': 65, 'min_child_weight': 16.181024185995494}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:26,840] Trial 36 finished with value: 7.95779052656453 and parameters: {'learning_rate': 0.07052866367947791, 'max_depth': 3, 'n_estimators': 290, 'num_leaves': 77, 'min_child_weight': 6.8676748382129045}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:27,489] Trial 37 finished with value: 7.3239811673700315 and parameters: {'learning_rate': 0.057620501407215974, 'max_depth': 4, 'n_estimators': 266, 'num_leaves': 83, 'min_child_weight': 1.5077589097868314}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:28,258] Trial 38 finished with value: 7.158455366251634 and parameters: {'learning_rate': 0.09456905224087221, 'max_depth': 5, 'n_estimators': 240, 'num_leaves': 73, 'min_child_weight': 0.4362586620397371}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:29,915] Trial 39 finished with value: 8.81404321542398 and parameters: {'learning_rate': 0.0425037170675557, 'max_depth': 0, 'n_estimators': 223, 'num_leaves': 65, 'min_child_weight': 0.02226969985239397}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:30,404] Trial 40 finished with value: 6.992060630533748 and parameters: {'learning_rate': 0.05007088922917648, 'max_depth': 2, 'n_estimators': 265, 'num_leaves': 90, 'min_child_weight': 0.00796784291624062}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:30,888] Trial 41 finished with value: 7.057906066418828 and parameters: {'learning_rate': 0.049816797658300646, 'max_depth': 2, 'n_estimators': 266, 'num_leaves': 90, 'min_child_weight': 0.0013263548784307171}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:31,413] Trial 42 finished with value: 8.267757783831673 and parameters: {'learning_rate': 0.06240104790938342, 'max_depth': 1, 'n_estimators': 288, 'num_leaves': 96, 'min_child_weight': 0.006829335185115532}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:31,946] Trial 43 finished with value: 7.348341456057633 and parameters: {'learning_rate': 0.03639739958449061, 'max_depth': 3, 'n_estimators': 257, 'num_leaves': 85, 'min_child_weight': 0.00433131071001186}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:32,661] Trial 44 finished with value: 7.737826338229636 and parameters: {'learning_rate': 0.05257871260414968, 'max_depth': 4, 'n_estimators': 271, 'num_leaves': 89, 'min_child_weight': 0.03917875324670329}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:34,342] Trial 45 finished with value: 9.834635623847504 and parameters: {'learning_rate': 0.08053256878296496, 'max_depth': -1, 'n_estimators': 238, 'num_leaves': 56, 'min_child_weight': 0.014020495420048804}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:34,901] Trial 46 finished with value: 7.1558782662705385 and parameters: {'learning_rate': 0.044718621241623804, 'max_depth': 2, 'n_estimators': 291, 'num_leaves': 82, 'min_child_weight': 0.1042136430535246}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:35,472] Trial 47 finished with value: 8.444146020280156 and parameters: {'learning_rate': 0.11010551500787376, 'max_depth': 3, 'n_estimators': 277, 'num_leaves': 75, 'min_child_weight': 37.429618216488}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:38,515] Trial 48 finished with value: 9.684177954158871 and parameters: {'learning_rate': 0.010554300835500883, 'max_depth': -7, 'n_estimators': 300, 'num_leaves': 92, 'min_child_weight': 304.628141869688}. Best is trial 14 with value: 6.919629439663532.\n",
      "[I 2024-08-20 20:17:40,809] Trial 49 finished with value: 9.184324714727822 and parameters: {'learning_rate': 0.07259075437021764, 'max_depth': -2, 'n_estimators': 225, 'num_leaves': 96, 'min_child_weight': 2.9459756716693124}. Best is trial 14 with value: 6.919629439663532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 71.340012\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:17:41,388] A new study created in memory with name: no-name-3e1d3b4e-9a06-4b4a-a05d-c35b2132a985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Finished optimization for quantile 0.3\n",
      "Best parameters for quantile 0.3: {'learning_rate': 0.06144059846441634, 'max_depth': 2, 'n_estimators': 299, 'num_leaves': 79, 'min_child_weight': 12.597650793263869, 'objective': 'quantile', 'alpha': 0.3}\n",
      "Starting optimization for quantile 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:17:42,494] Trial 0 finished with value: 7.48688128003299 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 7.48688128003299.\n",
      "[I 2024-08-20 20:17:43,160] Trial 1 finished with value: 7.238883733366881 and parameters: {'learning_rate': 0.010745715865807016, 'max_depth': -2, 'n_estimators': 122, 'num_leaves': 39, 'min_child_weight': 42.44112044681188}. Best is trial 1 with value: 7.238883733366881.\n",
      "[I 2024-08-20 20:17:44,863] Trial 2 finished with value: 9.338070660533363 and parameters: {'learning_rate': 0.05641092364413675, 'max_depth': -1, 'n_estimators': 165, 'num_leaves': 93, 'min_child_weight': 342.96896617445884}. Best is trial 1 with value: 7.238883733366881.\n",
      "[I 2024-08-20 20:17:45,221] Trial 3 finished with value: 7.581975420762224 and parameters: {'learning_rate': 0.018040823530713724, 'max_depth': 4, 'n_estimators': 125, 'num_leaves': 98, 'min_child_weight': 1.0463337530404244}. Best is trial 1 with value: 7.238883733366881.\n",
      "[I 2024-08-20 20:17:45,396] Trial 4 finished with value: 9.522301308583499 and parameters: {'learning_rate': 0.13270582827190383, 'max_depth': 1, 'n_estimators': 51, 'num_leaves': 67, 'min_child_weight': 8.444570059893145}. Best is trial 1 with value: 7.238883733366881.\n",
      "[I 2024-08-20 20:17:48,096] Trial 5 finished with value: 6.860858502807921 and parameters: {'learning_rate': 0.027175054757828564, 'max_depth': -3, 'n_estimators': 286, 'num_leaves': 91, 'min_child_weight': 1.7694687054539502}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:48,327] Trial 6 finished with value: 10.222059758747001 and parameters: {'learning_rate': 0.03406647222772188, 'max_depth': 1, 'n_estimators': 74, 'num_leaves': 69, 'min_child_weight': 856.3568107279024}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:48,917] Trial 7 finished with value: 7.590292542122579 and parameters: {'learning_rate': 0.021549195147647488, 'max_depth': 4, 'n_estimators': 239, 'num_leaves': 20, 'min_child_weight': 272.41792232725174}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:49,589] Trial 8 finished with value: 8.090333043883515 and parameters: {'learning_rate': 0.015617181540687851, 'max_depth': 4, 'n_estimators': 287, 'num_leaves': 86, 'min_child_weight': 0.2527203888976436}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:50,233] Trial 9 finished with value: 7.040361877543952 and parameters: {'learning_rate': 0.040201242205398155, 'max_depth': -7, 'n_estimators': 88, 'num_leaves': 52, 'min_child_weight': 0.05366165973045271}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:52,142] Trial 10 finished with value: 6.961737312573324 and parameters: {'learning_rate': 0.06518484815712311, 'max_depth': -7, 'n_estimators': 225, 'num_leaves': 78, 'min_child_weight': 0.0012856827793804307}. Best is trial 5 with value: 6.860858502807921.\n",
      "[I 2024-08-20 20:17:54,164] Trial 11 finished with value: 6.47100786253105 and parameters: {'learning_rate': 0.06636573423303777, 'max_depth': -7, 'n_estimators': 230, 'num_leaves': 80, 'min_child_weight': 0.001519314086161077}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:17:56,606] Trial 12 finished with value: 6.830471943408078 and parameters: {'learning_rate': 0.031196819747081855, 'max_depth': -4, 'n_estimators': 291, 'num_leaves': 79, 'min_child_weight': 2.1621550127169287}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:17:58,634] Trial 13 finished with value: 6.625586389984724 and parameters: {'learning_rate': 0.06135916448784108, 'max_depth': -5, 'n_estimators': 231, 'num_leaves': 78, 'min_child_weight': 0.0010849314198978976}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:17:59,997] Trial 14 finished with value: 6.6860533944797 and parameters: {'learning_rate': 0.07698683541397863, 'max_depth': -6, 'n_estimators': 214, 'num_leaves': 49, 'min_child_weight': 0.0010129983775896353}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:01,244] Trial 15 finished with value: 6.79424168988858 and parameters: {'learning_rate': 0.04740557491842422, 'max_depth': 7, 'n_estimators': 197, 'num_leaves': 78, 'min_child_weight': 0.010778935719687632}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:03,274] Trial 16 finished with value: 6.826853226834295 and parameters: {'learning_rate': 0.08979488131933484, 'max_depth': -5, 'n_estimators': 255, 'num_leaves': 69, 'min_child_weight': 0.008338517553771248}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:05,556] Trial 17 finished with value: 6.790290622561844 and parameters: {'learning_rate': 0.13384701813325361, 'max_depth': -5, 'n_estimators': 252, 'num_leaves': 84, 'min_child_weight': 0.2030515939813718}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:07,681] Trial 18 finished with value: 7.149080808991372 and parameters: {'learning_rate': 0.050782485377366564, 'max_depth': -7, 'n_estimators': 193, 'num_leaves': 99, 'min_child_weight': 0.003749653907316678}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:09,012] Trial 19 finished with value: 6.959314805377085 and parameters: {'learning_rate': 0.09680141460497924, 'max_depth': -2, 'n_estimators': 187, 'num_leaves': 60, 'min_child_weight': 0.04341756164711156}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:10,292] Trial 20 finished with value: 6.717400121191823 and parameters: {'learning_rate': 0.06906743096231859, 'max_depth': -5, 'n_estimators': 268, 'num_leaves': 34, 'min_child_weight': 0.04844996278439516}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:11,585] Trial 21 finished with value: 7.054928404755259 and parameters: {'learning_rate': 0.07478031457188596, 'max_depth': -6, 'n_estimators': 216, 'num_leaves': 47, 'min_child_weight': 0.0013361499489948753}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:13,046] Trial 22 finished with value: 6.864429269713309 and parameters: {'learning_rate': 0.0788808927943707, 'max_depth': -6, 'n_estimators': 226, 'num_leaves': 51, 'min_child_weight': 0.0010433912522285218}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:14,656] Trial 23 finished with value: 6.806197532726679 and parameters: {'learning_rate': 0.04627905291243734, 'max_depth': -4, 'n_estimators': 204, 'num_leaves': 72, 'min_child_weight': 0.0054932985824731086}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:15,679] Trial 24 finished with value: 6.877815044291679 and parameters: {'learning_rate': 0.06199538241862646, 'max_depth': -6, 'n_estimators': 175, 'num_leaves': 43, 'min_child_weight': 0.0026884357386654074}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:17,317] Trial 25 finished with value: 7.043642661972759 and parameters: {'learning_rate': 0.11458481716449861, 'max_depth': -3, 'n_estimators': 242, 'num_leaves': 59, 'min_child_weight': 0.01560970126075282}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:18,623] Trial 26 finished with value: 6.875650799925592 and parameters: {'learning_rate': 0.0834070282183347, 'max_depth': -7, 'n_estimators': 268, 'num_leaves': 35, 'min_child_weight': 0.18131903868022722}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:19,347] Trial 27 finished with value: 8.001183696966477 and parameters: {'learning_rate': 0.039025649060036145, 'max_depth': -5, 'n_estimators': 150, 'num_leaves': 29, 'min_child_weight': 0.025359217978768472}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:22,369] Trial 28 finished with value: 6.923660291888087 and parameters: {'learning_rate': 0.05549181906307446, 'max_depth': 0, 'n_estimators': 213, 'num_leaves': 53, 'min_child_weight': 0.0036470412531655837}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:24,038] Trial 29 finished with value: 7.031494150800145 and parameters: {'learning_rate': 0.10575219124178485, 'max_depth': -4, 'n_estimators': 231, 'num_leaves': 64, 'min_child_weight': 0.0022426889173594857}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:26,114] Trial 30 finished with value: 6.9279847980229885 and parameters: {'learning_rate': 0.11258272471988126, 'max_depth': -3, 'n_estimators': 269, 'num_leaves': 73, 'min_child_weight': 0.00936109584623264}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:27,340] Trial 31 finished with value: 7.009217650573678 and parameters: {'learning_rate': 0.06977634677531504, 'max_depth': -6, 'n_estimators': 266, 'num_leaves': 30, 'min_child_weight': 0.08324060421537019}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:30,554] Trial 32 finished with value: 6.757899917780644 and parameters: {'learning_rate': 0.06686207358661835, 'max_depth': -5, 'n_estimators': 300, 'num_leaves': 39, 'min_child_weight': 0.02690977771186077}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:31,466] Trial 33 finished with value: 7.743012784794647 and parameters: {'learning_rate': 0.05800319050250196, 'max_depth': -2, 'n_estimators': 250, 'num_leaves': 20, 'min_child_weight': 0.003022451617339438}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:32,927] Trial 34 finished with value: 6.763915130656834 and parameters: {'learning_rate': 0.08648862635148506, 'max_depth': -6, 'n_estimators': 210, 'num_leaves': 57, 'min_child_weight': 0.0010089577763076679}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:33,862] Trial 35 finished with value: 6.7398289719066975 and parameters: {'learning_rate': 0.049441686732282324, 'max_depth': -4, 'n_estimators': 162, 'num_leaves': 45, 'min_child_weight': 15.141115909064135}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:36,509] Trial 36 finished with value: 7.811274005316458 and parameters: {'learning_rate': 0.07210057586943297, 'max_depth': -1, 'n_estimators': 275, 'num_leaves': 92, 'min_child_weight': 0.6626667622411143}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:38,699] Trial 37 finished with value: 6.978268425696983 and parameters: {'learning_rate': 0.044862242245509054, 'max_depth': -7, 'n_estimators': 235, 'num_leaves': 85, 'min_child_weight': 0.005533164123104959}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:39,099] Trial 38 finished with value: 9.933438312310845 and parameters: {'learning_rate': 0.140619046534151, 'max_depth': 2, 'n_estimators': 184, 'num_leaves': 28, 'min_child_weight': 0.02063426650876845}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:40,383] Trial 39 finished with value: 6.882828588788034 and parameters: {'learning_rate': 0.033216941672601204, 'max_depth': -5, 'n_estimators': 256, 'num_leaves': 35, 'min_child_weight': 0.002019110892170133}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:42,126] Trial 40 finished with value: 6.911733926768655 and parameters: {'learning_rate': 0.02461452942253776, 'max_depth': -3, 'n_estimators': 220, 'num_leaves': 64, 'min_child_weight': 0.5459465118172907}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:42,984] Trial 41 finished with value: 7.00989004660121 and parameters: {'learning_rate': 0.05312459633315887, 'max_depth': -4, 'n_estimators': 133, 'num_leaves': 47, 'min_child_weight': 6.660941596349975}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:43,826] Trial 42 finished with value: 6.820303836217647 and parameters: {'learning_rate': 0.061621329464999805, 'max_depth': -6, 'n_estimators': 147, 'num_leaves': 43, 'min_child_weight': 51.06677482023374}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:44,763] Trial 43 finished with value: 6.811139087282217 and parameters: {'learning_rate': 0.04007998196923987, 'max_depth': -4, 'n_estimators': 168, 'num_leaves': 39, 'min_child_weight': 33.63217490082156}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:45,682] Trial 44 finished with value: 6.901445376153236 and parameters: {'learning_rate': 0.011475503391174651, 'max_depth': -5, 'n_estimators': 151, 'num_leaves': 46, 'min_child_weight': 5.13043125437716}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:46,758] Trial 45 finished with value: 6.627461238835294 and parameters: {'learning_rate': 0.09870679681603563, 'max_depth': -7, 'n_estimators': 109, 'num_leaves': 89, 'min_child_weight': 22.207399627171984}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:47,800] Trial 46 finished with value: 9.626187758124523 and parameters: {'learning_rate': 0.09646062873207203, 'max_depth': -7, 'n_estimators': 98, 'num_leaves': 89, 'min_child_weight': 214.82966152825114}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:48,240] Trial 47 finished with value: 7.79938806966715 and parameters: {'learning_rate': 0.12035229720091162, 'max_depth': 6, 'n_estimators': 64, 'num_leaves': 83, 'min_child_weight': 0.08615797869675129}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:49,454] Trial 48 finished with value: 6.899670129356936 and parameters: {'learning_rate': 0.08154109397877997, 'max_depth': -7, 'n_estimators': 105, 'num_leaves': 96, 'min_child_weight': 1.7057984828460908}. Best is trial 11 with value: 6.47100786253105.\n",
      "[I 2024-08-20 20:18:51,602] Trial 49 finished with value: 7.774832918430477 and parameters: {'learning_rate': 0.09346738385288207, 'max_depth': -6, 'n_estimators': 245, 'num_leaves': 75, 'min_child_weight': 0.005612034821083117}. Best is trial 11 with value: 6.47100786253105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 83.300003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:18:53,630] A new study created in memory with name: no-name-3f502489-c6fe-405d-808d-e4831a0bb1fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.4\n",
      "Best parameters for quantile 0.4: {'learning_rate': 0.06636573423303777, 'max_depth': -7, 'n_estimators': 230, 'num_leaves': 80, 'min_child_weight': 0.001519314086161077, 'objective': 'quantile', 'alpha': 0.4}\n",
      "Starting optimization for quantile 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:18:54,737] Trial 0 finished with value: 7.740052209625201 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 7.740052209625201.\n",
      "[I 2024-08-20 20:18:55,745] Trial 1 finished with value: 7.587569397041519 and parameters: {'learning_rate': 0.12362743734951166, 'max_depth': -2, 'n_estimators': 122, 'num_leaves': 72, 'min_child_weight': 0.06179097533441611}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:18:56,347] Trial 2 finished with value: 8.39183680452305 and parameters: {'learning_rate': 0.14510953060297993, 'max_depth': 5, 'n_estimators': 181, 'num_leaves': 43, 'min_child_weight': 0.002111774170917428}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:18:57,771] Trial 3 finished with value: 7.613319280965905 and parameters: {'learning_rate': 0.019818612338514584, 'max_depth': -6, 'n_estimators': 137, 'num_leaves': 85, 'min_child_weight': 0.3198331614940928}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:18:57,977] Trial 4 finished with value: 10.126549464593912 and parameters: {'learning_rate': 0.028156493292192695, 'max_depth': 2, 'n_estimators': 68, 'num_leaves': 42, 'min_child_weight': 4.415256996115144}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:18:58,447] Trial 5 finished with value: 8.268055173408168 and parameters: {'learning_rate': 0.012372914515201883, 'max_depth': -5, 'n_estimators': 92, 'num_leaves': 30, 'min_child_weight': 0.0667779828853667}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:00,458] Trial 6 finished with value: 7.752125553085737 and parameters: {'learning_rate': 0.011083673060873144, 'max_depth': -1, 'n_estimators': 214, 'num_leaves': 83, 'min_child_weight': 106.51726015116873}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:00,942] Trial 7 finished with value: 10.936478377178842 and parameters: {'learning_rate': 0.09933238162914129, 'max_depth': 2, 'n_estimators': 231, 'num_leaves': 55, 'min_child_weight': 0.004968354287066368}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:02,257] Trial 8 finished with value: 7.863159541096799 and parameters: {'learning_rate': 0.02413544361505817, 'max_depth': 7, 'n_estimators': 216, 'num_leaves': 74, 'min_child_weight': 69.33161961545481}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:02,630] Trial 9 finished with value: 9.4803797659137 and parameters: {'learning_rate': 0.07635493851887351, 'max_depth': 6, 'n_estimators': 60, 'num_leaves': 82, 'min_child_weight': 408.9813821408053}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:07,179] Trial 10 finished with value: 7.869687021008009 and parameters: {'learning_rate': 0.05279378997328302, 'max_depth': -2, 'n_estimators': 300, 'num_leaves': 68, 'min_child_weight': 5.705494537001693}. Best is trial 1 with value: 7.587569397041519.\n",
      "[I 2024-08-20 20:19:08,702] Trial 11 finished with value: 7.464181786462816 and parameters: {'learning_rate': 0.020492484799895346, 'max_depth': -7, 'n_estimators': 124, 'num_leaves': 98, 'min_child_weight': 0.171425540822519}. Best is trial 11 with value: 7.464181786462816.\n",
      "[I 2024-08-20 20:19:09,929] Trial 12 finished with value: 7.481335928460069 and parameters: {'learning_rate': 0.04333286921186723, 'max_depth': -7, 'n_estimators': 112, 'num_leaves': 98, 'min_child_weight': 0.07047271478402665}. Best is trial 11 with value: 7.464181786462816.\n",
      "[I 2024-08-20 20:19:11,051] Trial 13 finished with value: 7.596288933757956 and parameters: {'learning_rate': 0.04138703378798825, 'max_depth': -7, 'n_estimators': 96, 'num_leaves': 96, 'min_child_weight': 0.6573793048508852}. Best is trial 11 with value: 7.464181786462816.\n",
      "[I 2024-08-20 20:19:13,095] Trial 14 finished with value: 7.489048748338241 and parameters: {'learning_rate': 0.019134499148170468, 'max_depth': -4, 'n_estimators': 162, 'num_leaves': 100, 'min_child_weight': 0.049583201784368244}. Best is trial 11 with value: 7.464181786462816.\n",
      "[I 2024-08-20 20:19:15,661] Trial 15 finished with value: 7.438855918036684 and parameters: {'learning_rate': 0.053628849735842886, 'max_depth': -7, 'n_estimators': 114, 'num_leaves': 92, 'min_child_weight': 3.817056066357798}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:17,584] Trial 16 finished with value: 7.536808877286048 and parameters: {'learning_rate': 0.06277040516327771, 'max_depth': -4, 'n_estimators': 185, 'num_leaves': 90, 'min_child_weight': 4.429160912749738}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:17,830] Trial 17 finished with value: 11.010011558360219 and parameters: {'learning_rate': 0.030693574015542333, 'max_depth': 1, 'n_estimators': 88, 'num_leaves': 88, 'min_child_weight': 28.282762441599836}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:18,374] Trial 18 finished with value: 9.106792213826347 and parameters: {'learning_rate': 0.01625159589391998, 'max_depth': -7, 'n_estimators': 128, 'num_leaves': 22, 'min_child_weight': 1.1892746147213638}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:18,588] Trial 19 finished with value: 8.002975415422116 and parameters: {'learning_rate': 0.03537567347537286, 'max_depth': 4, 'n_estimators': 51, 'num_leaves': 77, 'min_child_weight': 0.29188079734695505}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:21,305] Trial 20 finished with value: 7.784564259884629 and parameters: {'learning_rate': 0.06335043709333397, 'max_depth': -5, 'n_estimators': 281, 'num_leaves': 93, 'min_child_weight': 19.73040714999539}. Best is trial 15 with value: 7.438855918036684.\n",
      "[I 2024-08-20 20:19:22,691] Trial 21 finished with value: 7.427288183541625 and parameters: {'learning_rate': 0.04591595310789486, 'max_depth': -7, 'n_estimators': 119, 'num_leaves': 99, 'min_child_weight': 0.016109923202265845}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:23,780] Trial 22 finished with value: 7.620167398833171 and parameters: {'learning_rate': 0.05024941771853903, 'max_depth': -6, 'n_estimators': 103, 'num_leaves': 99, 'min_child_weight': 0.012945632148274794}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:25,300] Trial 23 finished with value: 7.637874242463801 and parameters: {'learning_rate': 0.03633637241194177, 'max_depth': -3, 'n_estimators': 138, 'num_leaves': 91, 'min_child_weight': 0.001215737230464895}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:26,067] Trial 24 finished with value: 8.077703625810159 and parameters: {'learning_rate': 0.07433295961653909, 'max_depth': -6, 'n_estimators': 77, 'num_leaves': 79, 'min_child_weight': 0.016529158291789723}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:27,801] Trial 25 finished with value: 7.614098931813601 and parameters: {'learning_rate': 0.01618253878341141, 'max_depth': -7, 'n_estimators': 166, 'num_leaves': 90, 'min_child_weight': 1.6004380052219684}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:29,069] Trial 26 finished with value: 7.694430097801286 and parameters: {'learning_rate': 0.025165632935485273, 'max_depth': -5, 'n_estimators': 116, 'num_leaves': 95, 'min_child_weight': 0.20826097886999634}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:30,201] Trial 27 finished with value: 8.055682999587933 and parameters: {'learning_rate': 0.05149381658648684, 'max_depth': -3, 'n_estimators': 142, 'num_leaves': 68, 'min_child_weight': 0.17114434461094172}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:32,106] Trial 28 finished with value: 7.682288109689813 and parameters: {'learning_rate': 0.029926536416514275, 'max_depth': 0, 'n_estimators': 192, 'num_leaves': 85, 'min_child_weight': 0.003943530563234598}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:33,249] Trial 29 finished with value: 7.544879589804883 and parameters: {'learning_rate': 0.08788413470298939, 'max_depth': -5, 'n_estimators': 158, 'num_leaves': 59, 'min_child_weight': 0.0207327738038745}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:33,846] Trial 30 finished with value: 7.491867597938629 and parameters: {'learning_rate': 0.06197113009303636, 'max_depth': -3, 'n_estimators': 76, 'num_leaves': 50, 'min_child_weight': 2.789585174642042}. Best is trial 21 with value: 7.427288183541625.\n",
      "[I 2024-08-20 20:19:35,102] Trial 31 finished with value: 7.311548119788489 and parameters: {'learning_rate': 0.042480288499422716, 'max_depth': -7, 'n_estimators': 110, 'num_leaves': 99, 'min_child_weight': 0.09968269800672638}. Best is trial 31 with value: 7.311548119788489.\n",
      "[I 2024-08-20 20:19:36,451] Trial 32 finished with value: 6.999204158191513 and parameters: {'learning_rate': 0.0463975658804506, 'max_depth': -6, 'n_estimators': 124, 'num_leaves': 100, 'min_child_weight': 0.032923852181524396}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:37,619] Trial 33 finished with value: 7.275325825638899 and parameters: {'learning_rate': 0.04744971022035607, 'max_depth': -6, 'n_estimators': 109, 'num_leaves': 93, 'min_child_weight': 0.026847661946088543}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:39,242] Trial 34 finished with value: 7.6405426761908215 and parameters: {'learning_rate': 0.044218878782155975, 'max_depth': -6, 'n_estimators': 146, 'num_leaves': 100, 'min_child_weight': 0.03150151779169364}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:41,671] Trial 35 finished with value: 7.460948392423377 and parameters: {'learning_rate': 0.03979050424084847, 'max_depth': -4, 'n_estimators': 106, 'num_leaves': 88, 'min_child_weight': 0.006526061580560489}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:42,492] Trial 36 finished with value: 7.6881470478321425 and parameters: {'learning_rate': 0.03501104737528525, 'max_depth': -6, 'n_estimators': 87, 'num_leaves': 85, 'min_child_weight': 0.09506369696625915}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:43,832] Trial 37 finished with value: 7.649699589049932 and parameters: {'learning_rate': 0.04660694999766898, 'max_depth': -5, 'n_estimators': 130, 'num_leaves': 94, 'min_child_weight': 0.03260867826255981}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:45,138] Trial 38 finished with value: 7.7195803103262275 and parameters: {'learning_rate': 0.07673883255114712, 'max_depth': -2, 'n_estimators': 152, 'num_leaves': 68, 'min_child_weight': 0.0023114424856691086}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:45,667] Trial 39 finished with value: 7.5549437711125105 and parameters: {'learning_rate': 0.10767328014391249, 'max_depth': -6, 'n_estimators': 80, 'num_leaves': 35, 'min_child_weight': 0.6434341156319808}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:46,780] Trial 40 finished with value: 7.652287767282581 and parameters: {'learning_rate': 0.03182039456162156, 'max_depth': -4, 'n_estimators': 98, 'num_leaves': 80, 'min_child_weight': 0.012951693361487153}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:48,053] Trial 41 finished with value: 7.248292562559573 and parameters: {'learning_rate': 0.059333767521963135, 'max_depth': -7, 'n_estimators': 115, 'num_leaves': 95, 'min_child_weight': 0.007593042504239637}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:49,365] Trial 42 finished with value: 7.02153444815833 and parameters: {'learning_rate': 0.05740042589487119, 'max_depth': -6, 'n_estimators': 122, 'num_leaves': 95, 'min_child_weight': 0.007538253481277781}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:51,334] Trial 43 finished with value: 7.460835956299514 and parameters: {'learning_rate': 0.05938259413813963, 'max_depth': -6, 'n_estimators': 171, 'num_leaves': 95, 'min_child_weight': 0.007626380001868469}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:52,733] Trial 44 finished with value: 7.9490941062131935 and parameters: {'learning_rate': 0.06756551168249818, 'max_depth': -5, 'n_estimators': 133, 'num_leaves': 86, 'min_child_weight': 0.0029782691594571415}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:52,991] Trial 45 finished with value: 9.007494391068237 and parameters: {'learning_rate': 0.08752992761153677, 'max_depth': 4, 'n_estimators': 69, 'num_leaves': 73, 'min_child_weight': 0.0014232317514023052}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:54,039] Trial 46 finished with value: 8.146813279542494 and parameters: {'learning_rate': 0.13721423140184064, 'max_depth': -6, 'n_estimators': 106, 'num_leaves': 95, 'min_child_weight': 0.10316897061745574}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:55,280] Trial 47 finished with value: 7.406555807887032 and parameters: {'learning_rate': 0.053154381489766096, 'max_depth': -1, 'n_estimators': 126, 'num_leaves': 83, 'min_child_weight': 0.04912855514620965}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:57,537] Trial 48 finished with value: 7.648183567459195 and parameters: {'learning_rate': 0.05627910547326223, 'max_depth': -7, 'n_estimators': 93, 'num_leaves': 89, 'min_child_weight': 0.0055602310458402636}. Best is trial 32 with value: 6.999204158191513.\n",
      "[I 2024-08-20 20:19:59,125] Trial 49 finished with value: 7.32902783126757 and parameters: {'learning_rate': 0.07206826549858518, 'max_depth': -5, 'n_estimators': 152, 'num_leaves': 97, 'min_child_weight': 0.02511616321480229}. Best is trial 32 with value: 6.999204158191513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 97.790001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:20:00,512] A new study created in memory with name: no-name-f66a55a0-d94f-468c-9bf3-733673568157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.5\n",
      "Best parameters for quantile 0.5: {'learning_rate': 0.0463975658804506, 'max_depth': -6, 'n_estimators': 124, 'num_leaves': 100, 'min_child_weight': 0.032923852181524396, 'objective': 'quantile', 'alpha': 0.5}\n",
      "Starting optimization for quantile 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:20:01,616] Trial 0 finished with value: 8.768324432003938 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 8.768324432003938.\n",
      "[I 2024-08-20 20:20:02,895] Trial 1 finished with value: 8.203896382686949 and parameters: {'learning_rate': 0.051528014321387615, 'max_depth': 6, 'n_estimators': 286, 'num_leaves': 93, 'min_child_weight': 0.003762609324359518}. Best is trial 1 with value: 8.203896382686949.\n",
      "[I 2024-08-20 20:20:03,551] Trial 2 finished with value: 8.465216204417931 and parameters: {'learning_rate': 0.012964504543007942, 'max_depth': 5, 'n_estimators': 203, 'num_leaves': 98, 'min_child_weight': 0.006247208360848162}. Best is trial 1 with value: 8.203896382686949.\n",
      "[I 2024-08-20 20:20:05,381] Trial 3 finished with value: 8.333242068532439 and parameters: {'learning_rate': 0.06656022037623975, 'max_depth': 7, 'n_estimators': 142, 'num_leaves': 78, 'min_child_weight': 0.7194509252812984}. Best is trial 1 with value: 8.203896382686949.\n",
      "[I 2024-08-20 20:20:06,619] Trial 4 finished with value: 8.562687942284342 and parameters: {'learning_rate': 0.12186391209276234, 'max_depth': -1, 'n_estimators': 239, 'num_leaves': 40, 'min_child_weight': 14.705531431823985}. Best is trial 1 with value: 8.203896382686949.\n",
      "[I 2024-08-20 20:20:07,218] Trial 5 finished with value: 8.172752103652813 and parameters: {'learning_rate': 0.038272179351475394, 'max_depth': 4, 'n_estimators': 212, 'num_leaves': 50, 'min_child_weight': 0.10802123136327074}. Best is trial 5 with value: 8.172752103652813.\n",
      "[I 2024-08-20 20:20:08,694] Trial 6 finished with value: 8.101463732789323 and parameters: {'learning_rate': 0.08646364803551768, 'max_depth': -2, 'n_estimators': 144, 'num_leaves': 87, 'min_child_weight': 0.0022527070539606724}. Best is trial 6 with value: 8.101463732789323.\n",
      "[I 2024-08-20 20:20:09,156] Trial 7 finished with value: 7.855603112700112 and parameters: {'learning_rate': 0.13187788195870281, 'max_depth': -6, 'n_estimators': 53, 'num_leaves': 68, 'min_child_weight': 0.0022001152532804395}. Best is trial 7 with value: 7.855603112700112.\n",
      "[I 2024-08-20 20:20:10,675] Trial 8 finished with value: 8.261372777407553 and parameters: {'learning_rate': 0.030603050631842446, 'max_depth': -2, 'n_estimators': 246, 'num_leaves': 50, 'min_child_weight': 0.013498090788589817}. Best is trial 7 with value: 7.855603112700112.\n",
      "[I 2024-08-20 20:20:11,945] Trial 9 finished with value: 8.424094833241293 and parameters: {'learning_rate': 0.07294761043797035, 'max_depth': 7, 'n_estimators': 225, 'num_leaves': 84, 'min_child_weight': 0.05842746675970803}. Best is trial 7 with value: 7.855603112700112.\n",
      "[I 2024-08-20 20:20:12,217] Trial 10 finished with value: 9.598303446883666 and parameters: {'learning_rate': 0.020828429991943172, 'max_depth': -7, 'n_estimators': 52, 'num_leaves': 20, 'min_child_weight': 407.42112340867374}. Best is trial 7 with value: 7.855603112700112.\n",
      "[I 2024-08-20 20:20:12,927] Trial 11 finished with value: 8.893827932181285 and parameters: {'learning_rate': 0.12255217271722746, 'max_depth': -7, 'n_estimators': 63, 'num_leaves': 76, 'min_child_weight': 0.0012261061481862912}. Best is trial 7 with value: 7.855603112700112.\n",
      "[I 2024-08-20 20:20:13,218] Trial 12 finished with value: 7.6781410736609965 and parameters: {'learning_rate': 0.08258375389434038, 'max_depth': 2, 'n_estimators': 101, 'num_leaves': 68, 'min_child_weight': 1.4155851801891155}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:13,484] Trial 13 finished with value: 8.663188704069755 and parameters: {'learning_rate': 0.14815854216592864, 'max_depth': 2, 'n_estimators': 98, 'num_leaves': 67, 'min_child_weight': 4.612797441848869}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:13,737] Trial 14 finished with value: 7.731081907117468 and parameters: {'learning_rate': 0.053438194178684305, 'max_depth': 2, 'n_estimators': 91, 'num_leaves': 63, 'min_child_weight': 59.21057622757657}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:14,010] Trial 15 finished with value: 7.797415693558249 and parameters: {'learning_rate': 0.04726717404247865, 'max_depth': 2, 'n_estimators': 103, 'num_leaves': 55, 'min_child_weight': 148.0661297644938}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:14,276] Trial 16 finished with value: 9.058398154696002 and parameters: {'learning_rate': 0.027146069493601144, 'max_depth': 2, 'n_estimators': 100, 'num_leaves': 37, 'min_child_weight': 28.594937712157257}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:14,650] Trial 17 finished with value: 8.232304479795795 and parameters: {'learning_rate': 0.06101143549564906, 'max_depth': 1, 'n_estimators': 175, 'num_leaves': 70, 'min_child_weight': 1.5791844751068482}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:14,927] Trial 18 finished with value: 8.63332326171637 and parameters: {'learning_rate': 0.040392865493277724, 'max_depth': 4, 'n_estimators': 84, 'num_leaves': 39, 'min_child_weight': 58.0644132314929}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:15,773] Trial 19 finished with value: 8.30206416594102 and parameters: {'learning_rate': 0.09385684671085946, 'max_depth': 0, 'n_estimators': 124, 'num_leaves': 61, 'min_child_weight': 616.3448362220229}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:16,166] Trial 20 finished with value: 7.912196470046682 and parameters: {'learning_rate': 0.01835372755350401, 'max_depth': 3, 'n_estimators': 176, 'num_leaves': 77, 'min_child_weight': 0.44391484851834284}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:16,454] Trial 21 finished with value: 10.07795662695717 and parameters: {'learning_rate': 0.05066875962952792, 'max_depth': 1, 'n_estimators': 113, 'num_leaves': 54, 'min_child_weight': 121.90114563115345}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:16,696] Trial 22 finished with value: 7.973732211434934 and parameters: {'learning_rate': 0.04633972308673525, 'max_depth': 3, 'n_estimators': 77, 'num_leaves': 60, 'min_child_weight': 6.972907450308791}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:17,483] Trial 23 finished with value: 8.634849383111412 and parameters: {'learning_rate': 0.031698502511471084, 'max_depth': 0, 'n_estimators': 126, 'num_leaves': 45, 'min_child_weight': 125.96141445838644}. Best is trial 12 with value: 7.6781410736609965.\n",
      "[I 2024-08-20 20:20:17,712] Trial 24 finished with value: 7.6674526052014595 and parameters: {'learning_rate': 0.07208522420476395, 'max_depth': 2, 'n_estimators': 79, 'num_leaves': 64, 'min_child_weight': 979.291097033893}. Best is trial 24 with value: 7.6674526052014595.\n",
      "[I 2024-08-20 20:20:17,980] Trial 25 finished with value: 8.303638900042117 and parameters: {'learning_rate': 0.07729061743642623, 'max_depth': 4, 'n_estimators': 81, 'num_leaves': 71, 'min_child_weight': 855.1773795970529}. Best is trial 24 with value: 7.6674526052014595.\n",
      "[I 2024-08-20 20:20:18,564] Trial 26 finished with value: 7.9884803097188355 and parameters: {'learning_rate': 0.06151707889150654, 'max_depth': -1, 'n_estimators': 73, 'num_leaves': 64, 'min_child_weight': 3.5130969078155623}. Best is trial 24 with value: 7.6674526052014595.\n",
      "[I 2024-08-20 20:20:18,919] Trial 27 finished with value: 8.112129727804248 and parameters: {'learning_rate': 0.10199318853420174, 'max_depth': 1, 'n_estimators': 165, 'num_leaves': 25, 'min_child_weight': 321.7702919393529}. Best is trial 24 with value: 7.6674526052014595.\n",
      "[I 2024-08-20 20:20:19,432] Trial 28 finished with value: 8.00067042938129 and parameters: {'learning_rate': 0.05816631579537352, 'max_depth': 5, 'n_estimators': 126, 'num_leaves': 85, 'min_child_weight': 23.151380043292686}. Best is trial 24 with value: 7.6674526052014595.\n",
      "[I 2024-08-20 20:20:20,184] Trial 29 finished with value: 7.575554901820424 and parameters: {'learning_rate': 0.0845679320985278, 'max_depth': -3, 'n_estimators': 92, 'num_leaves': 57, 'min_child_weight': 0.2663550214278228}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:21,234] Trial 30 finished with value: 8.908983120179336 and parameters: {'learning_rate': 0.1059049440045391, 'max_depth': -1, 'n_estimators': 160, 'num_leaves': 56, 'min_child_weight': 0.20799728616622856}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:21,992] Trial 31 finished with value: 8.531616428555813 and parameters: {'learning_rate': 0.08490713162698467, 'max_depth': -4, 'n_estimators': 91, 'num_leaves': 62, 'min_child_weight': 0.031433900854837875}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:23,026] Trial 32 finished with value: 8.170733988715773 and parameters: {'learning_rate': 0.07017361112563159, 'max_depth': -4, 'n_estimators': 113, 'num_leaves': 73, 'min_child_weight': 1.5857388615217372}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:23,580] Trial 33 finished with value: 8.509105145263117 and parameters: {'learning_rate': 0.05514166947635938, 'max_depth': -3, 'n_estimators': 69, 'num_leaves': 58, 'min_child_weight': 11.445376773454043}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:24,206] Trial 34 finished with value: 7.619872861138326 and parameters: {'learning_rate': 0.10936535920208987, 'max_depth': 3, 'n_estimators': 280, 'num_leaves': 66, 'min_child_weight': 0.4017820758514811}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:25,052] Trial 35 finished with value: 8.087998084678178 and parameters: {'learning_rate': 0.10596635641461583, 'max_depth': 5, 'n_estimators': 264, 'num_leaves': 49, 'min_child_weight': 0.22180156141483087}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:25,703] Trial 36 finished with value: 9.083377865398022 and parameters: {'learning_rate': 0.08392425447451042, 'max_depth': 3, 'n_estimators': 297, 'num_leaves': 98, 'min_child_weight': 0.7166719395261091}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:28,123] Trial 37 finished with value: 7.734353005226355 and parameters: {'learning_rate': 0.1444865982591683, 'max_depth': -5, 'n_estimators': 271, 'num_leaves': 80, 'min_child_weight': 0.0104014951450256}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:29,013] Trial 38 finished with value: 7.692307706118946 and parameters: {'learning_rate': 0.11830327822405774, 'max_depth': 6, 'n_estimators': 202, 'num_leaves': 66, 'min_child_weight': 0.02989819024602689}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:30,845] Trial 39 finished with value: 8.10370400984605 and parameters: {'learning_rate': 0.09480609015318048, 'max_depth': -3, 'n_estimators': 193, 'num_leaves': 91, 'min_child_weight': 0.2407248185179002}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:31,544] Trial 40 finished with value: 8.285999098546187 and parameters: {'learning_rate': 0.07069048306370321, 'max_depth': 6, 'n_estimators': 136, 'num_leaves': 74, 'min_child_weight': 0.09307850082124358}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:32,424] Trial 41 finished with value: 7.682412835914504 and parameters: {'learning_rate': 0.11396243157639674, 'max_depth': 6, 'n_estimators': 202, 'num_leaves': 67, 'min_child_weight': 0.02390436912435426}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:33,041] Trial 42 finished with value: 8.325862790146086 and parameters: {'learning_rate': 0.11867173254230619, 'max_depth': 4, 'n_estimators': 235, 'num_leaves': 81, 'min_child_weight': 0.023553547228473738}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:34,336] Trial 43 finished with value: 8.763996172818572 and parameters: {'learning_rate': 0.011537066747515924, 'max_depth': 6, 'n_estimators': 265, 'num_leaves': 69, 'min_child_weight': 0.05723454803711262}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:34,802] Trial 44 finished with value: 8.07363493663596 and parameters: {'learning_rate': 0.07900002742873734, 'max_depth': 1, 'n_estimators': 216, 'num_leaves': 51, 'min_child_weight': 0.00553847482811884}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:35,044] Trial 45 finished with value: 8.212229781438381 and parameters: {'learning_rate': 0.12837262892589718, 'max_depth': 3, 'n_estimators': 62, 'num_leaves': 66, 'min_child_weight': 0.41522677046807854}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:36,225] Trial 46 finished with value: 7.9631448658049475 and parameters: {'learning_rate': 0.09246880712989783, 'max_depth': 7, 'n_estimators': 248, 'num_leaves': 45, 'min_child_weight': 2.1933109648614533}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:36,691] Trial 47 finished with value: 8.481747988672543 and parameters: {'learning_rate': 0.11434369906515848, 'max_depth': 5, 'n_estimators': 109, 'num_leaves': 60, 'min_child_weight': 0.8501400532919362}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:37,848] Trial 48 finished with value: 8.656690099715806 and parameters: {'learning_rate': 0.06544935766581075, 'max_depth': 0, 'n_estimators': 137, 'num_leaves': 71, 'min_child_weight': 0.1292541081981669}. Best is trial 29 with value: 7.575554901820424.\n",
      "[I 2024-08-20 20:20:39,284] Trial 49 finished with value: 7.813106411537508 and parameters: {'learning_rate': 0.13830925904594862, 'max_depth': -2, 'n_estimators': 191, 'num_leaves': 64, 'min_child_weight': 0.002387231665819434}. Best is trial 29 with value: 7.575554901820424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 119.550003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:20:40,066] A new study created in memory with name: no-name-7d5f6e0d-b30b-454b-9add-474821dccdd2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.6\n",
      "Best parameters for quantile 0.6: {'learning_rate': 0.0845679320985278, 'max_depth': -3, 'n_estimators': 92, 'num_leaves': 57, 'min_child_weight': 0.2663550214278228, 'objective': 'quantile', 'alpha': 0.6}\n",
      "Starting optimization for quantile 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:20:41,132] Trial 0 finished with value: 7.283589300605662 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 7.283589300605662.\n",
      "[I 2024-08-20 20:20:41,689] Trial 1 finished with value: 7.238448656206474 and parameters: {'learning_rate': 0.08530739713512431, 'max_depth': -7, 'n_estimators': 55, 'num_leaves': 80, 'min_child_weight': 0.0668224372977975}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:42,748] Trial 2 finished with value: 8.127660003934475 and parameters: {'learning_rate': 0.01121502684093804, 'max_depth': 6, 'n_estimators': 227, 'num_leaves': 76, 'min_child_weight': 55.336095305662006}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:43,106] Trial 3 finished with value: 7.292957957048478 and parameters: {'learning_rate': 0.13144201475881614, 'max_depth': 4, 'n_estimators': 130, 'num_leaves': 93, 'min_child_weight': 0.01167963157338882}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:43,697] Trial 4 finished with value: 8.045010409985592 and parameters: {'learning_rate': 0.039163692573493794, 'max_depth': -7, 'n_estimators': 77, 'num_leaves': 51, 'min_child_weight': 9.735949804531195}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:44,579] Trial 5 finished with value: 8.266337374811236 and parameters: {'learning_rate': 0.017545616655617966, 'max_depth': -2, 'n_estimators': 163, 'num_leaves': 37, 'min_child_weight': 64.31748258737998}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:46,282] Trial 6 finished with value: 7.510592197733189 and parameters: {'learning_rate': 0.03290518982865467, 'max_depth': -5, 'n_estimators': 265, 'num_leaves': 51, 'min_child_weight': 0.09337138681301632}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:46,588] Trial 7 finished with value: 8.56783573341172 and parameters: {'learning_rate': 0.05650929375351454, 'max_depth': 1, 'n_estimators': 122, 'num_leaves': 95, 'min_child_weight': 0.01597434329254483}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:46,881] Trial 8 finished with value: 7.779838892625313 and parameters: {'learning_rate': 0.04865172441615392, 'max_depth': 5, 'n_estimators': 60, 'num_leaves': 77, 'min_child_weight': 4.920632938789455}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:47,458] Trial 9 finished with value: 7.5555692503958705 and parameters: {'learning_rate': 0.05331982930014459, 'max_depth': 7, 'n_estimators': 73, 'num_leaves': 88, 'min_child_weight': 0.2502389062351322}. Best is trial 1 with value: 7.238448656206474.\n",
      "[I 2024-08-20 20:20:47,886] Trial 10 finished with value: 6.87158527753069 and parameters: {'learning_rate': 0.08705472519438881, 'max_depth': 1, 'n_estimators': 212, 'num_leaves': 21, 'min_child_weight': 0.0010238194113870705}. Best is trial 10 with value: 6.87158527753069.\n",
      "[I 2024-08-20 20:20:48,338] Trial 11 finished with value: 6.9663378895058425 and parameters: {'learning_rate': 0.08570735312169815, 'max_depth': 1, 'n_estimators': 216, 'num_leaves': 24, 'min_child_weight': 0.0011930655771506028}. Best is trial 10 with value: 6.87158527753069.\n",
      "[I 2024-08-20 20:20:48,752] Trial 12 finished with value: 6.731190369429759 and parameters: {'learning_rate': 0.0818435162472405, 'max_depth': 1, 'n_estimators': 210, 'num_leaves': 20, 'min_child_weight': 0.0010482679236434188}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:49,218] Trial 13 finished with value: 7.770055756137482 and parameters: {'learning_rate': 0.14741529597526576, 'max_depth': 3, 'n_estimators': 210, 'num_leaves': 20, 'min_child_weight': 0.0010277274209596731}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:50,573] Trial 14 finished with value: 7.568287071313437 and parameters: {'learning_rate': 0.02435780400342459, 'max_depth': -1, 'n_estimators': 287, 'num_leaves': 34, 'min_child_weight': 445.9327454414075}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:50,982] Trial 15 finished with value: 7.963245570551408 and parameters: {'learning_rate': 0.0708900047299602, 'max_depth': 2, 'n_estimators': 198, 'num_leaves': 33, 'min_child_weight': 0.0031869537513296103}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:53,784] Trial 16 finished with value: 7.33619308882012 and parameters: {'learning_rate': 0.10760917039756172, 'max_depth': -2, 'n_estimators': 266, 'num_leaves': 46, 'min_child_weight': 0.872172867979421}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:54,890] Trial 17 finished with value: 6.914264911515675 and parameters: {'learning_rate': 0.06828958843052661, 'max_depth': -1, 'n_estimators': 242, 'num_leaves': 28, 'min_child_weight': 0.005285882381935987}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:55,350] Trial 18 finished with value: 7.527908500815163 and parameters: {'learning_rate': 0.03369377382962762, 'max_depth': 3, 'n_estimators': 184, 'num_leaves': 42, 'min_child_weight': 0.08463098662125053}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:57,214] Trial 19 finished with value: 7.207946542031995 and parameters: {'learning_rate': 0.11591591769341734, 'max_depth': 0, 'n_estimators': 243, 'num_leaves': 65, 'min_child_weight': 0.03114135044691628}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:58,461] Trial 20 finished with value: 7.134625101145407 and parameters: {'learning_rate': 0.06880621220118052, 'max_depth': -4, 'n_estimators': 180, 'num_leaves': 20, 'min_child_weight': 0.3371251844395515}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:20:59,523] Trial 21 finished with value: 7.222772730833235 and parameters: {'learning_rate': 0.07343366845090529, 'max_depth': -1, 'n_estimators': 243, 'num_leaves': 27, 'min_child_weight': 0.0031567355763819495}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:00,100] Trial 22 finished with value: 6.939572662270197 and parameters: {'learning_rate': 0.0630033550462139, 'max_depth': 1, 'n_estimators': 295, 'num_leaves': 29, 'min_child_weight': 0.004380518624246995}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:01,242] Trial 23 finished with value: 7.2427334157931975 and parameters: {'learning_rate': 0.045075215547998544, 'max_depth': -2, 'n_estimators': 246, 'num_leaves': 27, 'min_child_weight': 0.0011605943607766848}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:03,920] Trial 24 finished with value: 7.1968255967262 and parameters: {'learning_rate': 0.08811811021893588, 'max_depth': 0, 'n_estimators': 207, 'num_leaves': 38, 'min_child_weight': 0.0032579101240475575}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:04,451] Trial 25 finished with value: 8.07634421556683 and parameters: {'learning_rate': 0.116793297092885, 'max_depth': 3, 'n_estimators': 229, 'num_leaves': 20, 'min_child_weight': 0.006920670910445689}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:04,976] Trial 26 finished with value: 7.763258052542841 and parameters: {'learning_rate': 0.08306551319983119, 'max_depth': 2, 'n_estimators': 266, 'num_leaves': 31, 'min_child_weight': 0.040355198348205334}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:06,070] Trial 27 finished with value: 7.410582453924484 and parameters: {'learning_rate': 0.06254443549773055, 'max_depth': -3, 'n_estimators': 185, 'num_leaves': 45, 'min_child_weight': 0.02049758696075225}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:07,162] Trial 28 finished with value: 7.740527052235882 and parameters: {'learning_rate': 0.0261484955419747, 'max_depth': -1, 'n_estimators': 142, 'num_leaves': 61, 'min_child_weight': 0.001925918598123928}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:07,852] Trial 29 finished with value: 7.221093187258592 and parameters: {'learning_rate': 0.1022982419469333, 'max_depth': -5, 'n_estimators': 157, 'num_leaves': 25, 'min_child_weight': 0.007541834969407481}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:08,150] Trial 30 finished with value: 7.39390349304439 and parameters: {'learning_rate': 0.04171658165075714, 'max_depth': 2, 'n_estimators': 104, 'num_leaves': 53, 'min_child_weight': 0.009724287244016857}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:08,717] Trial 31 finished with value: 7.066597386272886 and parameters: {'learning_rate': 0.065592688790544, 'max_depth': 1, 'n_estimators': 296, 'num_leaves': 30, 'min_child_weight': 0.005137692792927533}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:10,223] Trial 32 finished with value: 7.487710842172909 and parameters: {'learning_rate': 0.056988191345288104, 'max_depth': 0, 'n_estimators': 276, 'num_leaves': 38, 'min_child_weight': 0.0026065495216131243}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:10,778] Trial 33 finished with value: 8.562202039153235 and parameters: {'learning_rate': 0.09339884018327677, 'max_depth': 1, 'n_estimators': 300, 'num_leaves': 25, 'min_child_weight': 0.00102130956193247}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:11,409] Trial 34 finished with value: 7.352223353889203 and parameters: {'learning_rate': 0.0764296060901523, 'max_depth': 4, 'n_estimators': 228, 'num_leaves': 29, 'min_child_weight': 0.005520163270167948}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:13,296] Trial 35 finished with value: 6.9766241368926725 and parameters: {'learning_rate': 0.12519050741811022, 'max_depth': -1, 'n_estimators': 253, 'num_leaves': 71, 'min_child_weight': 0.020732062298430935}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:14,286] Trial 36 finished with value: 8.791922832158965 and parameters: {'learning_rate': 0.010306389424474316, 'max_depth': -3, 'n_estimators': 198, 'num_leaves': 35, 'min_child_weight': 3.7419356679656945}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:14,884] Trial 37 finished with value: 7.493420524144293 and parameters: {'learning_rate': 0.014892261616549106, 'max_depth': 4, 'n_estimators': 230, 'num_leaves': 24, 'min_child_weight': 0.14027703241361011}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:16,095] Trial 38 finished with value: 7.272566915545312 and parameters: {'learning_rate': 0.09735867203523961, 'max_depth': 0, 'n_estimators': 220, 'num_leaves': 41, 'min_child_weight': 0.04178081052926087}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:16,507] Trial 39 finished with value: 7.33345531961179 and parameters: {'learning_rate': 0.05850927622760043, 'max_depth': 2, 'n_estimators': 169, 'num_leaves': 31, 'min_child_weight': 0.001937492041464615}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:17,434] Trial 40 finished with value: 6.878391662881963 and parameters: {'learning_rate': 0.051423278186872846, 'max_depth': 5, 'n_estimators': 285, 'num_leaves': 53, 'min_child_weight': 38.16563286639811}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:18,567] Trial 41 finished with value: 6.953576970720101 and parameters: {'learning_rate': 0.050690984331600054, 'max_depth': 6, 'n_estimators': 278, 'num_leaves': 82, 'min_child_weight': 41.05994312831325}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:19,373] Trial 42 finished with value: 7.294728352039904 and parameters: {'learning_rate': 0.037255451115229564, 'max_depth': 5, 'n_estimators': 257, 'num_leaves': 53, 'min_child_weight': 561.2016217236203}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:20,350] Trial 43 finished with value: 7.335391391901797 and parameters: {'learning_rate': 0.07885750997319847, 'max_depth': 7, 'n_estimators': 284, 'num_leaves': 22, 'min_child_weight': 28.317742819186947}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:20,826] Trial 44 finished with value: 7.0664576908186225 and parameters: {'learning_rate': 0.04644171761591253, 'max_depth': 1, 'n_estimators': 236, 'num_leaves': 67, 'min_child_weight': 20.08256921454908}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:21,454] Trial 45 finished with value: 7.306769391688526 and parameters: {'learning_rate': 0.06581496924106546, 'max_depth': 5, 'n_estimators': 199, 'num_leaves': 48, 'min_child_weight': 236.01369118594505}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:22,878] Trial 46 finished with value: 7.287185334412912 and parameters: {'learning_rate': 0.05180507920067956, 'max_depth': -7, 'n_estimators': 259, 'num_leaves': 41, 'min_child_weight': 170.99408510028334}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:23,484] Trial 47 finished with value: 9.15706139939051 and parameters: {'learning_rate': 0.08090824195822498, 'max_depth': 3, 'n_estimators': 274, 'num_leaves': 34, 'min_child_weight': 1.6515326002255792}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:26,239] Trial 48 finished with value: 6.856913895029596 and parameters: {'learning_rate': 0.1483207638477551, 'max_depth': -2, 'n_estimators': 292, 'num_leaves': 100, 'min_child_weight': 0.014103381863334692}. Best is trial 12 with value: 6.731190369429759.\n",
      "[I 2024-08-20 20:21:28,112] Trial 49 finished with value: 6.66625823488083 and parameters: {'learning_rate': 0.14662101833221497, 'max_depth': -3, 'n_estimators': 212, 'num_leaves': 83, 'min_child_weight': 0.015738189800648606}. Best is trial 49 with value: 6.66625823488083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 144.770004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:21:29,995] A new study created in memory with name: no-name-319aa8cd-2d7d-43c8-ab92-dee9103f7b18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.7\n",
      "Best parameters for quantile 0.7: {'learning_rate': 0.14662101833221497, 'max_depth': -3, 'n_estimators': 212, 'num_leaves': 83, 'min_child_weight': 0.015738189800648606, 'objective': 'quantile', 'alpha': 0.7}\n",
      "Starting optimization for quantile 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:21:31,020] Trial 0 finished with value: 5.457068465702511 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:31,843] Trial 1 finished with value: 6.784079519809554 and parameters: {'learning_rate': 0.018278228706645746, 'max_depth': -1, 'n_estimators': 151, 'num_leaves': 42, 'min_child_weight': 14.403125373933804}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:32,468] Trial 2 finished with value: 6.398587605333914 and parameters: {'learning_rate': 0.025028233154895125, 'max_depth': -4, 'n_estimators': 152, 'num_leaves': 27, 'min_child_weight': 0.01093408039434072}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:33,019] Trial 3 finished with value: 8.367845741308814 and parameters: {'learning_rate': 0.013135139735408148, 'max_depth': -3, 'n_estimators': 113, 'num_leaves': 30, 'min_child_weight': 0.6745245928504893}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:34,469] Trial 4 finished with value: 7.128456072111379 and parameters: {'learning_rate': 0.011117905318816018, 'max_depth': -4, 'n_estimators': 214, 'num_leaves': 59, 'min_child_weight': 0.08260695475706156}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:35,654] Trial 5 finished with value: 6.416291495722547 and parameters: {'learning_rate': 0.0145712155664352, 'max_depth': 0, 'n_estimators': 257, 'num_leaves': 33, 'min_child_weight': 18.199397869159764}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:36,584] Trial 6 finished with value: 6.818306974595134 and parameters: {'learning_rate': 0.013320491737819505, 'max_depth': 6, 'n_estimators': 193, 'num_leaves': 46, 'min_child_weight': 0.24851819936129396}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:37,202] Trial 7 finished with value: 8.981258051380507 and parameters: {'learning_rate': 0.014529201396827437, 'max_depth': -3, 'n_estimators': 84, 'num_leaves': 53, 'min_child_weight': 0.2619693227003174}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:37,666] Trial 8 finished with value: 5.939394428099793 and parameters: {'learning_rate': 0.03908445096626142, 'max_depth': 3, 'n_estimators': 225, 'num_leaves': 63, 'min_child_weight': 0.0019135524694758417}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:38,002] Trial 9 finished with value: 5.762499432154978 and parameters: {'learning_rate': 0.08563212693908022, 'max_depth': 3, 'n_estimators': 150, 'num_leaves': 61, 'min_child_weight': 57.091106592578875}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:38,393] Trial 10 finished with value: 6.186571664443102 and parameters: {'learning_rate': 0.14970036082181892, 'max_depth': -7, 'n_estimators': 54, 'num_leaves': 83, 'min_child_weight': 883.1041050321446}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:38,743] Trial 11 finished with value: 6.120649453424495 and parameters: {'learning_rate': 0.09934340731950407, 'max_depth': 3, 'n_estimators': 128, 'num_leaves': 74, 'min_child_weight': 35.5029939768281}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:39,347] Trial 12 finished with value: 5.911599322520266 and parameters: {'learning_rate': 0.06861741610123362, 'max_depth': 3, 'n_estimators': 292, 'num_leaves': 100, 'min_child_weight': 409.03260320224933}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:40,489] Trial 13 finished with value: 5.573376786067825 and parameters: {'learning_rate': 0.057809812600598864, 'max_depth': 7, 'n_estimators': 180, 'num_leaves': 73, 'min_child_weight': 4.4132372321915225}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:41,445] Trial 14 finished with value: 5.576140427256219 and parameters: {'learning_rate': 0.05040280633911238, 'max_depth': 6, 'n_estimators': 184, 'num_leaves': 77, 'min_child_weight': 2.9719946997223126}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:42,798] Trial 15 finished with value: 5.6843373299769215 and parameters: {'learning_rate': 0.13712582181218982, 'max_depth': 7, 'n_estimators': 236, 'num_leaves': 91, 'min_child_weight': 0.017144413096176665}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:43,693] Trial 16 finished with value: 5.815372541016717 and parameters: {'learning_rate': 0.05384676237136888, 'max_depth': -7, 'n_estimators': 106, 'num_leaves': 70, 'min_child_weight': 3.9193249041926905}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:44,064] Trial 17 finished with value: 8.465484221639809 and parameters: {'learning_rate': 0.029301129489483407, 'max_depth': 1, 'n_estimators': 174, 'num_leaves': 86, 'min_child_weight': 0.002845777056944112}. Best is trial 0 with value: 5.457068465702511.\n",
      "[I 2024-08-20 20:21:45,964] Trial 18 finished with value: 5.454088831292287 and parameters: {'learning_rate': 0.09315844594668085, 'max_depth': -1, 'n_estimators': 266, 'num_leaves': 67, 'min_child_weight': 0.04706930355525928}. Best is trial 18 with value: 5.454088831292287.\n",
      "[I 2024-08-20 20:21:47,861] Trial 19 finished with value: 5.485984366854235 and parameters: {'learning_rate': 0.10354253209806902, 'max_depth': -5, 'n_estimators': 293, 'num_leaves': 50, 'min_child_weight': 0.03101503950207921}. Best is trial 18 with value: 5.454088831292287.\n",
      "[I 2024-08-20 20:21:49,399] Trial 20 finished with value: 5.461871398860064 and parameters: {'learning_rate': 0.07924602352243097, 'max_depth': -1, 'n_estimators': 260, 'num_leaves': 40, 'min_child_weight': 0.00520362744469308}. Best is trial 18 with value: 5.454088831292287.\n",
      "[I 2024-08-20 20:21:50,294] Trial 21 finished with value: 5.604023837177807 and parameters: {'learning_rate': 0.07864211507839663, 'max_depth': -1, 'n_estimators': 260, 'num_leaves': 20, 'min_child_weight': 0.007083039562906166}. Best is trial 18 with value: 5.454088831292287.\n",
      "[I 2024-08-20 20:21:51,684] Trial 22 finished with value: 5.3733942889592345 and parameters: {'learning_rate': 0.11039061660719415, 'max_depth': -2, 'n_estimators': 267, 'num_leaves': 39, 'min_child_weight': 0.06993882182743662}. Best is trial 22 with value: 5.3733942889592345.\n",
      "[I 2024-08-20 20:21:53,575] Trial 23 finished with value: 5.324939660948669 and parameters: {'learning_rate': 0.11591953921523504, 'max_depth': -2, 'n_estimators': 276, 'num_leaves': 65, 'min_child_weight': 0.057937921857839754}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:54,085] Trial 24 finished with value: 7.224100943807586 and parameters: {'learning_rate': 0.11754169245774737, 'max_depth': 1, 'n_estimators': 276, 'num_leaves': 67, 'min_child_weight': 0.06079897185642135}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:55,509] Trial 25 finished with value: 5.439217116191852 and parameters: {'learning_rate': 0.12271013496948406, 'max_depth': -2, 'n_estimators': 241, 'num_leaves': 53, 'min_child_weight': 0.15239152651662424}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:56,997] Trial 26 finished with value: 5.362382657678333 and parameters: {'learning_rate': 0.13442219020009005, 'max_depth': -2, 'n_estimators': 242, 'num_leaves': 53, 'min_child_weight': 0.19498019420068638}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:58,040] Trial 27 finished with value: 5.57502110914678 and parameters: {'learning_rate': 0.12382516025272147, 'max_depth': -6, 'n_estimators': 207, 'num_leaves': 38, 'min_child_weight': 0.663657589532069}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:58,627] Trial 28 finished with value: 5.335231846343009 and parameters: {'learning_rate': 0.06851725812623587, 'max_depth': 1, 'n_estimators': 298, 'num_leaves': 47, 'min_child_weight': 0.0010248445439328207}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:59,144] Trial 29 finished with value: 5.3349751054011865 and parameters: {'learning_rate': 0.06750481467674319, 'max_depth': 1, 'n_estimators': 283, 'num_leaves': 47, 'min_child_weight': 0.0012348895323612073}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:21:59,693] Trial 30 finished with value: 6.270817741326765 and parameters: {'learning_rate': 0.04055893615931731, 'max_depth': 1, 'n_estimators': 298, 'num_leaves': 58, 'min_child_weight': 0.001019682552720746}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:00,254] Trial 31 finished with value: 6.172190126242047 and parameters: {'learning_rate': 0.048449802861003415, 'max_depth': 2, 'n_estimators': 279, 'num_leaves': 47, 'min_child_weight': 0.0010173161303380313}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:01,878] Trial 32 finished with value: 5.715139928657028 and parameters: {'learning_rate': 0.06300290280267148, 'max_depth': 0, 'n_estimators': 246, 'num_leaves': 55, 'min_child_weight': 0.003420676150452248}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:03,489] Trial 33 finished with value: 5.527300720694239 and parameters: {'learning_rate': 0.07437697400070531, 'max_depth': -2, 'n_estimators': 283, 'num_leaves': 45, 'min_child_weight': 0.018999119860258627}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:05,108] Trial 34 finished with value: 5.6573260740489175 and parameters: {'learning_rate': 0.09063704263078172, 'max_depth': 0, 'n_estimators': 279, 'num_leaves': 50, 'min_child_weight': 0.00915330029283357}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:06,200] Trial 35 finished with value: 6.077603128948885 and parameters: {'learning_rate': 0.021348277286680657, 'max_depth': -3, 'n_estimators': 227, 'num_leaves': 35, 'min_child_weight': 1.4616057112237826}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:06,703] Trial 36 finished with value: 6.047000517576393 and parameters: {'learning_rate': 0.14359710019284144, 'max_depth': 2, 'n_estimators': 246, 'num_leaves': 64, 'min_child_weight': 0.0018090237900461814}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:08,275] Trial 37 finished with value: 5.60667750199382 and parameters: {'learning_rate': 0.0684311522783905, 'max_depth': -4, 'n_estimators': 295, 'num_leaves': 42, 'min_child_weight': 0.413340316777017}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:08,810] Trial 38 finished with value: 5.904787585104378 and parameters: {'learning_rate': 0.043008156524507235, 'max_depth': 4, 'n_estimators': 208, 'num_leaves': 29, 'min_child_weight': 0.15084525615325314}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:10,562] Trial 39 finished with value: 5.823385111660164 and parameters: {'learning_rate': 0.03169723194527312, 'max_depth': 0, 'n_estimators': 252, 'num_leaves': 57, 'min_child_weight': 0.015538388612444515}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:12,243] Trial 40 finished with value: 5.680734186770833 and parameters: {'learning_rate': 0.03315670210345617, 'max_depth': -5, 'n_estimators': 270, 'num_leaves': 49, 'min_child_weight': 1.3020622351598434}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:13,722] Trial 41 finished with value: 5.496004198952329 and parameters: {'learning_rate': 0.11466870414933741, 'max_depth': -2, 'n_estimators': 284, 'num_leaves': 42, 'min_child_weight': 0.08424577156546288}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:15,081] Trial 42 finished with value: 5.561960429482248 and parameters: {'learning_rate': 0.10381408363860208, 'max_depth': -3, 'n_estimators': 269, 'num_leaves': 38, 'min_child_weight': 0.1513258933182947}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:16,192] Trial 43 finished with value: 5.512842727727864 and parameters: {'learning_rate': 0.10881568579299758, 'max_depth': -2, 'n_estimators': 231, 'num_leaves': 34, 'min_child_weight': 0.02713323685440836}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:17,625] Trial 44 finished with value: 5.371999282374966 and parameters: {'learning_rate': 0.1318472248908232, 'max_depth': -1, 'n_estimators': 217, 'num_leaves': 53, 'min_child_weight': 0.004247531207267897}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:19,156] Trial 45 finished with value: 5.464440964495333 and parameters: {'learning_rate': 0.13238448729571695, 'max_depth': -1, 'n_estimators': 216, 'num_leaves': 60, 'min_child_weight': 0.0048851976038589906}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:19,699] Trial 46 finished with value: 6.532135429685888 and parameters: {'learning_rate': 0.0860628465049512, 'max_depth': 2, 'n_estimators': 300, 'num_leaves': 44, 'min_child_weight': 0.002431621279846764}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:20,094] Trial 47 finished with value: 6.04923957500917 and parameters: {'learning_rate': 0.13280693079505188, 'max_depth': 1, 'n_estimators': 195, 'num_leaves': 54, 'min_child_weight': 0.001552026401556067}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:20,567] Trial 48 finished with value: 6.016777969188889 and parameters: {'learning_rate': 0.06316493554485801, 'max_depth': 4, 'n_estimators': 163, 'num_leaves': 65, 'min_child_weight': 0.008401133707516016}. Best is trial 23 with value: 5.324939660948669.\n",
      "[I 2024-08-20 20:22:22,020] Trial 49 finished with value: 5.500142876095398 and parameters: {'learning_rate': 0.09403543298942707, 'max_depth': -3, 'n_estimators': 219, 'num_leaves': 52, 'min_child_weight': 0.003755368842792945}. Best is trial 23 with value: 5.324939660948669.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 174.130005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:22:24,048] A new study created in memory with name: no-name-72963a0c-18f7-417f-a3b9-702c244fda6d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization for quantile 0.8\n",
      "Best parameters for quantile 0.8: {'learning_rate': 0.11591953921523504, 'max_depth': -2, 'n_estimators': 276, 'num_leaves': 65, 'min_child_weight': 0.057937921857839754, 'objective': 'quantile', 'alpha': 0.8}\n",
      "Starting optimization for quantile 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 20:22:25,081] Trial 0 finished with value: 3.4224887032520357 and parameters: {'learning_rate': 0.1, 'max_depth': -4, 'n_estimators': 150, 'num_leaves': 60, 'min_child_weight': 0.01}. Best is trial 0 with value: 3.4224887032520357.\n",
      "[I 2024-08-20 20:22:25,450] Trial 1 finished with value: 4.8126470326592035 and parameters: {'learning_rate': 0.07861661655722325, 'max_depth': 1, 'n_estimators': 194, 'num_leaves': 38, 'min_child_weight': 228.1899825077589}. Best is trial 0 with value: 3.4224887032520357.\n",
      "[I 2024-08-20 20:22:25,809] Trial 2 finished with value: 6.31430127506621 and parameters: {'learning_rate': 0.012940640699482583, 'max_depth': 5, 'n_estimators': 99, 'num_leaves': 59, 'min_child_weight': 0.06006521437323781}. Best is trial 0 with value: 3.4224887032520357.\n",
      "[I 2024-08-20 20:22:27,085] Trial 3 finished with value: 3.2987448887081325 and parameters: {'learning_rate': 0.1237431840088094, 'max_depth': -4, 'n_estimators': 152, 'num_leaves': 87, 'min_child_weight': 0.005518591939850425}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:29,410] Trial 4 finished with value: 3.620688736143953 and parameters: {'learning_rate': 0.024059141468666397, 'max_depth': -7, 'n_estimators': 237, 'num_leaves': 100, 'min_child_weight': 0.04787410030841632}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:31,886] Trial 5 finished with value: 3.335503054885316 and parameters: {'learning_rate': 0.03142343401762617, 'max_depth': -5, 'n_estimators': 290, 'num_leaves': 86, 'min_child_weight': 0.012501949339602875}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:32,399] Trial 6 finished with value: 6.993741685051937 and parameters: {'learning_rate': 0.014331352748991803, 'max_depth': -3, 'n_estimators': 71, 'num_leaves': 58, 'min_child_weight': 19.904215838621898}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:32,617] Trial 7 finished with value: 6.013847153090048 and parameters: {'learning_rate': 0.06521136172050954, 'max_depth': 1, 'n_estimators': 81, 'num_leaves': 65, 'min_child_weight': 23.22173147829179}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:32,951] Trial 8 finished with value: 3.450574915193347 and parameters: {'learning_rate': 0.1363972912924486, 'max_depth': 4, 'n_estimators': 122, 'num_leaves': 20, 'min_child_weight': 61.60060818187035}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:33,823] Trial 9 finished with value: 3.5144835836516006 and parameters: {'learning_rate': 0.046748940707735755, 'max_depth': -1, 'n_estimators': 153, 'num_leaves': 43, 'min_child_weight': 0.013272052443238026}. Best is trial 3 with value: 3.2987448887081325.\n",
      "[I 2024-08-20 20:22:35,437] Trial 10 finished with value: 3.153950208693405 and parameters: {'learning_rate': 0.12447103733605464, 'max_depth': -7, 'n_estimators': 207, 'num_leaves': 81, 'min_child_weight': 0.0013318189329096916}. Best is trial 10 with value: 3.153950208693405.\n",
      "[I 2024-08-20 20:22:37,186] Trial 11 finished with value: 3.3162561947579583 and parameters: {'learning_rate': 0.14592866355483275, 'max_depth': -7, 'n_estimators': 218, 'num_leaves': 82, 'min_child_weight': 0.0016535439059940972}. Best is trial 10 with value: 3.153950208693405.\n",
      "[I 2024-08-20 20:22:39,155] Trial 12 finished with value: 3.258120767847511 and parameters: {'learning_rate': 0.05584172420644026, 'max_depth': -2, 'n_estimators': 239, 'num_leaves': 83, 'min_child_weight': 0.9170501010042693}. Best is trial 10 with value: 3.153950208693405.\n",
      "[I 2024-08-20 20:22:41,208] Trial 13 finished with value: 3.2195133627010515 and parameters: {'learning_rate': 0.05127445597177881, 'max_depth': -2, 'n_estimators': 265, 'num_leaves': 73, 'min_child_weight': 0.8579583985325141}. Best is trial 10 with value: 3.153950208693405.\n",
      "[I 2024-08-20 20:22:42,981] Trial 14 finished with value: 3.3432398841775344 and parameters: {'learning_rate': 0.03432217523929976, 'max_depth': 7, 'n_estimators': 295, 'num_leaves': 72, 'min_child_weight': 0.875620772952712}. Best is trial 10 with value: 3.153950208693405.\n",
      "[I 2024-08-20 20:22:45,330] Trial 15 finished with value: 3.142395953806214 and parameters: {'learning_rate': 0.08907923677793075, 'max_depth': -6, 'n_estimators': 263, 'num_leaves': 100, 'min_child_weight': 0.2022507312953144}. Best is trial 15 with value: 3.142395953806214.\n",
      "[I 2024-08-20 20:22:47,342] Trial 16 finished with value: 3.112187666449012 and parameters: {'learning_rate': 0.09359848422075455, 'max_depth': -6, 'n_estimators': 198, 'num_leaves': 99, 'min_child_weight': 0.17437427888652385}. Best is trial 16 with value: 3.112187666449012.\n",
      "[I 2024-08-20 20:22:49,761] Trial 17 finished with value: 3.047670240822928 and parameters: {'learning_rate': 0.07886213941042768, 'max_depth': -5, 'n_estimators': 260, 'num_leaves': 100, 'min_child_weight': 0.1657973375020632}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:22:51,391] Trial 18 finished with value: 3.178940171069216 and parameters: {'learning_rate': 0.07249132831146293, 'max_depth': -5, 'n_estimators': 175, 'num_leaves': 94, 'min_child_weight': 4.8998873574177955}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:22:53,618] Trial 19 finished with value: 3.228246398614048 and parameters: {'learning_rate': 0.10170208988619805, 'max_depth': 0, 'n_estimators': 248, 'num_leaves': 91, 'min_child_weight': 0.12090866506470001}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:22:54,003] Trial 20 finished with value: 3.7562723826210425 and parameters: {'learning_rate': 0.040407025623190415, 'max_depth': 3, 'n_estimators': 182, 'num_leaves': 44, 'min_child_weight': 4.438020761543696}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:22:56,378] Trial 21 finished with value: 3.126155946506284 and parameters: {'learning_rate': 0.0886912723534159, 'max_depth': -6, 'n_estimators': 271, 'num_leaves': 95, 'min_child_weight': 0.253537643789266}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:22:58,820] Trial 22 finished with value: 3.1357996544215303 and parameters: {'learning_rate': 0.09801285252608145, 'max_depth': -5, 'n_estimators': 276, 'num_leaves': 94, 'min_child_weight': 0.21792858940540982}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:00,872] Trial 23 finished with value: 3.244870931786034 and parameters: {'learning_rate': 0.06885170967326654, 'max_depth': -6, 'n_estimators': 221, 'num_leaves': 100, 'min_child_weight': 0.4356863941108371}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:03,155] Trial 24 finished with value: 3.212851196251381 and parameters: {'learning_rate': 0.05919351255965195, 'max_depth': -3, 'n_estimators': 250, 'num_leaves': 92, 'min_child_weight': 0.03374731717877154}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:05,194] Trial 25 finished with value: 3.1411981286524053 and parameters: {'learning_rate': 0.07872058896627716, 'max_depth': -6, 'n_estimators': 278, 'num_leaves': 75, 'min_child_weight': 2.507197200007728}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:07,393] Trial 26 finished with value: 3.6613518171209294 and parameters: {'learning_rate': 0.024860259375068576, 'max_depth': -4, 'n_estimators': 229, 'num_leaves': 94, 'min_child_weight': 0.11159074761255788}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:09,205] Trial 27 finished with value: 3.1466218885399115 and parameters: {'learning_rate': 0.11322410512256317, 'max_depth': -3, 'n_estimators': 210, 'num_leaves': 89, 'min_child_weight': 0.3320929530338649}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:11,160] Trial 28 finished with value: 3.295351519173026 and parameters: {'learning_rate': 0.08310806012297854, 'max_depth': -6, 'n_estimators': 258, 'num_leaves': 77, 'min_child_weight': 0.038479548909449976}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:12,278] Trial 29 finished with value: 3.4022844694025114 and parameters: {'learning_rate': 0.1062297235586184, 'max_depth': -5, 'n_estimators': 167, 'num_leaves': 66, 'min_child_weight': 781.2154425984305}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:15,088] Trial 30 finished with value: 3.138346939022162 and parameters: {'learning_rate': 0.043968287484404955, 'max_depth': -4, 'n_estimators': 300, 'num_leaves': 96, 'min_child_weight': 0.004494375494052118}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:17,542] Trial 31 finished with value: 3.1630805504300743 and parameters: {'learning_rate': 0.09318587654551118, 'max_depth': -5, 'n_estimators': 271, 'num_leaves': 96, 'min_child_weight': 0.30400772222939726}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:19,892] Trial 32 finished with value: 3.0993428772659173 and parameters: {'learning_rate': 0.09741975134170933, 'max_depth': -7, 'n_estimators': 279, 'num_leaves': 87, 'min_child_weight': 2.5771551656019502}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:21,702] Trial 33 finished with value: 3.1873723420017144 and parameters: {'learning_rate': 0.06489219547813682, 'max_depth': -7, 'n_estimators': 198, 'num_leaves': 88, 'min_child_weight': 1.9248094690611408}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:22,557] Trial 34 finished with value: 6.542720723644236 and parameters: {'learning_rate': 0.010045242950443069, 'max_depth': -7, 'n_estimators': 121, 'num_leaves': 53, 'min_child_weight': 6.876136364341012}. Best is trial 17 with value: 3.047670240822928.\n",
      "[I 2024-08-20 20:23:24,825] Trial 35 finished with value: 3.0187049494260187 and parameters: {'learning_rate': 0.11803191994755532, 'max_depth': -6, 'n_estimators': 281, 'num_leaves': 86, 'min_child_weight': 0.08928889594800071}. Best is trial 35 with value: 3.0187049494260187.\n",
      "[I 2024-08-20 20:23:25,296] Trial 36 finished with value: 3.668597948312543 and parameters: {'learning_rate': 0.12455211461947199, 'max_depth': -4, 'n_estimators': 50, 'num_leaves': 78, 'min_child_weight': 0.019583407269315817}. Best is trial 35 with value: 3.0187049494260187.\n",
      "[I 2024-08-20 20:23:27,678] Trial 37 finished with value: 3.010546756015936 and parameters: {'learning_rate': 0.14844727700821542, 'max_depth': -7, 'n_estimators': 289, 'num_leaves': 85, 'min_child_weight': 0.0709335679984089}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:30,038] Trial 38 finished with value: 3.1393787314938346 and parameters: {'learning_rate': 0.14892378360293543, 'max_depth': -7, 'n_estimators': 286, 'num_leaves': 85, 'min_child_weight': 0.0775563633192357}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:32,112] Trial 39 finished with value: 3.1304210924887497 and parameters: {'learning_rate': 0.11685745623146722, 'max_depth': -5, 'n_estimators': 300, 'num_leaves': 67, 'min_child_weight': 0.006210469477682895}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:32,627] Trial 40 finished with value: 4.208732501458299 and parameters: {'learning_rate': 0.1102194282663501, 'max_depth': 2, 'n_estimators': 283, 'num_leaves': 20, 'min_child_weight': 13.666215364883115}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:34,779] Trial 41 finished with value: 3.2252031801279877 and parameters: {'learning_rate': 0.13163704900899795, 'max_depth': -6, 'n_estimators': 250, 'num_leaves': 88, 'min_child_weight': 0.022679130844251164}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:37,111] Trial 42 finished with value: 3.1884176341615103 and parameters: {'learning_rate': 0.07647821571949506, 'max_depth': -7, 'n_estimators': 237, 'num_leaves': 99, 'min_child_weight': 0.07002791427711713}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:39,100] Trial 43 finished with value: 3.1764056998205628 and parameters: {'learning_rate': 0.14839775319646145, 'max_depth': -6, 'n_estimators': 258, 'num_leaves': 79, 'min_child_weight': 0.6256894966677635}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:41,474] Trial 44 finished with value: 3.157762437605203 and parameters: {'learning_rate': 0.0999769467467823, 'max_depth': -3, 'n_estimators': 287, 'num_leaves': 85, 'min_child_weight': 1.858602023924652}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:42,485] Trial 45 finished with value: 3.2326405376286598 and parameters: {'learning_rate': 0.12763569272386607, 'max_depth': -7, 'n_estimators': 131, 'num_leaves': 70, 'min_child_weight': 0.14974879584648845}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:43,627] Trial 46 finished with value: 3.911133406407143 and parameters: {'learning_rate': 0.01787805158846771, 'max_depth': -5, 'n_estimators': 289, 'num_leaves': 28, 'min_child_weight': 0.007753178922207973}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:45,603] Trial 47 finished with value: 3.1216146896089745 and parameters: {'learning_rate': 0.08536967376270076, 'max_depth': -4, 'n_estimators': 239, 'num_leaves': 82, 'min_child_weight': 52.60316786074682}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:46,822] Trial 48 finished with value: 3.3585052845851173 and parameters: {'learning_rate': 0.060439392343991837, 'max_depth': 6, 'n_estimators': 265, 'num_leaves': 91, 'min_child_weight': 0.04869958578918919}. Best is trial 37 with value: 3.010546756015936.\n",
      "[I 2024-08-20 20:23:48,602] Trial 49 finished with value: 3.275291668937334 and parameters: {'learning_rate': 0.05168337469643308, 'max_depth': -2, 'n_estimators': 280, 'num_leaves': 57, 'min_child_weight': 0.002820504199700747}. Best is trial 37 with value: 3.010546756015936.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20274\n",
      "[LightGBM] [Info] Number of data points in the train set: 50891, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 214.339966\n",
      "Finished optimization for quantile 0.9\n",
      "Best parameters for quantile 0.9: {'learning_rate': 0.14844727700821542, 'max_depth': -7, 'n_estimators': 289, 'num_leaves': 85, 'min_child_weight': 0.0709335679984089, 'objective': 'quantile', 'alpha': 0.9}\n",
      "Last CV loss for quantile 0.1: 3.212506141712019\n",
      "Last CV loss for quantile 0.2: 4.885855530537209\n",
      "Last CV loss for quantile 0.3: 6.919629435958689\n",
      "Last CV loss for quantile 0.4: 6.47100784846183\n",
      "Last CV loss for quantile 0.5: 6.999204164885743\n",
      "Last CV loss for quantile 0.6: 7.5755548992015465\n",
      "Last CV loss for quantile 0.7: 6.666258239410183\n",
      "Last CV loss for quantile 0.8: 5.324939673523676\n",
      "Last CV loss for quantile 0.9: 3.0105467777904305\n"
     ]
    }
   ],
   "source": [
    "# Directory for saving models\n",
    "saved_models_dir = 'models/DAP'\n",
    "os.makedirs(saved_models_dir, exist_ok=True)\n",
    "\n",
    "# Quantiles for the models\n",
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "best_params_dict = {}\n",
    "best_models = {}\n",
    "\n",
    "# Function to compute pinball loss\n",
    "def pinball_loss(y_true, y_pred, alpha):\n",
    "    residuals = y_true - y_pred\n",
    "    return np.mean(np.maximum(alpha * residuals, (alpha - 1) * residuals))\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial, quantile, initial_params=None):\n",
    "    if initial_params:\n",
    "        params = initial_params\n",
    "    else:\n",
    "        params = {\n",
    "            'objective': 'quantile',\n",
    "            'alpha': quantile,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', -7, 7),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 1e3, log=True),\n",
    "            'verbose': -1\n",
    "        }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    # Train on train_table and evaluate on cv_table\n",
    "    model.fit(train_table, train_target_variable)\n",
    "    preds = model.predict(cv_table)\n",
    "    \n",
    "    # Calculate pinball loss on the CV set\n",
    "    loss = pinball_loss(cv_target_variable, preds, alpha=quantile)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Train a model for each quantile with Optuna\n",
    "for quantile in quantiles:\n",
    "    print(f\"Starting optimization for quantile {quantile}\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # Initial parameters (from the ones you provided)\n",
    "    initial_params = {\n",
    "        'objective': 'quantile',\n",
    "        'alpha': quantile,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': -4,\n",
    "        'n_estimators': 150,\n",
    "        'num_leaves': 60,\n",
    "        'min_child_weight': 1e-2,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Run the first trial with your initial parameters\n",
    "    study.enqueue_trial(initial_params)\n",
    "    \n",
    "    # Run further trials\n",
    "    study.optimize(lambda trial: objective(trial, quantile), n_trials=50)  # You can adjust the number of trials\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_params['objective'] = 'quantile'\n",
    "    best_params['alpha'] = quantile\n",
    "    \n",
    "    # Train the model with the best parameters\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    model.fit(\n",
    "        train_table, train_target_variable,\n",
    "        eval_set=[(cv_table, cv_target_variable)],\n",
    "        eval_metric='quantile'\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = f'{saved_models_dir}/DAP_Tuned_q{int(quantile * 100)}.txt'\n",
    "    model.booster_.save_model(model_path)\n",
    "    \n",
    "    # Store the best params and model\n",
    "    best_params_dict[quantile] = best_params\n",
    "    best_models[quantile] = model\n",
    "    \n",
    "    print(f\"Finished optimization for quantile {quantile}\")\n",
    "    print(f\"Best parameters for quantile {quantile}: {best_params}\")\n",
    "\n",
    "# Print the last training loss for each quantile after all models have been trained\n",
    "for quantile, model in best_models.items():\n",
    "    last_loss = model.evals_result_['valid_0']['quantile'][-1]\n",
    "    print(f\"Last CV loss for quantile {quantile}: {last_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1007757459915455\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DA_Price'] = train_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DAP_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(train_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DA_Price'))\n",
    "\n",
    "# Save the predictions (They might be used for ensemble learning)\n",
    "quantile_predictions_df['time'] = train_times  \n",
    "csv_file_path = 'data/TradingTrackData/DAP_quantiles_train_set.csv'\n",
    "quantile_predictions_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.410903538394871\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DA_Price'] = cv_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DAP_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(cv_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DA_Price'))\n",
    "\n",
    "quantile_predictions_df['time'] = cv_times  \n",
    "csv_file_path = 'data/TradingTrackData/DAP_quantiles_cv_set.csv'\n",
    "quantile_predictions_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.506342087209934\n"
     ]
    }
   ],
   "source": [
    "quantile_predictions = {}\n",
    "quantile_predictions['DA_Price'] = test_target_variable\n",
    "\n",
    "quantiles = range(10, 100, 10)\n",
    "for qu in quantiles:\n",
    "    model_path = f'models/DAP/DAP_Tuned_q{qu}.txt'\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    quantile_predictions[f'q{qu}'] = model.predict(test_table)\n",
    "\n",
    "quantile_predictions_df = pd.DataFrame(quantile_predictions)\n",
    "quantile_columns = [col for col in quantile_predictions_df.columns if col.startswith('q')]\n",
    "quantile_predictions_df = sort_quantiles(quantile_predictions_df, quantile_columns)\n",
    "print(pinball_score(quantile_predictions_df,target_col='DA_Price'))\n",
    "\n",
    "quantile_predictions_df['time'] = test_times  \n",
    "csv_file_path = 'data/TradingTrackData/DAP_quantiles_test_set.csv'\n",
    "quantile_predictions_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Quantiles (Probabilistic Forecasting) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"plots/DAP/DAP_Plot.html\"\n",
    "graph_title = \"Day-Ahead-Price (DAP) Forecasting\"\n",
    "quantile_predictions_df['time'] = test_times  \n",
    "plot_quantiles_target_and_average_loss_interactive(quantile_predictions_df, 'DA_Price', test_times, save_path, title=graph_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Statistics of Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile_stats(quantile_predictions_df,'DA_Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_and_plot_average_quantile_loss(quantile_predictions_df, 'DA_Price', \"Day-Ahead-Price: Average Quantile Loss (LightGBM)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
